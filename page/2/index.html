<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!--Description-->
    

    <!--Author-->
    
        <meta name="author" content="Robert Lexis">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="This is Robert Lexis."/>
    

    <!--Open Graph Description-->
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content="This is Robert Lexis."/>

    <!--Type page-->
    
        <meta property="og:type" content="website" />
    

    <!--Page Cover-->
    

    <meta name="twitter:card" content="summary" />
    

    <!-- Title -->
    
    <title>page - This is Robert Lexis.</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.2/css/bootstrap.min.css" integrity="sha384-y3tfxAZXuh4HwSYylfB+J125MxIs6mR5FOHamPBG064zB+AFeWH94NdvaCBm8qnd" crossorigin="anonymous">

    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/style.css">

    <!-- Google Analytics -->
    


</head>


<body>

<div class="bg-gradient"></div>
<div class="bg-pattern"></div>

<!-- Menu -->
<!--Menu Links and Overlay-->
<div class="menu-bg">
    <div class="menu-container">
        <ul>
            
            <li class="menu-item">
                <a href="/">
                    Home
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/archives">
                    Archives
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/about">
                    About
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/tags">
                    Tags
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/categories">
                    Categories
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/contact">
                    Contact
                </a>
            </li>
            
        </ul>
    </div>
</div>

<!--Hamburger Icon-->
<nav>
    <a href="#menu"></a>
</nav>

<div class="container">

    <!-- Main Content -->
    <div class="row">
    <div class="col-sm-12">

        <!--Title and Logo-->
        <header>
    <div class="logo">
        <a href="/"><i class="logo-icon fa fa-cube" aria-hidden="true"></i></a>
        
            <h1 id="main-title" class="title">This is Robert Lexis.</h1>
        
    </div>
</header>

        <section class="main">
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/09/03/Optimizers/">
                Optimizers
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-09-03</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h3 id="Batch-vs-mini-batch-gradient-descent"><a href="#Batch-vs-mini-batch-gradient-descent" class="headerlink" title="Batch vs. mini-batch gradient descent"></a>Batch vs. mini-batch gradient descent</h3><p>mini-batch gradient descent 可以加快训练过程，Batch gradient descent 是过一次整个训练集才更新一次参数。Too long per iteration（<br>一次更新就是一次迭代，一次迭代就是一次更新）.<br>one epoch: single pass through training set.</p>
<h5 id="Understanding-mini-batch-gradient-descent"><a href="#Understanding-mini-batch-gradient-descent" class="headerlink" title="Understanding mini-batch gradient descent"></a>Understanding mini-batch gradient descent</h5><ul>
<li>Batch gradient descent cost 一定是单调递减的，如果不是，有可能是学习率太大了，导致发散了。</li>
<li>mini-batch gradient descent noisy</li></ul>
        </div>
        <a href="/2018/09/03/Optimizers/" class="read-more">Read More</a>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/28/Tensorflow-模型浮点数计算量和参数量统计/">
                TensorFlow 模型浮点数计算量和参数量统计
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-28</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>本博文整理了如何对一个 TensorFlow 模型的浮点数计算量（FLOPs）和参数量进行统计。<br>stats_graph.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stats_graph</span><span class="params">(graph)</span>:</span></div><div class="line">    flops = tf.profiler.profile(graph, options=tf.profiler.ProfileOptionBuilder.float_operation())</div><div class="line">    params = tf.profiler.profile(graph, options=tf.profiler.ProfileOptionBuilder.trainable_variables_parameter())</div><div class="line">    print(<span class="string">'FLOPs: &#123;&#125;;    Trainable params: &#123;&#125;'</span>.format(flops.total_float_ops, params.total_parameters))</div></pre></td></tr></table></figure></p>
        </div>
        <a href="/2018/08/28/Tensorflow-模型浮点数计算量和参数量统计/" class="read-more">Read More</a>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/26/YOLO/">
                YOLO
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-26</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h3 id="Sliding-Windows-滑动窗口"><a href="#Sliding-Windows-滑动窗口" class="headerlink" title="Sliding Windows 滑动窗口"></a>Sliding Windows 滑动窗口</h3><p>通过滑动窗口的方式在图像上生成一系列的 box，然后利用分类器对每个 box 进行分类，即可完成对图像中目标的检测。<br>基于滑动窗口的目标检测效率很低，因为我们需要对每个区域都进行预测，而且为了获得更加准确的结果，我们需要尝试各种不同尺寸的 box。</p>
<h3 id="Convolutional-Implementation-of-Sliding-Windows"><a href="#Convolutional-Implementation-of-Sliding-Windows" class="headerlink" title="Convolutional Implementation of Sliding Windows"></a>Convolutional Implementation of Sliding Windows</h3><p>这是一个加速的方法，共享计算。<br><img src="/2018/08/26/YOLO/cnn-slide.jpg" alt="cnn-slide"><br></p>
        </div>
        <a href="/2018/08/26/YOLO/" class="read-more">Read More</a>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/26/非最大值抑制/">
                非最大值抑制
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-26</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>非最大值抑制 Non-max Suppression 是目标检测（object detection）中常用的后处理（post processing）技术。<br>（Fast-， Faster-）RCNN，SSD，YOLO 等目标检测框架会对一个目标产生多个 bounding box 的预测结果，而我们最终需要的仅仅是最“合适”的那一个。<br>非最大值抑制就是用来去除（clean up）多余的 bounding box 的预测结果，确保对一个目标只输出一个检测结果。<br>概率最大的 bounding box 被保留，且该 bounding box 周围的与它有较大交并比的 bounding box 会被抑制。<br>Each output prediction is:<br>\[<br>    \left[<br>    \begin{matrix}<br>    p_c \\\\<br>    b_x \\\\<br>    b_y \\\\<br>    b_w \\\\<br>    b_h<br>    \end{matrix}<br>    \right]<br>\]<br></p>
        </div>
        <a href="/2018/08/26/非最大值抑制/" class="read-more">Read More</a>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/26/目标定位-vs-目标检测/">
                目标定位 vs 目标检测
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-26</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>计算机视觉领域的不同任务：<br><img src="/2018/08/26/目标定位-vs-目标检测/cls.jpg" alt="classification"><br><img src="/2018/08/26/目标定位-vs-目标检测/other.jpg" alt="other task"><br></p>
        </div>
        <a href="/2018/08/26/目标定位-vs-目标检测/" class="read-more">Read More</a>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/13/消失的梯度/">
                消失的梯度
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-13</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>这篇博文的主要灵感是来自 sleebapaul 的 <a href="https://github.com/sleebapaul/vanishing_gradients" target="_blank" rel="external">vanishing gradients</a>，但是他的那篇博文存在大量的公式推导错误，因此主要借鉴了他的一些图片。</p>
<p>This is a discussion on an old problem that hindered the Machine Learning research for decades, now partially solved using various methods discovered in last 10 years. </p>
<center><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/vanishing_grad/neural_network_shallow.png" alt="neural_network_shallow"></center><br>
        </div>
        <a href="/2018/08/13/消失的梯度/" class="read-more">Read More</a>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/11/MobileNet-V1-and-V2-带来的卷积结构革命/">
                MobileNet V1 and V2 带来的卷积结构革命
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-11</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>主要总结了轻量级深度卷积神经网络 MobileNet V1 &amp; V2 的关键贡献 separable convolution 和 inverted resisual &amp; linear bottlenecks。</p>
<h3 id="MobileNet-V1"><a href="#MobileNet-V1" class="headerlink" title="MobileNet V1"></a>MobileNet V1</h3><p><a href="https://arxiv.org/abs/1704.04861" target="_blank" rel="external">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a><br>提出了<strong>可分离卷积结构（separable convolution）</strong>来代替传统的卷积结构，可以在很小的精度损失下有效地减少网络参数，适合于在移动端和嵌入式环境下构建轻量级深度卷积神经网络。</p>
<blockquote>
<p>A standard convolution both filters and combines inputs into a new set of outputs in one step. The depthwise separable convolution splits this into two layers, a separate layer for filtering and a separate layer for combining.</p>
<p>Depthwise separable convolution are made up of two layers: depthwise convolutions and pointwise convolutions. We use depthwise convolutions to apply a single filter per each input channel (input depth). Pointwise convolution, a simple 1×1 convolution, is then used to create a linear combination of the output of the depthwise layer. MobileNets use both batchnorm and ReLU nonlinearities for both layers.</p>
<p>MobileNet uses 3 × 3 depthwise separable convolutions which uses between 8 to 9 times less computation than standard convolutions at only a small reduction in accuracy.</p>
</blockquote>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/mobilenet/separable_convolution.png" alt="separable_convolution"><br></p>
        </div>
        <a href="/2018/08/11/MobileNet-V1-and-V2-带来的卷积结构革命/" class="read-more">Read More</a>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/09/卷积转置卷积关系在-TensorFLow-中的验证/">
                卷积转置卷积关系在 TensorFLow 中的验证
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-09</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>本文分别在 Numpy 和 TensorFlow 下实现了卷积和转置卷积的计算，并对卷积和转置卷积的参数关系进行了探讨。<br>本文代码的 Jupyter Notebook 可以在我的 <a href="https://github.com/RobertLexis/convolution_vs_transpose_convolution" target="_blank" rel="external">github 仓库</a>中找到。</p>
<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>正向传播：<br>\[<br>\mathbf{y} = \mathbf{C}\mathbf{x}<br>\]</p>
<h5 id="核及输入"><a href="#核及输入" class="headerlink" title="核及输入"></a>核及输入</h5><p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/transposeConvolution/convolution.gif" alt="convolution"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kernel = np.arange(1, 10).reshape((3, 3))</div></pre></td></tr></table></figure></p>
<p>\[<br>kernel =<br>\left[<br>    \begin{matrix}<br>    1 &amp; 2 &amp; 3 \\\\<br>    4 &amp; 5 &amp; 6 \\\\<br>    7 &amp; 8 &amp; 9<br>    \end{matrix}<br>\right]<br>\]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">C = np.array([[1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9, 0, 0, 0, 0, 0],</div><div class="line">              [0, 1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9, 0, 0, 0, 0],</div><div class="line">              [0, 0, 0, 0, 1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9, 0],</div><div class="line">              [0,  0, 0, 0, 0, 1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9]])</div></pre></td></tr></table></figure></p>
<p>\[<br>\mathbf{C} =<br>\left[<br>    \begin{matrix}<br>    1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\<br>    0 &amp; 1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\<br>    0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9 &amp; 0 \\\\<br>    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9<br>    \end{matrix}<br>\right]<br>\]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">input_ = np.arange(1, 17).reshape((4, 4))</div></pre></td></tr></table></figure></p>
<p>\[<br>input\_ =<br>\left[<br>    \begin{matrix}<br>    1 &amp; 2 &amp; 3 &amp; 4 \\\\<br>    5 &amp; 6 &amp; 7 &amp; 8 \\\\<br>    9 &amp; 10 &amp; 11 &amp; 12 \\\\<br>    13 &amp; 14 &amp; 15 &amp; 16<br>    \end{matrix}<br>\right]<br>\]<br></p>
        </div>
        <a href="/2018/08/09/卷积转置卷积关系在-TensorFLow-中的验证/" class="read-more">Read More</a>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/08/转置卷积-Transposed-Convolution/">
                转置卷积 Transposed Convolution
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-08</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>转置卷积在 Fully Convolutional Network (FCN) 结构的卷积神经网络中完成“上采样”。<br><strong>转置卷积</strong>与<strong>卷积</strong>在神经网络结构的正向和反向传播中正好做着相反的运算。</p>
<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>4x4 的输入（蓝色），3x3 的卷积核, 2x2 的输出为（绿色）。</p>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/transposeConvolution/convolution.gif" alt="convolution"></p>
<p>卷积操作过程可以如下计算： </p>
<p>输入矩阵展开为 \( 4 \times 4 = 16 \) 维（列）向量，记作 \( \mathbf{x} \)。 </p>
<p>输出矩阵展开为 \( 2 \times 2 = 4 \) 维（列）向量，记作 \( \mathbf{y} \)。 </p>
<p>卷积核扩展为如下的形式 \( \mathbf{C} \)，注意这个矩阵并不是<a href="https://en.wikipedia.org/wiki/Toeplitz_matrix" target="_blank" rel="external">托普利兹矩阵（Toeplitz matrix）</a>：</p>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/transposeConvolution/kernel.png" alt="kernel"><br></p>
        </div>
        <a href="/2018/08/08/转置卷积-Transposed-Convolution/" class="read-more">Read More</a>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/08/Nvidia-TensorRT-推理加速引擎支持的Layers/">
                Nvidia TensorRT 推理加速引擎支持的Layers
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-08</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h3 id="Supported-Operations-By-Framework"><a href="#Supported-Operations-By-Framework" class="headerlink" title="Supported Operations By Framework"></a>Supported Operations By Framework</h3><p>由<a href="https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#support_op" target="_blank" rel="external">TensorRT 开发者指南</a>可以得知，并不是 Keras 或者 TensorFlow 支持的操作都被 TensorRT 所支持。<br></p>
        </div>
        <a href="/2018/08/08/Nvidia-TensorRT-推理加速引擎支持的Layers/" class="read-more">Read More</a>
    

</div>
            
        </section>
    </div>
</div>



    <div class="row">
        <div class="col-sm-12">
            <div class="wrap-pagination">
                <a class="" href="/">
                    <i class="fa fa-chevron-left" aria-hidden="true"></i>
                </a>
                <a class="" href="/page/3/">
                    <i class="fa fa-chevron-right" aria-hidden="true"></i>
                </a>
            </div>
        </div>
    </div>




</div>

<!-- Footer -->
<div class="push"></div>

<footer class="footer-content">
    <div class="container">
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-6 col-lg-6 footer-about">
                <h2>About</h2>
                <p>
                    This is Robert Lexis (FengCun Li). To see the world, things dangerous to come to, to see behind walls, to draw closer, to find each other and to feel. That is the purpose of LIFE.
                </p>
            </div>
            
    <div class="col-xs-6 col-sm-6 col-md-3 col-lg-3 recent-posts">
        <h2>Recent Posts</h2>
        <ul>
            
            <li>
                <a class="footer-post" href="/2019/07/12/Unnamed-namespace/">Unnamed namespace</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2019/05/08/Static-variable-in-inlined-function/">Static variable in inline</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2019/04/23/Iterator-invalidation-rules/">Iterator invalidation rul</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2019/03/18/Emplace-back/">Emplace back</a>
            </li>
            
        </ul>
    </div>



            
        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <ul class="list-inline footer-social-icons">
                    
                    <li class="list-inline-item">
                        <a href="https://github.com/RobertLexis">
                            <span class="footer-icon-container">
                                <i class="fa fa-github"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    <li class="list-inline-item">
                        <a href="mailto:robert_lexis@163.com">
                            <span class="footer-icon-container">
                                <i class="fa fa-envelope-o"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                </ul>
            </div>
        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <div class="footer-copyright">
                    @Untitled. All right reserved | Robert Lexis Loves Wenny
                </div>
            </div>
        </div>
    </div>
</footer>

<!-- After footer scripts -->

<!-- jQuery -->
<script src="//code.jquery.com/jquery-2.1.4.min.js"></script>

<!-- Tween Max -->
<script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.5/TweenMax.min.js"></script>

<!-- Gallery -->
<script src="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.js" type="text/javascript" charset="utf-8"></script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script>

<!-- Custom JavaScript -->
<script src="/js/main.js"></script>

<!-- Disqus Comments -->



</body>

</html>