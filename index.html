<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!--Description-->
    

    <!--Author-->
    
        <meta name="author" content="Robert Lexis">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="This is Robert Lexis."/>
    

    <!--Open Graph Description-->
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content="This is Robert Lexis."/>

    <!--Type page-->
    
        <meta property="og:type" content="website" />
    

    <!--Page Cover-->
    

    <meta name="twitter:card" content="summary" />
    

    <!-- Title -->
    
    <title>This is Robert Lexis.</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.2/css/bootstrap.min.css" integrity="sha384-y3tfxAZXuh4HwSYylfB+J125MxIs6mR5FOHamPBG064zB+AFeWH94NdvaCBm8qnd" crossorigin="anonymous">

    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/style.css">

    <!-- Google Analytics -->
    


</head>


<body>

<div class="bg-gradient"></div>
<div class="bg-pattern"></div>

<!-- Menu -->
<!--Menu Links and Overlay-->
<div class="menu-bg">
    <div class="menu-container">
        <ul>
            
            <li class="menu-item">
                <a href="/">
                    Home
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/archives">
                    Archives
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/about.html">
                    About
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/tags">
                    Tags
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/categories">
                    Categories
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/contact.html">
                    Contact
                </a>
            </li>
            
        </ul>
    </div>
</div>

<!--Hamburger Icon-->
<nav>
    <a href="#menu"></a>
</nav>

<div class="container">

    <!-- Main Content -->
    <div class="row">
    <div class="col-sm-12">

        <!--Title and Logo-->
        <header>
    <div class="logo">
        <a href="/"><i class="logo-icon fa fa-cube" aria-hidden="true"></i></a>
        
            <h1 id="main-title" class="title">This is Robert Lexis.</h1>
        
    </div>
</header>

        <section class="main">
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/13/消失的梯度/">
                消失的梯度
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-13</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>这篇博文的主要灵感是来自 sleebapaul 的 <a href="https://github.com/sleebapaul/vanishing_gradients" target="_blank" rel="external">vanishing gradients</a>，但是他的那篇博文存在大量的公式推导错误，因此主要借鉴了他的一些图片。</p>
<p>This is a discussion on an old problem that hindered the Machine Learning research for decades, now partially solved using various methods discovered in last 10 years. </p>
<center><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/vanishing_grad/neural_network_shallow.png" alt="neural_network_shallow"></center>

<h3 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h3><p>\[<br>\begin{split}<br>    Z_1 &amp; = W_1 \times X \\\\<br>    A_1 &amp; = g(Z_1) \\\\<br>    Z_2 &amp; = W_2 \times A_1 \\\\<br>    A_2 &amp; = g(Z_2) \\\\<br>    Z_3 &amp; = W_3 \times A_2 \\\\<br>    A_3 &amp; = g(Z_3) \\\\<br>    J &amp; = \sum A_3 - y<br>\end{split}<br>\]<br>\( X \) \( Z_1 \) \( A_1 \) \( Z_2 \) \( A_2 \) \( Z_3 \) \( A_3\) \( y \) 都是列向量，这样的假设不仅适用于全连接神经网络，也适用于卷积神经网络，因为卷积运算也可以展开为这样的形式，具体的可以看我的另外一篇博文<a href="https://robertlexis.github.io/2018/08/08/转置卷积-Transposed-Convolution/" target="_blank" rel="external">转置卷积 Transposed Convolution</a>。</p>
<h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p>\( g \) 是激活函数，是 element-wise 地对输入进行激活的，因此其导数 \( g^\prime \) 也是 element-wise 地发挥作用的。<br>即 \( g(z) \)、\( g^\prime(z) \)、\( z \) 的 shape 是相同的。\( g^\prime(z) \) 在公式中与其他项是 element-wise 相乘（用 \( \cdot \) 表示）而不是矩阵相乘（用 \( \times \) 表示）。<br>\[<br>\begin{split}<br>    \frac{\partial J}{\partial J} &amp; = 1 \\\ <br>    \frac{\partial J}{\partial A_3} &amp; = \mathbf{1} \\\ <br>    \frac{\partial J}{\partial Z_3} &amp; = \frac{\partial J}{\partial A_3} \frac{\partial A_3}{\partial Z_3} \\\\<br>    &amp; = \mathbf{1} \cdot g^\prime(Z_3) \\\\<br>    \frac{\partial J}{\partial A_2} &amp; = \frac{\partial J}{\partial Z_3} \frac{\partial Z_3}{\partial A_2} \\\\<br>    &amp; = {W_3}^T \times (\mathbf{1} \cdot g^\prime(Z_3)) \\\\<br>    \frac{\partial J}{\partial Z_2} &amp; = \frac{\partial J}{\partial A_2} \frac{\partial A_2}{\partial Z_2} \\\\<br>    &amp; = ({W_3}^T \times (\mathbf{1} \cdot g^\prime(Z_3))) \cdot g^\prime(Z_2) \\\\<br>    \frac{\partial J}{\partial A_1} &amp; = \frac{\partial J}{\partial Z_2} \frac{\partial Z_2}{\partial A_1} \\\\<br>    &amp; = {W_2}^T \times (({W_3}^T \times (\mathbf{1} \cdot g^\prime(Z_3))) \cdot g^\prime(Z_2)) \\\\<br>    \frac{\partial J}{\partial Z_1} &amp; = \frac{\partial J}{\partial A_1} \frac{\partial A_1}{\partial Z_1} \\\\<br>    &amp; = ({W_2}^T \times (({W_3}^T \times (\mathbf{1} \cdot g^\prime(Z_3))) \cdot g^\prime(Z_2))) \cdot g^\prime(Z_1) \\\\<br>    \frac{\partial J}{\partial X} &amp; = \frac{\partial J}{\partial Z_1} \frac{\partial Z_1}{\partial X} \\\\<br>    &amp; = {W_1}^T \times (({W_2}^T \times (({W_3}^T \times (\mathbf{1} \cdot g^\prime(Z_3))) \cdot g^\prime(Z_2))) \cdot g^\prime(Z_1)) \\\\<br>\end{split}<br>\]</p>
<p><hr><br>\[<br>\begin{split}<br>    \frac{\partial J}{\partial W_3} &amp; = \frac{\partial J}{\partial Z_3} \frac{\partial Z_3}{\partial W_3} \\\\<br>    &amp; = \frac{\partial J}{\partial Z_3} \times {A_2}^T \\\\<br>    &amp; = (\mathbf{1} \cdot g^\prime(Z_3)) \times {A_2}^T \\\\<br>    &amp; = (\mathbf{1} \cdot g^\prime(Z_3)) \times g(W_2 \times g(W_1 \times X))^T \\\\<br>    \frac{\partial J}{\partial W_2} &amp; = \frac{\partial J}{\partial Z_2} \frac{\partial Z_2}{\partial W_2} \\\\<br>    &amp; = \frac{\partial J}{\partial Z_2} \times {A_1}^T \\\\<br>    &amp; = (({W_3}^T \times (\mathbf{1} \cdot g^\prime(Z_3))) \cdot g^\prime(Z_2)) \times {A_1}^T \\\\<br>    &amp; = (({W_3}^T \times (\mathbf{1} \cdot g^\prime(Z_3))) \cdot g^\prime(Z_2)) \times {g(W_1 \times X)}^T \\\\<br>    \frac{\partial J}{\partial W_1} &amp; = \frac{\partial J}{\partial Z_1} \frac{\partial Z_1}{\partial W_1} \\\\<br>    &amp; = \frac{\partial J}{\partial Z_1} \times {X}^T \\\\<br>    &amp; = (({W_2}^T \times (({W_3}^T \times (\mathbf{1} \cdot g^\prime(Z_3))) \cdot g^\prime(Z_2))) \cdot g^\prime(Z_1)) \times {X}^T<br>\end{split}<br>\]<br>We call this Chain rule in calculus.<br>Now, what is essentially “back propagated”? It’s the gradients which represents the rate at which the error changes with respect to the change of parameters in each layer! 即每一层参数的变化引起误差变化的大小，每一层参数的变化对误差变化的贡献。</p>
<h3 id="梯度弥散"><a href="#梯度弥散" class="headerlink" title="梯度弥散"></a>梯度弥散</h3><center><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/vanishing_grad/sigmoid.png" alt="sigmoid"></center>

<p>\[<br>\begin{split}<br>    {0.99}^3 &amp; = 0.970299 \\\\<br>    {0.99}^7 &amp; = 0.9320653479 \\\\<br>    {0.99}^{100} &amp; = 0.36603234127 \\\\<br>    {0.99}^{300} &amp; = 0.04904089407 \\\\<br>\end{split}<br>\]<br>As we propagate away from final layer, the perturbation on network output will not reach the layers, even if reaches, the gradient will be too feeble to make an update. This issue get worsened when number of layers increases. Very deep networks often have a gradient signal that goes to zero quickly because of this reason, thus making gradient descent unbearably slow. </p>
<p>More specifically, during gradient descent, as we backprop from the final layer back to the first layer, we are multiplying by the weight matrix on each step, and thus the gradient can decrease exponentially quickly to zero. Gradient based methods learn a parameter’s value by understanding how a small change in the parameter’s value will affect the network’s output. If a change in the parameter’s value causes very small change in the network’s output-the network just can’t learn the parameter effectively.</p>
<center><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/vanishing_grad/vanishing_grad.png" alt="vanishing_grad"></center>

<p><small>The speed of learning decreases very rapidly for the early layers as the network trains.</small></p>
<h3 id="改进措施"><a href="#改进措施" class="headerlink" title="改进措施"></a>改进措施</h3><h5 id="Initializing-the-weights-with-standard-techniques-like-Xavier-Intialization"><a href="#Initializing-the-weights-with-standard-techniques-like-Xavier-Intialization" class="headerlink" title="Initializing the weights with standard techniques like Xavier Intialization"></a>Initializing the weights with standard techniques like Xavier Intialization</h5><p>Initializing weights properly can reduce to some extend since the fact both too high or too low weights can result in exploding/vanishing gradients.</p>
<h5 id="The-curse-of-Sigmoids-and-Tanhs"><a href="#The-curse-of-Sigmoids-and-Tanhs" class="headerlink" title="The curse of Sigmoids and Tanhs"></a>The curse of Sigmoids and Tanhs</h5><p><center><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/vanishing_grad/sigmoid_derivative.png" alt="sigmoid_derivative"></center><br>Let’s make some observations from these graphs.</p>
<ol>
<li>Sigmoid is confined to the interval [0, 1], the output will be always between these interval for any input. If we consider to initialize the weights as big as say  [−400, 400], after the activation, that will a binay matrix. High values tend to 1 and low values to 0. This will make derivatives zero and thus vanishing gradients.</li>
<li>The maximum value of derivative of sigmoid function is 0.25. So by default, the input weights get \( {\frac{1}{4}}{th}\) of the original value on calculating the gradients.<br>Same are applicable to tanh which is an extended sigmoid.<br><strong>So the take away is don’t use them.</strong></li>
</ol>
<h5 id="Dying-ReLUs"><a href="#Dying-ReLUs" class="headerlink" title="Dying ReLUs"></a>Dying ReLUs</h5><p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/vanishing_grad/relu.png" alt="relu"></p>
<ol>
<li>ReLUs don’t suffer from limited interval problem like sigmoid. The minimum value is 0 but there is no limit for maximum value.</li>
<li>If the input value is less than zero, then output and derivative are zero.<br>This will eliminate all the negative inputs which is okay. But derivatives getting zero is a problem. This means, in the entire training, that neuron which can’t fire above zero will remain unlearned or dead.</li>
</ol>
<p>So, ReLU is also not the perfect solution, but provides a great relief.</p>
<h5 id="ResNets"><a href="#ResNets" class="headerlink" title="ResNets"></a>ResNets</h5><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/11/MobileNet-V1-and-V2-带来的卷积结构革命/">
                MobileNet V1 and V2 带来的卷积结构革命
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-11</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>主要总结了轻量级深度卷积神经网络 MobileNet V1 &amp; V2 的关键贡献 separable convolution 和 inverted resisual &amp; linear bottlenecks。</p>
<h3 id="MobileNet-V1"><a href="#MobileNet-V1" class="headerlink" title="MobileNet V1"></a>MobileNet V1</h3><p><a href="https://arxiv.org/abs/1704.04861" target="_blank" rel="external">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a><br>提出了<strong>可分离卷积结构（separable convolution）</strong>来代替传统的卷积结构，可以在很小的精度损失下有效地减少网络参数，适合于在移动端和嵌入式环境下构建轻量级深度卷积神经网络。</p>
<blockquote>
<p>A standard convolution both filters and combines inputs into a new set of outputs in one step. The depthwise separable convolution splits this into two layers, a separate layer for filtering and a separate layer for combining.</p>
<p>Depthwise separable convolution are made up of two layers: depthwise convolutions and pointwise convolutions. We use depthwise convolutions to apply a single filter per each input channel (input depth). Pointwise convolution, a simple 1×1 convolution, is then used to create a linear combination of the output of the depthwise layer. MobileNets use both batchnorm and ReLU nonlinearities for both layers.</p>
<p>MobileNet uses 3 × 3 depthwise separable convolutions which uses between 8 to 9 times less computation than standard convolutions at only a small reduction in accuracy.</p>
</blockquote>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/mobilenet/separable_convolution.png" alt="separable_convolution"><br><strong>可分离卷积结构可以替代标准卷积结构在各种各样的卷积神经网络中作为基础卷积结构，实现卷积神经网络的轻量化。</strong></p>
<h5 id="MobileNet-可分离卷积的官方实现（去掉关于-namescope-的代码）"><a href="#MobileNet-可分离卷积的官方实现（去掉关于-namescope-的代码）" class="headerlink" title="MobileNet 可分离卷积的官方实现（去掉关于 namescope 的代码）"></a>MobileNet 可分离卷积的官方实现（去掉关于 namescope 的代码）</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_separable_conv2d</span><span class="params">(input_tensor,</span></span></div><div class="line"><span class="function"><span class="params">                           num_outputs,</span></span></div><div class="line"><span class="function"><span class="params">                           normalizer_fn=None,</span></span></div><div class="line"><span class="function"><span class="params">                           stride=<span class="number">1</span>,</span></span></div><div class="line"><span class="function"><span class="params">                           rate=<span class="number">1</span>)</span>:</span></div><div class="line">    <span class="string">"""Separable mobilenet V1 style convolution.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Depthwise convolution, with default non-linearity (relu),</span></div><div class="line"><span class="string">    followed by 1x1 depthwise convolution.  This is similar to</span></div><div class="line"><span class="string">    slim.separable_conv2d, but differs in that it applies batch</span></div><div class="line"><span class="string">    normalization and non-linearity to depthwise. This  matches</span></div><div class="line"><span class="string">    the basic building of Mobilenet Paper</span></div><div class="line"><span class="string">    (https://arxiv.org/abs/1704.04861)</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Args:</span></div><div class="line"><span class="string">      input_tensor: input</span></div><div class="line"><span class="string">      num_outputs: number of outputs</span></div><div class="line"><span class="string">      normalizer_fn: which normalizer function to use for depthwise/pointwise</span></div><div class="line"><span class="string">      stride: stride</span></div><div class="line"><span class="string">      rate: output rate (also known as dilation rate)</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Returns:</span></div><div class="line"><span class="string">        output tesnor</span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    kernel_size = [<span class="number">3</span>, <span class="number">3</span>]</div><div class="line">    padding = <span class="string">'SAME'</span></div><div class="line">    <span class="comment"># 设置 num_outputs = None，即仅做 depthwise convoltion，而不做 slim.separable_conv2d 中的 pointwise convolution，然后依次使用了 normalizer_fn 和 slim.separable_conv2d 的默认非线性激活函数（relu），符合论文给出的卷积结构。</span></div><div class="line">    net = slim.separable_conv2d(</div><div class="line">        input_tensor,</div><div class="line">        num_outputs=<span class="keyword">None</span>,</div><div class="line">        kernel_size,</div><div class="line">        depth_multiplier=<span class="number">1</span>,</div><div class="line">        stride=stride,</div><div class="line">        rate=rate,</div><div class="line">        normalizer_fn=normalizer_fn,</div><div class="line">        padding=padding)</div><div class="line"></div><div class="line">    <span class="comment"># 进行 pointwise convolution，然后依次使用了 normalizer_fn 和 slim.separable_conv2d 的默认非线性激活函数（relu），符合论文给出的卷积结构。</span></div><div class="line">    net = slim.conv2d(</div><div class="line">        net,</div><div class="line">        num_outputs, [<span class="number">1</span>, <span class="number">1</span>],</div><div class="line">        stride=<span class="number">1</span>,</div><div class="line">        normalizer_fn=normalizer_fn)</div><div class="line">  <span class="keyword">return</span> net</div></pre></td></tr></table></figure>
<p>slim.separable_conv2d 和 slim.conv2d 的<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py" target="_blank" rel="external">官方文档</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">slim.separable_conv2d(</div><div class="line">    inputs,</div><div class="line">    num_outputs,</div><div class="line">    kernel_size,</div><div class="line">    depth_multiplier=<span class="number">1</span>,</div><div class="line">    stride=<span class="number">1</span>,</div><div class="line">    padding=<span class="string">'SAME'</span>,</div><div class="line">    data_format=DATA_FORMAT_NHWC,</div><div class="line">    rate=<span class="number">1</span>,</div><div class="line">    activation_fn=nn.relu,</div><div class="line">    normalizer_fn=<span class="keyword">None</span>,</div><div class="line">    normalizer_params=<span class="keyword">None</span>,</div><div class="line">    ...)</div><div class="line"><span class="number">1.</span> This op first performs a depthwise convolution that acts separately on</div><div class="line">channels, creating a variable called `depthwise_weights`. </div><div class="line"><span class="number">2.</span> If `num_outputs` <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>, it adds a pointwise convolution that mixes channels, creating a</div><div class="line">variable called `pointwise_weights`. </div><div class="line"><span class="number">3.</span> Then, <span class="keyword">if</span> `normalizer_fn` <span class="keyword">is</span> <span class="keyword">None</span>, it adds bias to the result, creating a variable called <span class="string">'biases'</span>, otherwise, the `normalizer_fn` <span class="keyword">is</span> applied. </div><div class="line"><span class="number">4.</span> It <span class="keyword">finally</span> applies an activation function to produce the end result.</div><div class="line"></div><div class="line">slim.conv2d</div><div class="line"><span class="number">1.</span> creates a variable called `weights`, representing the convolutional kernel, that <span class="keyword">is</span> convolved (actually cross-correlated) <span class="keyword">with</span> the `inputs`.</div><div class="line"><span class="number">2.</span> If a `normalizer_fn` <span class="keyword">is</span> provided (such <span class="keyword">as</span> `batch_norm`), it <span class="keyword">is</span> then applied. Otherwise, <span class="keyword">if</span></div><div class="line">`normalizer_fn` <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">and</span> a `biases_initializer` <span class="keyword">is</span> provided then a `biases`</div><div class="line">variable would be created <span class="keyword">and</span> added the activations. </div><div class="line"><span class="number">3.</span> Finally, <span class="keyword">if</span> `activation_fn` <span class="keyword">is</span> <span class="keyword">not</span> `<span class="keyword">None</span>`, it <span class="keyword">is</span> applied to the activations <span class="keyword">as</span> well.</div></pre></td></tr></table></figure></p>
<h3 id="MobileNet-V2"><a href="#MobileNet-V2" class="headerlink" title="MobileNet V2"></a>MobileNet V2</h3><p><a href="https://arxiv.org/abs/1801.04381" target="_blank" rel="external">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></p>
<blockquote>
<p>Main contribution:<br>A novel layer module: the inverted residual with linear bottleneck. This module takes as an input a low-dimensional compressed representation which is first expanded to high dimension and filtered with a lightweight depthwise convolution. Features are subsequently projected back to a low-dimensional representation with a <strong>linear convolution</strong>.<br>总结起来就是一句话，利用 MobileNet V1 提出的可分离卷积结构的变种（去掉可分离卷积结构中 pointwise 之后的 relu）作为基础卷积结构，对 residual block 的变种进行了“加速降参”。</p>
</blockquote>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/mobilenet/inverted_residual.png" alt="inverted_residual"><br><small>Diagonally hatched layers do not use non-linearities. The thickness of each block to indicate its relative number of channels. Note how classical residuals connects the layers with high number of channels, whereas the inverted residuals connect the bottlenecks. </small></p>
<ol>
<li>为什么输入和输出的通道数目都被限制在较小的值？<br> The manifolds of interest in neural networks could be embedded in low-dimensional subspaces.</li>
<li>为什么扩张通道数？<br> 由下图可以看出不应该在低维空间内应用 relu，因为会造成信息的丢失，而又需要 relu 提供非线性，就只能在扩张通道数（升维）之后再使用 relu。<blockquote>
<p>The bottlenecks actually contain all the necessary information, while an expansion layer acts merely as an implementation detail that accompanies a non-linear transformation of the tensor. </p>
</blockquote>
</li>
</ol>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/mobilenet/why_remove_relu.png" alt="why_remove_relu"></p>
<ol>
<li>为什么去掉可分离卷积结构中 pointwise 之后的 relu？<br>不应该在低维空间内应用 relu，因为会造成信息的丢失</li>
</ol>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/mobilenet/inverted_residual_1.png" alt="inverted_residual_1"></p>
<p><strong>Inverted Residuals 指中间通道多两头通道少，Linear Bottlenecks 指两头都是线性激活之后得到的 feature map。</strong></p>
<h5 id="Inverted-Residuals-and-Linear-Bottlenecks-的官方实现（去掉关于-namescope-的代码）"><a href="#Inverted-Residuals-and-Linear-Bottlenecks-的官方实现（去掉关于-namescope-的代码）" class="headerlink" title="Inverted Residuals and Linear Bottlenecks 的官方实现（去掉关于 namescope 的代码）"></a>Inverted Residuals and Linear Bottlenecks 的官方实现（去掉关于 namescope 的代码）</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_make_divisible</span><span class="params">(v, divisor)</span>:</span></div><div class="line">    min_value = divisor</div><div class="line">    new_v = max(min_value, int(v + divisor / <span class="number">2</span>) // divisor * divisor)</div><div class="line">    <span class="comment"># Make sure that round down does not go down by more than 10%.</span></div><div class="line">    <span class="keyword">if</span> new_v &lt; <span class="number">0.9</span> * v:</div><div class="line">        new_v += divisor</div><div class="line">    <span class="keyword">return</span> new_v</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">expand_input_by_factor</span><span class="params">(n, divisible_by=<span class="number">8</span>)</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="keyword">lambda</span> num_inputs, **_: _make_divisible(num_inputs * n, divisible_by)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">expanded_conv</span><span class="params">(input_tensor,</span></span></div><div class="line"><span class="function"><span class="params">                  num_outputs,</span></span></div><div class="line"><span class="function"><span class="params">                  expansion_size=expand_input_by_factor<span class="params">(<span class="number">6</span>)</span>,</span></span></div><div class="line"><span class="function"><span class="params">                  stride=<span class="number">1</span>,</span></span></div><div class="line"><span class="function"><span class="params">                  rate=<span class="number">1</span>,</span></span></div><div class="line"><span class="function"><span class="params">                  kernel_size=<span class="params">(<span class="number">3</span>, <span class="number">3</span>)</span>,</span></span></div><div class="line"><span class="function"><span class="params">                  normalizer_fn=None,</span></span></div><div class="line"><span class="function"><span class="params">                  depthwise_channel_multiplier=<span class="number">1</span>,</span></span></div><div class="line"><span class="function"><span class="params">                  padding=<span class="string">'SAME'</span>)</span>:</span></div><div class="line">    <span class="string">"""Depthwise Convolution Block with expansion.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Builds a composite convolution that has the following structure</span></div><div class="line"><span class="string">    expansion (1x1) -&gt; depthwise (kernel_size) -&gt; projection (1x1)</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Args:</span></div><div class="line"><span class="string">        input_tensor: input</span></div><div class="line"><span class="string">        num_outputs: number of outputs in the final layer.</span></div><div class="line"><span class="string">        expansion_size: the size of expansion, could be a constant or a callable.</span></div><div class="line"><span class="string">            If latter it will be provided 'num_inputs' as an input. For forward</span></div><div class="line"><span class="string">            compatibility it should accept arbitrary keyword arguments.</span></div><div class="line"><span class="string">            Default will expand the input by factor of 6.</span></div><div class="line"><span class="string">        stride: depthwise stride</span></div><div class="line"><span class="string">        rate: depthwise rate</span></div><div class="line"><span class="string">        kernel_size: depthwise kernel</span></div><div class="line"><span class="string">        normalizer_fn: batchnorm or otherwise</span></div><div class="line"><span class="string">        depthwise_channel_multiplier: depthwise channel multiplier:</span></div><div class="line"><span class="string">        padding: Padding type to use</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Returns:</span></div><div class="line"><span class="string">        Tensor of depth num_outputs</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    prev_depth = input_tensor.get_shape().as_list()[<span class="number">3</span>]</div><div class="line"></div><div class="line">    <span class="comment"># 设置 num_outputs = None，即仅做 depthwise convoltion，而不做 slim.separable_conv2d 中的 pointwise convolution，然后依次使用了 normalizer_fn 和 slim.separable_conv2d 的默认非线性激活函数（relu），符合论文给出的卷积结构。</span></div><div class="line">    depthwise_func = functools.partial(</div><div class="line">        slim.separable_conv2d,</div><div class="line">        num_outputs=<span class="keyword">None</span>,</div><div class="line">        kernel_size=kernel_size,</div><div class="line">        depth_multiplier=depthwise_channel_multiplier,</div><div class="line">        stride=stride,</div><div class="line">        rate=rate,</div><div class="line">        normalizer_fn=normalizer_fn,</div><div class="line">        padding=padding)</div><div class="line"></div><div class="line">    net = input_tensor</div><div class="line"></div><div class="line">    <span class="comment"># expand</span></div><div class="line">    <span class="keyword">if</span> callable(expansion_size):</div><div class="line">      inner_size = expansion_size(num_inputs=prev_depth)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">      inner_size = expansion_size</div><div class="line">    <span class="keyword">if</span> inner_size &gt; net.shape[<span class="number">3</span>]:</div><div class="line">        net = slim.conv2d(net, inner_size, [<span class="number">1</span>, <span class="number">1</span>], stride=<span class="number">1</span>, normalizer_fn=normalizer_fn, padding=padding)</div><div class="line"></div><div class="line">    <span class="comment"># separable convolution</span></div><div class="line">    net = depthwise_func(net)</div><div class="line">    net = slim.conv2d(net, num_outputs, [<span class="number">1</span>, <span class="number">1</span>], stride=<span class="number">1</span>, normalizer_fn=normalizer_fn, activation_fn=<span class="keyword">None</span>, padding=padding)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> residual <span class="keyword">and</span> stride == <span class="number">1</span> <span class="keyword">and</span> net.get_shape().as_list()[<span class="number">3</span>] == prev_depth: </div><div class="line">      net += input_tensor</div><div class="line">    <span class="keyword">return</span> net</div></pre></td></tr></table></figure>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/09/卷积转置卷积关系在-TensorFLow-中的验证/">
                卷积转置卷积关系在 TensorFLow 中的验证
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-09</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>本文分别在 Numpy 和 TensorFlow 下实现了卷积和转置卷积的计算，并对卷积和转置卷积的参数关系进行了探讨。<br>本文代码的 Jupyter Notebook 可以在我的 <a href="https://github.com/RobertLexis/convolution_vs_transpose_convolution" target="_blank" rel="external">github 仓库</a>中找到。</p>
<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>正向传播：<br>\[<br>\mathbf{y} = \mathbf{C}\mathbf{x}<br>\]</p>
<h5 id="核及输入"><a href="#核及输入" class="headerlink" title="核及输入"></a>核及输入</h5><p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/transposeConvolution/convolution.gif" alt="convolution"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kernel = np.arange(1, 10).reshape((3, 3))</div></pre></td></tr></table></figure></p>
<p>\[<br>kernel =<br>\left[<br>    \begin{matrix}<br>    1 &amp; 2 &amp; 3 \\\\<br>    4 &amp; 5 &amp; 6 \\\\<br>    7 &amp; 8 &amp; 9<br>    \end{matrix}<br>\right]<br>\]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">C = np.array([[1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9, 0, 0, 0, 0, 0],</div><div class="line">              [0, 1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9, 0, 0, 0, 0],</div><div class="line">              [0, 0, 0, 0, 1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9, 0],</div><div class="line">              [0,  0, 0, 0, 0, 1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9]])</div></pre></td></tr></table></figure></p>
<p>\[<br>\mathbf{C} =<br>\left[<br>    \begin{matrix}<br>    1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\<br>    0 &amp; 1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\<br>    0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9 &amp; 0 \\\\<br>    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9<br>    \end{matrix}<br>\right]<br>\]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">input_ = np.arange(1, 17).reshape((4, 4))</div></pre></td></tr></table></figure></p>
<p>\[<br>input\_ =<br>\left[<br>    \begin{matrix}<br>    1 &amp; 2 &amp; 3 &amp; 4 \\\\<br>    5 &amp; 6 &amp; 7 &amp; 8 \\\\<br>    9 &amp; 10 &amp; 11 &amp; 12 \\\\<br>    13 &amp; 14 &amp; 15 &amp; 16<br>    \end{matrix}<br>\right]<br>\]</p>
<h5 id="卷积-in-Numpy"><a href="#卷积-in-Numpy" class="headerlink" title="卷积 in Numpy"></a>卷积 in Numpy</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">x = input_.reshape((-1, 1))</div></pre></td></tr></table></figure>
<p>\[<br>\mathbf{x} =<br>\left[<br>    \begin{matrix}<br>    1 \\\ <br>    2 \\\ <br>    3 \\\ <br>    4 \\\\<br>    5 \\\ <br>    6 \\\ <br>    7 \\\ <br>    8 \\\\<br>    9 \\\ <br>    10 \\\ <br>    11 \\\ <br>    12 \\\\<br>    13 \\\ <br>    14 \\\ <br>    15 \\\ <br>    16<br>    \end{matrix}<br>\right]<br>\]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">y = C.dot(x)</div></pre></td></tr></table></figure></p>
<p>\[<br>\mathbf{y} =<br>\left[<br>    \begin{matrix}<br>    348 \\\\<br>    393 \\\\<br>    528 \\\\<br>    573<br>    \end{matrix}<br>\right]<br>\]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">y = y.reshape((2, 2))</div></pre></td></tr></table></figure></p>
<p>\[<br>\mathbf{y} =<br>\left[<br>    \begin{matrix}<br>    348 &amp; 393 \\\\<br>    528 &amp; 573<br>    \end{matrix}<br>\right]<br>\]</p>
<h5 id="卷积-in-TensorFlow"><a href="#卷积-in-TensorFlow" class="headerlink" title="卷积 in TensorFlow"></a>卷积 in TensorFlow</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">x = tf.expand_dims(tf.expand_dims(tf.constant(input_, dtype=tf.float32), axis=-1), axis=0)</div><div class="line">x.get_shape().as_list()</div><div class="line">[1, 4, 4, 1]</div><div class="line"></div><div class="line">kernel_conv = tf.expand_dims(tf.expand_dims(tf.constant(kernel, dtype=tf.float32), axis=-1), axis=-1)</div><div class="line">kernel_conv.get_shape().as_list()</div><div class="line">[3, 3, 1, 1]</div><div class="line"></div><div class="line">y = tf.nn.conv2d(x, kernel_conv, strides=(1, 1, 1, 1), padding=&apos;VALID&apos;)</div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">    print(y.eval()[0, :, :, 0])</div><div class="line">[[348. 393.]</div><div class="line"> [528. 573.]]</div></pre></td></tr></table></figure>
<h4 id="转置卷积"><a href="#转置卷积" class="headerlink" title="转置卷积"></a>转置卷积</h4><p>正向传播：<br>\[<br>\mathbf{y} = \mathbf{C}^T\mathbf{x}<br>\]</p>
<h5 id="核及输入-1"><a href="#核及输入-1" class="headerlink" title="核及输入"></a>核及输入</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kernel = np.arange(1, 10).reshape((3, 3))</div></pre></td></tr></table></figure>
<p>\[<br>kernel =<br>\left[<br>    \begin{matrix}<br>    1 &amp; 2 &amp; 3 \\\\<br>    4 &amp; 5 &amp; 6 \\\\<br>    7 &amp; 8 &amp; 9<br>    \end{matrix}<br>\right]<br>\]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">C = np.array([[1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9, 0, 0, 0, 0, 0],</div><div class="line">              [0, 1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9, 0, 0, 0, 0],</div><div class="line">              [0, 0, 0, 0, 1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9, 0],</div><div class="line">              [0,  0, 0, 0, 0, 1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9]])</div></pre></td></tr></table></figure></p>
<p>\[<br>\mathbf{C} =<br>\left[<br>    \begin{matrix}<br>    1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\<br>    0 &amp; 1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\<br>    0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9 &amp; 0 \\\\<br>    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9<br>    \end{matrix}<br>\right]<br>\]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">C_T = C.T</div></pre></td></tr></table></figure></p>
<p>\[<br>\mathbf{C}^T =<br>\left[<br>    \begin{matrix}<br>       1 &amp; 0 &amp; 0 &amp; 0 \\\\<br>       2 &amp; 1 &amp; 0 &amp; 0 \\\\<br>       3 &amp; 2 &amp; 0 &amp; 0 \\\\<br>       0 &amp; 3 &amp; 0 &amp; 0 \\\\<br>       4 &amp; 0 &amp; 1 &amp; 0 \\\\<br>       5 &amp; 4 &amp; 2 &amp; 1 \\\\<br>       6 &amp; 5 &amp; 3 &amp; 2 \\\\<br>       0 &amp; 6 &amp; 0 &amp; 3 \\\\<br>       7 &amp; 0 &amp; 4 &amp; 0 \\\\<br>       8 &amp; 7 &amp; 5 &amp; 4 \\\\<br>       9 &amp; 8 &amp; 6 &amp; 5 \\\\<br>       0 &amp; 9 &amp; 0 &amp; 6 \\\\<br>       0 &amp; 0 &amp; 7 &amp; 0 \\\\<br>       0 &amp; 0 &amp; 8 &amp; 7 \\\\<br>       0 &amp; 0 &amp; 9 &amp; 8 \\\\<br>       0 &amp; 0 &amp; 0 &amp; 9<br>    \end{matrix}<br>\right]<br>\]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">input_ = np.arange(1, 5).reshape((2, 2))</div></pre></td></tr></table></figure>
<p>\[<br>input\_ =<br>\left[<br>    \begin{matrix}<br>    1 &amp; 2  \\\\<br>    3 &amp; 4<br>    \end{matrix}<br>\right]<br>\]</p>
<h5 id="转置卷积-in-Numpy"><a href="#转置卷积-in-Numpy" class="headerlink" title="转置卷积 in Numpy"></a>转置卷积 in Numpy</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">x = input_.reshape((-1, 1))</div></pre></td></tr></table></figure>
<p>\[<br>\mathbf{x} =<br>\left[<br>    \begin{matrix}<br>    1\\\\<br>    2\\\\<br>    3\\\\<br>    4<br>    \end{matrix}<br>\right]<br>\]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">y = C_T.dot(x)</div><div class="line">y = y.reshape(4, 4)</div></pre></td></tr></table></figure>
<p>\[<br>\mathbf{y} =<br>\left[<br>    \begin{matrix}<br>     1 &amp;  4 &amp;  7 &amp;  6 \\\\<br>     7 &amp; 23 &amp; 33 &amp; 24 \\\\<br>     19 &amp; 53 &amp; 63 &amp; 42 \\\\<br>     21 &amp; 52 &amp; 59 &amp; 36<br>    \end{matrix}<br>\right]<br>\]</p>
<h5 id="转置卷积-in-TensorFlow"><a href="#转置卷积-in-TensorFlow" class="headerlink" title="转置卷积 in TensorFlow"></a>转置卷积 in TensorFlow</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">x =  tf.expand_dims(tf.expand_dims(tf.constant(input_, dtype=tf.float32), axis=-1), axis=0)</div><div class="line">x.get_shape().as_list()</div><div class="line">[1, 2, 2, 1]</div><div class="line"></div><div class="line">kernel_transpose_conv = tf.expand_dims(tf.expand_dims(tf.constant(kernel, dtype=tf.float32), axis=-1), axis=-1)</div><div class="line">kernel_transpose_conv.get_shape().as_list()</div><div class="line">[3, 3, 1, 1]</div><div class="line"></div><div class="line">y = tf.nn.conv2d_transpose(x, kernel_transpose_conv, output_shape=(1, 4, 4, 1), strides=(1, 1, 1, 1), padding=&apos;VALID&apos;)</div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">    print(y.eval()[0, :, :, 0])</div><div class="line">[[ 1.  4.  7.  6.]</div><div class="line"> [ 7. 23. 33. 24.]</div><div class="line"> [19. 53. 63. 42.]</div><div class="line"> [21. 52. 59. 36.]]</div></pre></td></tr></table></figure>
<p>这里选择参数值 <code>strides=(1, 1, 1, 1), padding=&#39;VALID&#39;</code> 是因为转置卷积过程<code>[2, 2] -&gt; [4, 4]</code>对应的卷积过程<code>[4, 4] -&gt; [2, 2]</code>（见第一部分）的 <code>strides=(1, 1, 1, 1), padding=&#39;VALID&#39;</code>，即转置卷积过程的参数是由自身对应的卷积过程的参数确定的，要想在 shape 上做到“逆”，两者的参数必须一致。<code>[2, 2] &lt;-&gt; [4, 4]</code>来回转换的参数需一致，包括 kernel 的shape。</p>
<p>假设 kernel shape <code>[3, 3]</code>，<code>conv2d_transpose</code> 的输入 shape <code>[2, 2]</code>，<code>strides=(1, 1, 1, 1)</code>，而 <code>padding=&#39;SAME&#39;</code>，是不可能得到 <code>output_shape=(1, 4, 4, 1)</code> 的，这是因为 <code>conv2d</code> 在<code>strides=(1, 1, 1, 1), padding=&#39;SAME&#39;</code>，kernel shape <code>[3, 3]</code>，输入是 <code>(1, 4, 4, 1)</code>时，得到的卷积结果 shape 是 <code>[4, 4]</code> ，而不是 <code>conv2d_transpose</code> 输入的 <code>[2, 2]</code>，即卷积操作的输出 shape 和转置卷积的输入 shape 不匹配，会导致 <code>conv2d_transpose</code> 报错。</p>
<h3 id="shape-计算"><a href="#shape-计算" class="headerlink" title="shape 计算"></a>shape 计算</h3><h5 id="卷积-1"><a href="#卷积-1" class="headerlink" title="卷积"></a>卷积</h5><p>padding == “SAME” （有 padding）<br>\[<br>    output\_shape[i] = ceil(input\_shape[i] / strides[i])<br>\]<br>padding == “VALID” （无 padding）<br>\[<br>    output\_shape[i] = ceil((input\_shape[i] - filter\_shape[i] + 1) * dilation\_rate[i] / strides[i])<br>\]</p>
<h5 id="转置卷积-1"><a href="#转置卷积-1" class="headerlink" title="转置卷积"></a>转置卷积</h5><p>\[<br>new\_rows = (rows - 1) \times strides[0] + kernel\_size[0] - 2 \times padding[0] + output\_padding[0]<br>\\\\<br>new\_cols = (cols - 1) \times strides[1] + kernel\_size[1] - 2 \times padding[1] + output\_padding[1]<br>\]</p>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/08/转置卷积-Transposed-Convolution/">
                转置卷积 Transposed Convolution
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-08</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>转置卷积在 Fully Convolutional Network (FCN) 结构的卷积神经网络中完成“上采样”。<br><strong>转置卷积</strong>与<strong>卷积</strong>在神经网络结构的正向和反向传播中正好做着相反的运算。</p>
<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>4x4 的输入（蓝色），3x3 的卷积核, 2x2 的输出为（绿色）。</p>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/transposeConvolution/convolution.gif" alt="convolution"></p>
<p>卷积操作过程可以如下计算： </p>
<p>输入矩阵展开为 \( 4 \times 4 = 16 \) 维（列）向量，记作 \( \mathbf{x} \)。 </p>
<p>输出矩阵展开为 \( 2 \times 2 = 4 \) 维（列）向量，记作 \( \mathbf{y} \)。 </p>
<p>卷积核扩展为如下的形式 \( \mathbf{C} \)，注意这个矩阵并不是<a href="https://en.wikipedia.org/wiki/Toeplitz_matrix" target="_blank" rel="external">托普利兹矩阵（Toeplitz matrix）</a>：</p>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/transposeConvolution/kernel.png" alt="kernel"> </p>
<h5 id="正向传播"><a href="#正向传播" class="headerlink" title="正向传播"></a>正向传播</h5><p>卷积神经网络的正向传播就转换为：<br>\[ \mathbf{y} = \mathbf{C} \mathbf{x} \]<br>左乘 \( \mathbf{C} \)。</p>
<h5 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h5><p>\[<br>\begin{split}<br>\frac{\partial loss}{\partial x_i} &amp; = \sum_{j}\frac{\partial loss}{\partial y_j}\frac{\partial y_j}{\partial x_i} \\\\<br>&amp; = \sum_{j}\frac{\partial loss}{\partial y_j}C_{j, i} \\\\<br>&amp; = C_{*, i}^{T}\frac{\partial loss}{\partial y}<br>\end{split}<br>\]<br>即<br>\[<br>\frac{\partial loss}{\partial x} = C^T\frac{\partial loss}{\partial y}<br>\]</p>
<p>左乘 \( C^T \)。</p>
<h3 id="转置卷积"><a href="#转置卷积" class="headerlink" title="转置卷积"></a>转置卷积</h3><blockquote>
<p>Transposed convolutions – also called fractionally strided convolutions or deconvolutions – work by swapping the forward and backward passes of a convolution.<a href="https://arxiv.org/pdf/1603.07285.pdf" target="_blank" rel="external"><font size="2">1</font></a></p>
<p>The term “deconvolution” is sometimes used in the literature, but we advocate against it on the grounds that a deconvolution is mathematically defined as the inverse of a convolution, which is different from a transposed convolution.<a href="https://arxiv.org/pdf/1603.07285.pdf" target="_blank" rel="external"><font size="2">1</font></a></p>
</blockquote>
<p>转置卷积核扩展为如下的形式 \( \mathbf{C} \)，注意这个矩阵并不是<a href="https://en.wikipedia.org/wiki/Toeplitz_matrix" target="_blank" rel="external">托普利兹矩阵（Toeplitz matrix）</a>：<br><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/transposeConvolution/kernel.png" alt="kernel"> </p>
<h5 id="正向传播-1"><a href="#正向传播-1" class="headerlink" title="正向传播"></a>正向传播</h5><p>\[ \mathbf{y} = \mathbf{C}^T \mathbf{x} \]<br>左乘 \( \mathbf{C}^T \)。</p>
<h5 id="反向传播-1"><a href="#反向传播-1" class="headerlink" title="反向传播"></a>反向传播</h5><p>\[<br>\begin{split}<br>\frac{\partial loss}{\partial x} &amp; = (C^T)^T\frac{\partial loss}{\partial y} \\\\<br>&amp; = C\frac{\partial loss}{\partial y}<br>\end{split}<br>\]<br>左乘 \( C \)。</p>
<p>综上，转置卷积不是逆卷积，在信号处理中逆卷积是输入经过卷积的信号，还原出经过卷积之前的原始信号的操作。而神经网络中卷积和逆卷积仅仅分别是对输入左乘\( \mathbf{C} \) 和 \( \mathbf{C}^T\) 。</p>
<h3 id="两者的联系"><a href="#两者的联系" class="headerlink" title="两者的联系"></a>两者的联系</h3><p>就像论文 <a href="https://arxiv.org/pdf/1603.07285.pdf" target="_blank" rel="external">A guide to convolution arithmetic for deep learning</a> 中讲到的，一个核定义了一个卷积操作，但是它是一个直接卷积（ direct convolution ）还是一个转置卷积（ transposed convolution ）取决于正向传播和反向传播是如何计算的。</p>
<blockquote>
<p>One way to put it is to note that the kernel defines a convolution, but whether it’s a direct convolution or a transposed convolution is determined by how the forward and backward passes are computed. </p>
<p>For instance, although the kernel \( \mathbf{w} \) defines a convolution whose forward and backward passes are computed by multiplying with \( \mathbf{C} \) and \( \mathbf{C}^T \) respectively, it also defines a transposed convolution whose forward and backward passes are computed by multiplying with \( \mathbf{C}^T \) and  \( (\mathbf{C}^T)^T = \mathbf{C} \) respectively.</p>
</blockquote>
<p>另外需要注意的一点是，总是可以通过一个直接卷积（ direct convolution ）来模拟一个转置卷积（ transposed convolution ），但是这种方式的一个缺点是通常会在输入中引入大量的零行和零列，导致计算效率的降低。</p>
<blockquote>
<p>Finally note that it is always possible to emulate a transposed convolution with a direct convolution. The disadvantage is that it usually involves adding many columns and rows of zeros to the input, resulting in a much less efficient implementation.</p>
</blockquote>
<h5 id="直接卷积模拟转置卷积"><a href="#直接卷积模拟转置卷积" class="headerlink" title="直接卷积模拟转置卷积"></a>直接卷积模拟转置卷积</h5><p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/transposeConvolution/transpose_convolution.gif" alt="transpose convolution"> </p>
<ol>
<li>对输入 \( \mathbf{x} \) (1)进行补零得到 \( \tilde{\mathbf{x}} \)；</li>
<li>对核 \( \mathbf{w} \) (2) 进行左右翻转上下翻转得到新的核 \( \tilde{\mathbf{w}} \) (3)；</li>
<li>利用核 \( \tilde{\mathbf{w}} \) 对  \( \tilde{\mathbf{x}} \) 进行卷积，如上面的动图所示。</li>
</ol>
<p>\[<br> \left\{<br> \begin{matrix}<br>   x_0 &amp; x_1 \\\\<br>   x_2 &amp; x_3<br>  \end{matrix}<br>  \right\}\tag{1}<br>\]<br>\[<br> \left\{<br> \begin{matrix}<br>   w_{00} &amp; w_{01} &amp; w_{02} \\\\<br>   w_{10} &amp; w_{11} &amp; w_{12} \\\\<br>   w_{20} &amp; w_{21} &amp; w_{22}<br>  \end{matrix}<br>  \right\}\tag{2}<br>\]<br>\[<br> \left\{<br> \begin{matrix}<br>   w_{22} &amp; w_{21} &amp; w_{20} \\\\<br>   w_{12} &amp; w_{11} &amp; w_{10} \\\\<br>   w_{02} &amp; w_{01} &amp; w_{00}<br>  \end{matrix}<br>  \right\}\tag{3}<br>\]</p>
<p>由图可以看出：</p>
<ol>
<li>\( y_0 = w_{00} \cdot x_0 \)</li>
<li>\( y_1 = w_{01} \cdot x_0 + w_{00} \cdot x_1 \)</li>
<li>\( y_2 = w_{02} \cdot x_0 + w_{01} \cdot x_1 \)</li>
<li>\( y_3 = w_{02} \cdot x_1 \)</li>
<li>以此类推</li>
</ol>
<p>在结果上等效于转置卷积的定义式：</p>
<p>\[<br> \left[<br> \begin{matrix}<br>   w_{00} &amp; 0      &amp; 0      &amp; 0      \\\\<br>   w_{01} &amp; w_{00} &amp; 0      &amp; 0      \\\\<br>   w_{02} &amp; w_{01} &amp; 0      &amp; 0      \\\\<br>   0      &amp; w_{02} &amp; 0      &amp; 0      \\\\<br>   w_{10} &amp; 0      &amp; w_{00} &amp; 0      \\\\<br>   w_{11} &amp; w_{10} &amp; w_{01} &amp; w_{00} \\\\<br>   w_{12} &amp; w_{11} &amp; w_{02} &amp; w_{01} \\\\<br>   0      &amp; w_{12} &amp; 0      &amp; w_{02} \\\\<br>   w_{20} &amp; 0      &amp; w_{10} &amp; 0      \\\\<br>   w_{21} &amp; w_{20} &amp; w_{11} &amp; w_{10} \\\\<br>   w_{22} &amp; w_{21} &amp; w_{12} &amp; w_{11} \\\\<br>   0      &amp; w_{22} &amp; 0      &amp; w_{12} \\\\<br>   0      &amp; 0      &amp; w_{20} &amp; 0      \\\\<br>   0      &amp; 0      &amp; w_{21} &amp; w_{20} \\\\<br>   0      &amp; 0      &amp; w_{22} &amp; w_{21} \\\\<br>   0      &amp; 0      &amp; 0      &amp; w_{22}<br>  \end{matrix}<br>  \right]<br>  \cdot<br>  \left[<br>  \begin{matrix}<br>   x_0 \\\\<br>   x_1 \\\\<br>   x_2 \\\\<br>   x_3<br>  \end{matrix}<br>  \right]<br>\]</p>
<p><font size="2">[1] A guide to convolution arithmetic for deep learning</font></p>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/08/Nvidia-TensorRT-推理加速引擎支持的Layers/">
                Nvidia TensorRT 推理加速引擎支持的Layers
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-08</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h3 id="Supported-Operations-By-Framework"><a href="#Supported-Operations-By-Framework" class="headerlink" title="Supported Operations By Framework"></a>Supported Operations By Framework</h3><p>由<a href="https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#support_op" target="_blank" rel="external">TensorRT 开发者指南</a>可以得知，并不是 Keras 或者 TensorFlow 支持的操作都被 TensorRT 所支持。<br>截止目前[2018/08/08]，TensorRT 支持的 TensorFlow 操作有：</p>
<ul>
<li>Placeholder</li>
<li>Const</li>
<li>Add, Sub, Mul, Div, Minimum and Maximum</li>
<li>BiasAdd</li>
<li>Negative, Abs, Sqrt, Rsqrt, Pow, Exp and Log</li>
<li>FusedBatchNorm</li>
<li>ReLU, TanH, Sigmoid</li>
<li>SoftMax</li>
<li>Mean</li>
<li>ConcatV2</li>
<li>Reshape</li>
<li>Transpose</li>
<li>Conv2D</li>
<li>DepthwiseConv2dNative</li>
<li>ConvTranspose2D</li>
<li>MaxPool</li>
<li>AvgPool</li>
<li>Pad is supported if followed by one of these TensorFlow layers: Conv2D, DepthwiseConv2dNative, MaxPool, and AvgPool</li>
</ul>
<p>在项目实践中，Keras 的 <code>Lambda</code> 和 <code>UpSampling2D</code>（底层是 TensorFlow 的 <code>tf.image.resize_nearest_neighbor -&gt; tensorflow::ops::ResizeNearestNeighbor</code>）并不被 TensorRT 所支持，这在实现 Stacked Hourglass Networks 时造成了困难。特别是 <code>Lambda</code>层 ，在 frozen graph 到 uff 的转化过程中，由于 UFFParser 不能正确地解析 <code>Lambda</code> 层的输入，从而不能正确地对 frozen graph 计算图进行广度优先遍历（使用队列数据结构）转化操作节点，造成解析过程错误中断。至于上采样，目前是使用 <code>Conv2DTranspose</code> 完成的，这样相较于 <code>UpSampling2D</code> 会增加一部分可训练参数，使模型变得“更重”。</p>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/08/OpenCV-Python-C-与Scikit-image在BGR-RGB转灰度图上的不同/">
                OpenCV(Python & C++)与Scikit-image在BGR/RGB转灰度图上的不同
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-08</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>将主机 Python 环境下训练的卷积神经网络模型移植到 Jetson TX2 的 TensorRT 加速环境（C++）下时，遇到了模型精度损失的问题，发现是由于 Python Scikit-image 中函数 <code>color.rgb2gray</code> 与 C++ OpenCV 中函数 <code>cv::cvtColor(cv::InputArray src, cv::OutputArray dst, cv::COLOR_BGR2GRAY)</code> 的彩色图转灰度图的转换函数定义不同，分别如下：</p>
<h3 id="OpenCV"><a href="#OpenCV" class="headerlink" title="OpenCV"></a>OpenCV</h3><p>\[ Y = 0.299 \times R + 0.587 \times G + 0.114 \times B \]</p>
<h3 id="Scikit-image"><a href="#Scikit-image" class="headerlink" title="Scikit-image"></a>Scikit-image</h3><p>\[ Y = 0.2125 \times R + 0.7154 \times G + 0.0721 \times B \]</p>
<h3 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h3><p>由于模型训练时，RGB 转灰度图的预处理是由 Scikit-image  <code>color.rgb2gray</code> 完成的，因此在将模型部署到 Jetson TX2 时使用 C++ OpenCV 时，需要按照 Scikit-image <code>color.rgb2gray</code> 的公式自主实现 RGB 转灰度图，而不是直接使用 OpenCV 的 <code>cv::cvtColor(cv::InputArray src, cv::OutputArray dst, cv::COLOR_BGR2GRAY)</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">cv::Mat skimageBGR2GRAY(const cv::Mat &amp; img) &#123;</div><div class="line">    cv::Mat image;</div><div class="line">    if (img.type() != CV_32FC3) &#123;</div><div class="line">        img.convertTo(image, CV_32FC3);</div><div class="line">    &#125;</div><div class="line">    else &#123;</div><div class="line">        image = img;</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    std::vector&lt;cv::Mat&gt; channels;</div><div class="line">    cv::split(image, channels);</div><div class="line">    cv::Mat B = channels.at(0);</div><div class="line">    cv::Mat G = channels.at(1);</div><div class="line">    cv::Mat R = channels.at(2);</div><div class="line">    cv::Mat grayImage = (0.0721 * B + 0.7154 * G + 0.2125 * R) / 255;</div><div class="line">    </div><div class="line">    return grayImage;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上面的代码首先进行了 <code>cv::Mat</code> 元素数据类型转换，将由 <code>cv::imread(imageFilename, CV_LOAD_IMAGE_COLOR)</code> 读取到的 <code>CV_8UC3</code> 矩阵转换为 <code>CV_32FC3</code>，避免在计算过程中由于数据类型的截断造成精度的损失，由此得到的 <code>grayImage</code> 的元素数据类型为 <code>CV_32FC1</code>，取值范围<code>[0, 1]</code>。</p>
<p>这里需要注意的是，以下函数</p>
<ul>
<li><code>cv2.imread</code></li>
<li><code>cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</code></li>
<li><code>cv::imread(imageFilename, CV_LOAD_IMAGE_COLOR)</code></li>
<li><code>cv::cvtColor(cv::InputArray src, cv::OutputArray dst, cv::COLOR_BGR2GRAY)</code></li>
<li><code>skimage.io.imread</code></li>
<li><code>skimage.color.rgb2gray</code></li>
</ul>
<p>的结果的数据类型，可能发生的数据类型隐式转换和数据类型截断会影响到计算精度。</p>
<p><code>cv2.imread</code>，<code>cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</code>，<code>cv::imread(imageFilename, CV_LOAD_IMAGE_COLOR)</code>，<code>cv::cvtColor(cv::InputArray src, cv::OutputArray dst, cv::COLOR_BGR2GRAY)</code> 结果的数据类型是 <code>uint8</code> ，取值范围是 [0, 255]。<br><code>skimage.io.imread</code> 结果的数据类型是 <code>uint8</code>，取值范围是 [0, 255]；<code>skimage.color.rgb2gray</code> 结果的数据类型是 <code>float64</code>，取值范围是 <code>[0, 1]</code>。</p>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/03/TensorRT-加速-Keras-模型在-Jetson-上的推理/">
                TensorRT 加速 Keras 模型在 Jetson 上的推理
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-03</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>将一个训练好的 Keras 模型通过 TensorRT 加速并 Push 到 Jetson TX2 上的流程框图如下：<br><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/tensorRT/flowchart.png" alt="flowchart"><br>下面对一些关键代码及步骤进行解释：</p>
<h3 id="Keras-model-to-Tensorflow-frozen-graph"><a href="#Keras-model-to-Tensorflow-frozen-graph" class="headerlink" title="Keras model to Tensorflow frozen graph"></a>Keras model to Tensorflow frozen graph</h3><p>这一步可以在任意一台机器上完成，不限于 Jetson TX2 或者其 Host PC 上，只要配置了 tensorflow 和 keras 即可。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> model_from_json</div><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</div><div class="line"><span class="keyword">import</span> os </div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">keras_to_frozen</span><span class="params">(model_file, weights_file)</span>:</span></div><div class="line">    <span class="comment"># load keras model and weights</span></div><div class="line">    <span class="keyword">with</span> open(model_file, <span class="string">'r'</span>) <span class="keyword">as</span> f:</div><div class="line">        json_string = f.read()</div><div class="line">    K.set_learning_phase(<span class="number">0</span>)</div><div class="line">    </div><div class="line">    model = model_from_json(json_string)</div><div class="line">    model.load_weights(weights_file)</div><div class="line"></div><div class="line">    <span class="comment"># rename output nodes</span></div><div class="line">    output_node_prefix = <span class="string">'output_node_'</span></div><div class="line">    output_node_names = []</div><div class="line">    output_nodes = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(model.outputs)):</div><div class="line">        output_node_name = output_node_prefix + str(i)</div><div class="line">        output_nodes.append(tf.identity(model.outputs[i],  name=output_node_name))</div><div class="line">        output_node_names.append(output_node_name)</div><div class="line">    print(<span class="string">'output node names are: '</span>, output_node_names)</div><div class="line"></div><div class="line">    <span class="comment"># freeze the graph</span></div><div class="line">    sess = K.get_session()</div><div class="line">    constant_graph = tf.graph_util.convert_variables_to_constants(sess=sess, </div><div class="line">                                                              input_graph_def=sess.graph.as_graph_def(), </div><div class="line">                                                              output_node_names=output_node_names)</div><div class="line">    <span class="comment"># write graph as pb</span></div><div class="line">    output_dir = <span class="string">'frozen_graph'</span></div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(output_dir):</div><div class="line">        os.mkdir(output_dir)</div><div class="line">    filename = <span class="string">'model.pb'</span></div><div class="line">    <span class="keyword">return</span> tf.train.write_graph(constant_graph, output_dir, filename, as_text=<span class="keyword">False</span>)</div></pre></td></tr></table></figure></p>
<p>代码的关键要点：</p>
<ol>
<li><code>K.set_learning_phase(0)</code> 将学习阶段设置为 0， 即 test 阶段，像 <code>BatchNormalization</code> 这种 layer 在 test 阶段和 train 阶段的行为是不一样的。</li>
<li><code>tf.graph_util.convert_variables_to_constants</code> 将变量转换为常量，这一步使得我们可以用一个文件完全地（fully）表达一个神经网络，即如果不做这一步的话，<code>tf.train.write_graph</code> 写到文件里的仅仅有网络结构而没有相应的训练得到的权重参数。</li>
</ol>
<h3 id="Tensorflow-frozen-graph-to-UFF"><a href="#Tensorflow-frozen-graph-to-UFF" class="headerlink" title="Tensorflow frozen graph to UFF"></a>Tensorflow frozen graph to UFF</h3><p>就目前[2018/08/03]来说，NVCaffe 框架搭建的神经网络可以直接被导入并转化为推理引擎，来自其他框架的神经网络模型可以转化为 UFF 或者 ONNX 格式，然后通过相应的解析器解析成推理引擎。</p>
<p>将 Tensorflow frozen graph 转化为 UFF 文件，需要安装 uff Python 包。<br>这一步可以在 Jetson TX2 或者其 Host PC 上完成，只要安装了 uff 包即可。</p>
<p>uff 包是 TensorRT 3.0.4 for Ubuntu 16.04 and CUDA 9.0 tar package 的一部分，因此需要下载这个 tar 包，同时这个 tar 包也可以用来安装 TensorRT，由于已经通过 JetPack 在 Jetson TX2 上安装了 TensorRT，这一点可以在上一篇文章<a href="https://robertlexis.github.io/2018/08/01/Nvidia-Jetson-TX2-开箱及刷机/" target="_blank" rel="external">Nvidia Jetson TX2 开箱及刷机</a>或者下图中看到，因此我在这里仅取用安装其中的 uff。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tar -xzf TensorRT-3.0.4.Ubuntu-16.04.3.x86_64.cuda-9.0.cudnn7.0.tar.gz</div><div class="line">sudo pip install TensorRT-3.0.4/uff/uff-0.2.0-py2.py3-none-any.whl</div></pre></td></tr></table></figure></p>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/tensorRT/installed.png" alt="installed"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> uff</div><div class="line"><span class="comment"># generate uff from frozen graph</span></div><div class="line">uff_model = uff.from_tensorflow_frozen_model(</div><div class="line">    frozen_file=frozen_graph_filename,</div><div class="line">    output_nodes=output_node_names,</div><div class="line">    output_filename=uff_model_filename,</div><div class="line">    text=<span class="keyword">False</span>,</div><div class="line">)</div></pre></td></tr></table></figure>
<h3 id="UFF-to-plan-engine"><a href="#UFF-to-plan-engine" class="headerlink" title="UFF to plan (engine)"></a>UFF to plan (engine)</h3><p>这一步在安装了 TensorRT 的机器上完成，在此文章中为 Jetson TX2。<br>这一步可以参考 Nvidia <a href="https://developer.nvidia.com/embedded/twodaystoademo" target="_blank" rel="external">Two Days to a Demo</a> Advanced - TensorFlow to TensorRT Image Classification 的 <a href="https://github.com/NVIDIA-Jetson/tf_to_trt_image_classification" target="_blank" rel="external">github 仓库</a> 中的 <code>src/uff_to_plan.cpp</code>。<br>但是需要注意的是，该文件的 71 行方法调用存在错误：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">parser-&gt;registerInput(inputName.c_str(), DimsCHW(<span class="number">3</span>, inputHeight, inputWidth));</div></pre></td></tr></table></figure></p>
<p>编译时报错：<br><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/tensorRT/error1.png" alt="error_1"><br><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/tensorRT/error2.png" alt="error_2"><br>去 <code>/usr/include/aarch64-linux-gnu/NvUffParser.h</code> 查看函数声明，发现需要一个 <code>UffInputOrder</code> 类型的参数:<br><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/tensorRT/method_prototype.png" alt="error_2"><br>在这个头文件内搜索可以找到 <code>UffInputOrder</code> 这一个枚举类型:<br><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/tensorRT/enum.png" alt="error_2"></p>
<p>修改 <code>src/uff_to_plan.cpp</code> 的行 71 为<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">parser-&gt;registerInput(inputName.c_str(), DimsCHW(<span class="number">3</span>, inputHeight, inputWidth), UffInputOrder::kNHWC);</div></pre></td></tr></table></figure></p>
<p>即可。</p>
<h3 id="predict-cu"><a href="#predict-cu" class="headerlink" title="predict.cu"></a>predict.cu</h3><p>这一步在安装了 TensorRT 的机器上完成，在此文章中为 Jetson TX2，即在 Jetson TX2 完成 <code>.cu</code> 文件的编译。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fstream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sstream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;NvInfer.h&gt;</span></span></div><div class="line"></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> nvinfer1;</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Logger</span> :</span> <span class="keyword">public</span> ILogger</div><div class="line">&#123;</div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">log</span><span class="params">(Severity severity, <span class="keyword">const</span> <span class="keyword">char</span> * msg)</span> override</span></div><div class="line"><span class="function">  </span>&#123;</div><div class="line">    <span class="keyword">if</span> (severity != Severity::kINFO)</div><div class="line">      <span class="built_in">cout</span> &lt;&lt; msg &lt;&lt; <span class="built_in">endl</span>;</div><div class="line">  &#125;</div><div class="line">&#125; gLogger;</div><div class="line"></div><div class="line"><span class="comment">/* load the engine */</span></div><div class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"Loading TensorRT engine from plan file..."</span> &lt;&lt; <span class="built_in">endl</span>;</div><div class="line"></div><div class="line"><span class="function">ifstream <span class="title">planFile</span><span class="params">(planFilename)</span></span>; </div><div class="line"><span class="keyword">if</span> (!planFile.is_open())</div><div class="line">&#123;</div><div class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"Could not open plan file."</span> &lt;&lt; <span class="built_in">endl</span>;</div><div class="line">    <span class="keyword">return</span> <span class="number">1</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="built_in">stringstream</span> planBuffer;</div><div class="line">planBuffer &lt;&lt; planFile.rdbuf();</div><div class="line"><span class="built_in">string</span> plan = planBuffer.str();</div><div class="line"></div><div class="line">IRuntime *runtime = createInferRuntime(gLogger);</div><div class="line">ICudaEngine *engine = runtime-&gt;deserializeCudaEngine((<span class="keyword">void</span>*)plan.data(), plan.size(), <span class="literal">nullptr</span>);</div></pre></td></tr></table></figure>
        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/01/Nvidia-Jetson-TX2-开箱及刷机/">
                Nvidia Jetson TX2 开箱及刷机
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-01</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>钱学森实验室购买了 Nvidia <a href="https://developer.nvidia.com/embedded-computing" target="_blank" rel="external">Jetson</a> TX2 支持嵌入式 AI 开发。</p>
<blockquote>
<p>Jetson, the Platform for AI at the Edge<br>NVIDIA Jetson with GPU-accelerated parallel processing is the world’s leading embedded AI computing platform. The Jetson portfolio of devices, featuring the new NVIDIA Jetson TX2, delivers more performance and features for Artificial Intelligence at the edge. Devices at the edge, from drones to intelligent cameras, need on-board AI to process complex data without relying on network connectivity. AI at the Edge is the future of industry, transforming processes in manufacturing, industrial inspection, agriculture, general robotics, security, and AI cities.</p>
</blockquote>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/jetson/Jetson.jpeg" alt="Jetson"><br><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/jetson/Jetson_1.jpeg" alt="Jetson"></p>
<h3 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h3><p>NVIDIA Tegra Linux Driver Package – L4T 28.2.1 <a href="https://developer.nvidia.com/embedded/linux-tegra" target="_blank" rel="external">Linux For Tegra</a> 是为支持 Jetson 平台上的开发而设计的。<br>通过 <code>uname -a</code> 查看到的信息是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Linux tegra-ubuntu 4.4.38-tegra #1 SMP PREEMPT Thu May 17 00:15:19 PDT 2018 aarch64 aarch64 aarch64 GNU/Linux</div></pre></td></tr></table></figure></p>
<p>可以看出系统适配的是 aarch 处理器架构，而不是通常的 x86_64 架构。<br>L4T 28.2.1 支持的 Jetson 平台是 NVIDIA &#174; Tegra &#174; X2 series (Jetson TX2, Jetson TX2i)</p>
<p>L4T 28.2.1 System Requirements </p>
<ul>
<li>Host PC running Ubuntu Linux version 16.04 is recommended.</li>
<li>Tegra Linux Driver Package providing a kernel image, bootloader, NVIDIA drivers, and flashing utilities. </li>
</ul>
<h3 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h3><p><a href="https://www.nvidia.com/object/tegra.html" target="_blank" rel="external">Tegra</a> The World’s Fastest Mobile Processors.<br>Tegra ARM based processors.</p>
<h3 id="JetPack"><a href="#JetPack" class="headerlink" title="JetPack"></a>JetPack</h3><p>NVIDIA <a href="https://developer.nvidia.com/embedded/jetpack" target="_blank" rel="external">JetPack</a> SDK is the most comprehensive solution for building AI applications. Use the JetPack installer to flash your Jetson Developer Kit with <strong>the latest OS image</strong>, to install developer tools for both <strong>host PC</strong> and <strong>Developer Kit</strong>, and to install the libraries and APIs, samples, and documentation needed to jumpstart your development environment.</p>
<p>JetPack bundles all the Jetson platform software, including <a href="https://developer.nvidia.com/tensorrt" target="_blank" rel="external">TensorRT</a>, cuDNN, CUDA Toolkit, VisionWorks, GStreamer, and OpenCV, all built <strong>on top of L4T with LTS Linux kernel</strong>.</p>
<p>在<strong>主机 host PC</strong> 上下载安装 JetPack 3.3, JetPack 3.3 contains CUDA toolkit for the host (Ubuntu) and target platform, the latest NVIDIA Developer Tools (Tegra Graphics Debugger 2.5 and NVIDIA System Profiler 4.0), VisionWorks 1.6, cuDNN v7.1.5, Multimedia API v28.2, OpenCV 3.3.1, and TensorRT 4.0 GA.<a href="https://developer.nvidia.com/embedded/jetpack-notes" target="_blank" rel="external">JetPack Release Notes</a></p>
<p>JetPack 3.3 对主机的要求是 Ubuntu Linux x64 v16.04，对目标平台（Target Platform）的要求是 Jetson Developer Kit with Jetson TX2, Jetson TX2i, or Jetson TX1 module。</p>
<p>另外也需要一根以太网网线，An Ethernet cable plugged into the on-board Ethernet port, which is connected to either a secondary network card on your Linux host or the same network router providing Internet access for the Linux host.</p>
<p>JetPack 3.3 启动之后会下载所需的各种软件包，目前[2018/08/02]下载这些软件包需要主机 host PC 能够翻墙，可在 Ubuntu 下安装 ShadowSocks 客户端并配合 privoxy 连接 VPN 服务器实现翻墙，需要 VPN 服务器的可以联系我进行借用。</p>
<ol>
<li><p><code>sudo pip install shadowsocks</code></p>
</li>
<li><p>shawdowsocks.json</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&#123; </div><div class="line">&quot;server&quot;: &quot;_._._._&quot;, </div><div class="line">&quot;server_port&quot;: _, </div><div class="line">&quot;local_port&quot;: 1080, </div><div class="line">&quot;password&quot;: &quot;_&quot;, </div><div class="line">&quot;timeout&quot;: 600, </div><div class="line">&quot;method&quot;: &quot;aes-256-cfb&quot; </div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p><code>sudo sslocal -c shawdowsocks.json -d start</code></p>
</li>
<li><p>安装配置 privoxy。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install privoxy</div><div class="line"></div><div class="line">sudo vim /etc/privoxy/config</div><div class="line"></div><div class="line">1336行处 ：forward-socks5t / 127.0.0.1:1080 .</div><div class="line">sudo service privoxy start</div></pre></td></tr></table></figure>
</li>
<li><p>设置 http 和 https 全局代理 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export http_proxy=&apos;http://localhost:8118&apos;</div><div class="line">export https_proxy=&apos;https://localhost:8118&apos;</div></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wget www.google.com</div></pre></td></tr></table></figure>
</li>
</ol>
<p>JetPack 安装图示参考<a href="https://docs.nvidia.com/jetpack-l4t/index.html#jetpack/3.3/install.htm" target="_blank" rel="external">官方文档</a>。</p>
<h3 id="NVIDIA-TensorRT"><a href="#NVIDIA-TensorRT" class="headerlink" title="NVIDIA TensorRT"></a>NVIDIA <a href="https://developer.nvidia.com/tensorrt" target="_blank" rel="external">TensorRT</a></h3><p>Programmable Inference Accelerator (可编程推理加速器)<br>NVIDIA TensorRT is a high-performance deep learning <strong>inference</strong>(只有推理，NOT for Training) optimizer and runtime that delivers low latency and high-throughput for deep learning inference applications. With TensorRT, you can optimize neural network models, calibrate for lower precision with high accuracy, and finally deploy the models to hyperscale data centers, embedded, or automotive product platforms. TensorRT-based applications on GPUs perform up to 100x faster than CPU during inference for models trained in all major frameworks.</p>
<p>TensorRT provides INT8 and FP16 optimizations for production deployments of deep learning inference applications such as video streaming, speech recognition, recommendation and natural language processing. Reduced precision inference significantly lowers application latency, which is a requirement for many real-time services as well as auto and embedded applications.</p>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/jetson/TRT.png" alt="TRT"><br>You can import trained models from every deep learning framework into TensorRT. After applying optimizations, TensorRT selects platform specific kernels to maximize performance on Tesla GPUs in the datacenter, Jetson embedded platforms, and NVIDIA DRIVE autonomous driving platforms. </p>
<p>With TensorRT developers can focus on creating novel AI-powered applications rather than performance tuning for inference deployment.<br>关于使用详情，<a href="https://docs.nvidia.com/deeplearning/sdk/" target="_blank" rel="external">NVIDIA Deep Learning SDK</a>，<a href="https://devblogs.nvidia.com/deploying-deep-learning-nvidia-tensorrt/" target="_blank" rel="external">Deploying Deep Neural Networks with NVIDIA TensorRT</a>。</p>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/07/26/Stacked-Hourglass-Networks-卫星部件检测/">
                Stacked Hourglass Networks 卫星部件检测
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-07-26</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h3 id="STACKED-HOURGLASS-NETWORKS"><a href="#STACKED-HOURGLASS-NETWORKS" class="headerlink" title="STACKED HOURGLASS NETWORKS"></a>STACKED HOURGLASS NETWORKS</h3><p><a href="http://www-personal.umich.edu/~alnewell/pose/" target="_blank" rel="external">STACKED HOURGLASS NETWORKS</a> 是由密歇根大学的研究团队设计的一个专门用来进行人体姿态估计的网络结构。在卫星的部件检测项目中，我们对其进行了修改和调整，利用同样的网络结构完成了太阳帆板的检测定位（类似图像分割任务）、发动机和对接环的定位（关键点检测任务）、发动机和对接环的检测定位（类似图像分割任务）。<br>下面对 STACKED HOURGLASS NETWORKS 进行介绍及对自主实现的 Keras 关键代码进行分析。</p>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>在该论文中，作者指出：</p>
<blockquote>
<p>This work introduces a novel convolutional network architecture for the task of human pose estimation. Features are processed across all scales and consolidated to best capture the various spatial relationships associated with the body. We show how repeated bottom-up, top-down processing used in conjunction with intermediate supervision is critical to improving the performance of the network. We refer to the architecture as a “stacked hourglass” network based on the successive steps of pooling and upsampling that are done to produce a final set of predictions. State-of-the-art results are achieved on the FLIC and MPII benchmarks outcompeting all recent methods.</p>
</blockquote>
<p>特征在各个不同尺度上的进行处理并合并，可以让神经网络更好地把握部件的空间关系。将 bottom-up, top-down 的处理模块（hourglass 模块）进行重复堆叠（stack），在辅以中间监督 （intermediate supervision），可以极大地提高网络的性能。<br>实际上，是通过卷积神经网络对部件模型进行了编码表示，是一种隐式空间模型（implicit spatial model）。<br>STACKED HOURGLASS NETWORKS 与 CPM (Convolutional Pose Machines) 方法相比，思路更明晰，网络更简洁。<br><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/satellite/stacked-hg.png" alt="stacked hourglass"></p>
<h5 id="hourglass-模块"><a href="#hourglass-模块" class="headerlink" title="hourglass 模块"></a>hourglass 模块</h5><p>一个 hourglass 模块如下图所示，体现了跳级的思想。除红框内的 box 之外，每一个 box 都是一个 residual 模块的输出。<br>下图是 4 阶 hourglass 模块，进行了 4 次下采样（及对应的 4 次上采样）。n 阶 hourglass 模块可以提取从原始尺度到\(\frac{1}{2^n}\)<br>尺度的特征。<strong>在一个 hourglass 模块中特征图的通道数目保持不变。</strong><br><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/satellite/hourglass.png" alt="hourglass"></p>
<h5 id="residual-模块"><a href="#residual-模块" class="headerlink" title="residual 模块"></a>residual 模块</h5><p>一个 residual 模块如下图所示，residual 模块的 upper branch 是一个卷积模块 conv block，卷积模块首先进行一次\( 1 \times 1 \) 的卷积操作，缩减特征图的通道数目，然后进行一次 \( 3 \times 3 \)的卷积操作，最后再进行一次\( 1 \times 1 \)的卷积操作。residual 模块的 lower branch 是一个 skip layer，是一个跳级结构，在 skip layer 的输入与 conv block 的输出的通道数目不一致时，skip layer 会进行必要的 \( 1 \times 1 \) 卷积操作，使得其输出与 conv block 的输出通道数目一致，从而能够进行 element-wise 的相加。<br>一个 residual 模块可以看成是一个尺寸保持、通道数目可变可不变的“卷积层”。<br><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/satellite/residual.png" alt="residual"></p>
<h5 id="intermediate-supervision"><a href="#intermediate-supervision" class="headerlink" title="intermediate supervision"></a>intermediate supervision</h5><p>中间监督（intermediate supervision）的结构如下图所示，网络进行分支，并产生图中蓝色所示的热图（heatmap），热图可以被用来计算损失。在热图上应用一次 \( 1 \times 1\) 卷积操作，增加通道数目使得其可以与网络的中间特征图进行相加。图中虚线是来自上一个 hourglass 模块输出的特征图，这里也体现了跳级（skip layer）的思想。</p>
<p>跳级结构一方面可以看成是一个梯度反向传播的高速通道，另一方面也是网络正则化的一个替代，允许训练过程中神经网络自主选择其深度（结构复杂度）。<br><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/satellite/intermediate_supervision.png" alt="intermediate_supervision"></p>
<h5 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h5><p>对于 \( H \times W  \times N \)<br>的输入，每一个 hourglass 模块都会生成一个 \( \frac{H}{2}  \times \frac{W}{2} \times K\)<br>的热图。对于每个热图，都比较其与真值（groundtruth）的误差作为损失，体现了中间监督(intermediate supervision)的思想。</p>
<h5 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h5><p>在做预测时，仅选择最后一个 hourglass 模块输出的热图作为结果。</p>
<h3 id="关键代码"><a href="#关键代码" class="headerlink" title="关键代码"></a>关键代码</h3><h5 id="residual-模块-1"><a href="#residual-模块-1" class="headerlink" title="residual 模块"></a>residual 模块</h5><h6 id="conv-block"><a href="#conv-block" class="headerlink" title="conv block"></a>conv block</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_block</span><span class="params">(inputs, num_output)</span>:</span></div><div class="line">    <span class="string">""" Convolutional Block</span></div><div class="line"><span class="string">    Args:</span></div><div class="line"><span class="string">        inputs  : Input Tensor (Not after being activated!!!!!)</span></div><div class="line"><span class="string">        num_output  : Desired output number of channel</span></div><div class="line"><span class="string">    Returns:</span></div><div class="line"><span class="string">        output  : Output Tensor</span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    x = BatchNormalization()(inputs)</div><div class="line">    x = Activation(<span class="string">'relu'</span>)(x)</div><div class="line">    x = Conv2D(num_output // <span class="number">2</span>, (<span class="number">1</span>, <span class="number">1</span>), strides=<span class="number">1</span>, padding=<span class="string">'valid'</span>)(x)</div><div class="line"></div><div class="line">    x = BatchNormalization()(x)</div><div class="line">    x = Activation(<span class="string">'relu'</span>)(x)</div><div class="line">    x = Conv2D(num_output // <span class="number">2</span>, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">'same'</span>)(x)</div><div class="line"></div><div class="line">    x = BatchNormalization()(x)</div><div class="line">    x = Activation(<span class="string">'relu'</span>)(x)</div><div class="line">    output = Conv2D(num_output, (<span class="number">1</span>, <span class="number">1</span>), strides=<span class="number">1</span>, padding=<span class="string">'valid'</span>)(x)</div><div class="line">    <span class="keyword">return</span> output</div></pre></td></tr></table></figure>
<h6 id="skip-layer"><a href="#skip-layer" class="headerlink" title="skip layer"></a>skip layer</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">skip_layer</span><span class="params">(inputs, num_output)</span>:</span></div><div class="line">    <span class="string">""" Skip Layer</span></div><div class="line"><span class="string">    Args:</span></div><div class="line"><span class="string">        inputs  : Input Tensor</span></div><div class="line"><span class="string">        num_output  : Desired output number of channel</span></div><div class="line"><span class="string">    Returns:</span></div><div class="line"><span class="string">        Tensor of shape (None, inputs.height, inputs.width, num_output)</span></div><div class="line"><span class="string">    """</span></div><div class="line">    <span class="keyword">if</span> inputs.get_shape().as_list()[<span class="number">3</span>] == num_output:</div><div class="line">        <span class="keyword">return</span> inputs</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        x = BatchNormalization()(inputs)</div><div class="line">        x = Activation(<span class="string">'relu'</span>)(x)</div><div class="line">        output = Conv2D(num_output, (<span class="number">1</span>, <span class="number">1</span>), strides=<span class="number">1</span>, padding=<span class="string">'valid'</span>)(x)</div><div class="line">        <span class="keyword">return</span> output</div></pre></td></tr></table></figure>
<h6 id="residual"><a href="#residual" class="headerlink" title="residual"></a>residual</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">residual</span><span class="params">(inputs, num_output)</span>:</span></div><div class="line">    <span class="string">""" Residual Unit</span></div><div class="line"><span class="string">    Args:</span></div><div class="line"><span class="string">        inputs  : Input Tensor</span></div><div class="line"><span class="string">        num_output  : Number of Output Features (channels)</span></div><div class="line"><span class="string">    """</span></div><div class="line">    convb = conv_block(inputs, num_output)</div><div class="line">    skipl = skip_layer(inputs, num_output)</div><div class="line">    <span class="keyword">return</span> Add()([convb, skipl])</div></pre></td></tr></table></figure>
<h5 id="hourglass-模块-1"><a href="#hourglass-模块-1" class="headerlink" title="hourglass 模块"></a>hourglass 模块</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">hourglass</span><span class="params">(inputs, num_low, num_output)</span>:</span></div><div class="line">    <span class="string">""" Hourglass Module</span></div><div class="line"><span class="string">    Args:</span></div><div class="line"><span class="string">        inputs  : Input Tensor</span></div><div class="line"><span class="string">        num_low       : Number of downsampling step</span></div><div class="line"><span class="string">        num_output  : Number of Output Features (channels)</span></div><div class="line"><span class="string">    """</span></div><div class="line">    <span class="comment"># Upper Branch</span></div><div class="line">    up_1 = residual(inputs, num_output)</div><div class="line"></div><div class="line">    <span class="comment"># Lower Branch</span></div><div class="line">    low_ = MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=(<span class="number">2</span>, <span class="number">2</span>))(inputs)</div><div class="line">    low_1= residual(low_, num_output)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> num_low &gt; <span class="number">0</span>:</div><div class="line">        low_2 = hourglass(low_1, num_low<span class="number">-1</span>, num_output)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        low_2 = residual(low_1, num_output)</div><div class="line"></div><div class="line">    low_3 = residual(low_2, num_output)</div><div class="line"></div><div class="line">    up_2 = UpSampling2D(size=(<span class="number">2</span>, <span class="number">2</span>))(low_3)</div><div class="line">    <span class="keyword">return</span> Add()([up_2, up_1])</div></pre></td></tr></table></figure>
<h5 id="loss"><a href="#loss" class="headerlink" title="loss"></a>loss</h5><p>在使用 Keras 对损失函数进行实现的时候，需要注意的几点是：</p>
<ul>
<li>定义的 Python 损失函数需要传入模型的 <code>fit</code> 或者 <code>fit_generator</code> 方法，这两个方法会在内部调用该函数并为其传入训练数据中的标签和神经网络的输出，这两个参数是损失函数计算损失的唯二参数，此处由于使用中间监督的模型结构，即网络中间产生的热图也需要参与到损失值的计算，所以需要将所有这些热图都 stack 起来当作网络的输出，从而可以被传入损失函数完成损失值的计算。</li>
<li>Keras 中定义 loss，返回的是 batch_size 长度的 tensor， 而不是像 tensorflow 中那样是一个 scalar。</li>
<li><code>K.binary_crossentropy</code> 的默认设置是 <code>from_logits=False</code>,即该函数的默认设置假设输入是经过 <code>sigmoid</code> 激活之后的值，而不是仅经过卷积操作之后的<code>logits</code>，这是由其需要注意的一点，<code>K.binary_crossentropy</code> 的源码如下，如果<code>from_logits==True</code>，则直接调用 TensorFlow 的 <code>tf.nn.sigmoid_cross_entropy_with_logits</code>；如果<code>from_logits==False</code>，则首先将输入转换回 logits，再调用<code>tf.nn.sigmoid_cross_entropy_with_logits</code>。如果使用错误，就会 logits 就会被 <code>clip_by_value</code> 裁剪到（0，1）之间。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_crossentropy</span><span class="params">(target, output, from_logits=False)</span>:</span></div><div class="line">    <span class="string">"""Binary crossentropy between an output tensor and a target tensor.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    # Arguments</span></div><div class="line"><span class="string">        target: A tensor with the same shape as `output`.</span></div><div class="line"><span class="string">        output: A tensor.</span></div><div class="line"><span class="string">        from_logits: Whether `output` is expected to be a logits tensor.</span></div><div class="line"><span class="string">            By default, we consider that `output`</span></div><div class="line"><span class="string">            encodes a probability distribution.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    # Returns</span></div><div class="line"><span class="string">        A tensor.</span></div><div class="line"><span class="string">    """</span></div><div class="line">    <span class="comment"># Note: tf.nn.sigmoid_cross_entropy_with_logits</span></div><div class="line">    <span class="comment"># expects logits, Keras expects probabilities.</span></div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> from_logits:</div><div class="line">        <span class="comment"># transform back to logits</span></div><div class="line">        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)</div><div class="line">        output = tf.clip_by_value(output, _epsilon, <span class="number">1</span> - _epsilon)</div><div class="line">        output = tf.log(output / (<span class="number">1</span> - output))</div><div class="line"></div><div class="line">    <span class="keyword">return</span> tf.nn.sigmoid_cross_entropy_with_logits(labels=target,</div><div class="line">                                                   logits=output)</div></pre></td></tr></table></figure>
<p>定义的损失函数如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span><span class="params">(y_true, y_pred)</span>:</span></div><div class="line">	<span class="string">"""</span></div><div class="line"><span class="string">	# Arguments</span></div><div class="line"><span class="string">		y_true: A tensor of shape (batch_size, W, H, K), K is the num of heatmaps.</span></div><div class="line"><span class="string">		y_pred: A tensor of shape (batch_size, N, W, H, K), N is the num of hourglass modules. </span></div><div class="line"><span class="string">	"""</span></div><div class="line">    losses = []</div><div class="line">    shapes = y_pred.get_shape().as_list()</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(shapes[<span class="number">1</span>]):</div><div class="line">        losses.append(K.reshape(</div><div class="line">            K.mean(K.binary_crossentropy(y_true, y_pred[:, i], from_logits=<span class="keyword">True</span>), axis=<span class="number">-1</span>), </div><div class="line">            (<span class="number">-1</span>, shapes[<span class="number">2</span>]*shapes[<span class="number">3</span>])))</div><div class="line">    </div><div class="line">    loss = K.mean(K.mean(K.stack(losses, axis=<span class="number">1</span>), axis=<span class="number">1</span>), axis=<span class="number">1</span>)</div><div class="line"></div><div class="line">    <span class="keyword">return</span> loss</div></pre></td></tr></table></figure></p>
<h3 id="数据集及结果"><a href="#数据集及结果" class="headerlink" title="数据集及结果"></a>数据集及结果</h3><h5 id="发动机和对接环的定位（关键点检测任务）"><a href="#发动机和对接环的定位（关键点检测任务）" class="headerlink" title="发动机和对接环的定位（关键点检测任务）"></a>发动机和对接环的定位（关键点检测任务）</h5><h6 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h6><p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/satellite/satellite_key_pts.png" alt="satellite_key_pts"></p>
<h6 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h6><p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/satellite/satellite_key_pts_ret.png" alt="satellite_key_pts_ret"></p>
<h5 id="发动机和对接环的检测定位（类似图像分割任务）"><a href="#发动机和对接环的检测定位（类似图像分割任务）" class="headerlink" title="发动机和对接环的检测定位（类似图像分割任务）"></a>发动机和对接环的检测定位（类似图像分割任务）</h5><h6 id="数据集-1"><a href="#数据集-1" class="headerlink" title="数据集"></a>数据集</h6><p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/satellite/satellite.png" alt="satellite"></p>
<h6 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h6><p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/satellite/satellite_ret.png" alt="satellite_ret"></p>
<h5 id="太阳帆板的检测定位（类似图像分割任务）"><a href="#太阳帆板的检测定位（类似图像分割任务）" class="headerlink" title="太阳帆板的检测定位（类似图像分割任务）"></a>太阳帆板的检测定位（类似图像分割任务）</h5><h6 id="数据集-2"><a href="#数据集-2" class="headerlink" title="数据集"></a>数据集</h6><p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/satellite/satellite_sol_pan.png" alt="satellite_sol_pan"></p>
<h6 id="结果-2"><a href="#结果-2" class="headerlink" title="结果"></a>结果</h6><p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/satellite/satellite_sol_pan_ret.png" alt="satellite_sol_pan_ret"></p>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/07/03/Run-Keras-models-in-C-Tensorflow/">
                Run Keras models in C++ Tensorflow
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-07-03</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            
        </div>
    

</div>
            
        </section>
    </div>
</div>



    <div class="row">
        <div class="col-sm-12">
            <div class="wrap-pagination">
                <a class="disabled" href="/">
                    <i class="fa fa-chevron-left" aria-hidden="true"></i>
                </a>
                <a class="" href="/page/2/">
                    <i class="fa fa-chevron-right" aria-hidden="true"></i>
                </a>
            </div>
        </div>
    </div>




</div>

<!-- Footer -->
<div class="push"></div>

<footer class="footer-content">
    <div class="container">
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-6 col-lg-6 footer-about">
                <h2>About</h2>
                <p>
                    This is Robert Lexis (FengCun Li). To see the world, things dangerous to come to, to see behind walls, to draw closer, to find each other and to feel. That is the purpose of LIFE.
                </p>
            </div>
            
    <div class="col-xs-6 col-sm-6 col-md-3 col-lg-3 recent-posts">
        <h2>Recent Posts</h2>
        <ul>
            
            <li>
                <a class="footer-post" href="/2018/08/13/消失的梯度/">消失的梯度</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2018/08/11/MobileNet-V1-and-V2-带来的卷积结构革命/">MobileNet V1 and V2 带来的卷积</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2018/08/09/卷积转置卷积关系在-TensorFLow-中的验证/">卷积转置卷积关系在 TensorFLow 中的验证</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2018/08/08/转置卷积-Transposed-Convolution/">转置卷积 Transposed Convoluti</a>
            </li>
            
        </ul>
    </div>



            
        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <ul class="list-inline footer-social-icons">
                    
                    <li class="list-inline-item">
                        <a href="https://github.com/RobertLexis">
                            <span class="footer-icon-container">
                                <i class="fa fa-github"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    <li class="list-inline-item">
                        <a href="mailto:robert_lexis@163.com">
                            <span class="footer-icon-container">
                                <i class="fa fa-envelope-o"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                </ul>
            </div>
        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <div class="footer-copyright">
                    @Untitled. All right reserved | Robert Lexis Loves Wenny
                </div>
            </div>
        </div>
    </div>
</footer>

<!-- After footer scripts -->

<!-- jQuery -->
<script src="//code.jquery.com/jquery-2.1.4.min.js"></script>

<!-- Tween Max -->
<script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.5/TweenMax.min.js"></script>

<!-- Gallery -->
<script src="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Custom JavaScript -->
<script src="/js/main.js"></script>

<!-- Disqus Comments -->



</body>

</html>