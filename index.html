<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!--Description-->
    

    <!--Author-->
    
        <meta name="author" content="Robert Lexis">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="This is Robert Lexis."/>
    

    <!--Open Graph Description-->
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content="This is Robert Lexis."/>

    <!--Type page-->
    
        <meta property="og:type" content="website" />
    

    <!--Page Cover-->
    

    <meta name="twitter:card" content="summary" />
    

    <!-- Title -->
    
    <title>This is Robert Lexis.</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.2/css/bootstrap.min.css" integrity="sha384-y3tfxAZXuh4HwSYylfB+J125MxIs6mR5FOHamPBG064zB+AFeWH94NdvaCBm8qnd" crossorigin="anonymous">

    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/style.css">

    <!-- Google Analytics -->
    


</head>


<body>

<div class="bg-gradient"></div>
<div class="bg-pattern"></div>

<!-- Menu -->
<!--Menu Links and Overlay-->
<div class="menu-bg">
    <div class="menu-container">
        <ul>
            
            <li class="menu-item">
                <a href="/">
                    Home
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/archives">
                    Archives
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/about">
                    About
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/tags">
                    Tags
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/categories">
                    Categories
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/contact">
                    Contact
                </a>
            </li>
            
        </ul>
    </div>
</div>

<!--Hamburger Icon-->
<nav>
    <a href="#menu"></a>
</nav>

<div class="container">

    <!-- Main Content -->
    <div class="row">
    <div class="col-sm-12">

        <!--Title and Logo-->
        <header>
    <div class="logo">
        <a href="/"><i class="logo-icon fa fa-cube" aria-hidden="true"></i></a>
        
            <h1 id="main-title" class="title">This is Robert Lexis.</h1>
        
    </div>
</header>

        <section class="main">
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/26/YOLO/">
                YOLO
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-26</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h3 id="Sliding-Windows-滑动窗口"><a href="#Sliding-Windows-滑动窗口" class="headerlink" title="Sliding Windows 滑动窗口"></a>Sliding Windows 滑动窗口</h3><p>通过滑动窗口的方式在图像上生成一系列的 box，然后利用分类器对每个 box 进行分类，即可完成对图像中目标的检测。<br>基于滑动窗口的目标检测效率很低，因为我们需要对每个区域都进行预测，而且为了获得更加准确的结果，我们需要尝试各种不同尺寸的 box。</p>
<h3 id="Convolutional-Implementation-of-Sliding-Windows"><a href="#Convolutional-Implementation-of-Sliding-Windows" class="headerlink" title="Convolutional Implementation of Sliding Windows"></a>Convolutional Implementation of Sliding Windows</h3><p>这是一个加速的方法，共享计算。<br><img src="/2018/08/26/YOLO/cnn-slide.jpg" alt="cnn-slide"></p>
<h3 id="More-accurate-bounding-boxes"><a href="#More-accurate-bounding-boxes" class="headerlink" title="More accurate bounding boxes"></a>More accurate bounding boxes</h3><p>通过上面一个 \( reduction factor = 8 \) 的卷积神经网络，我们可以在 4 个 \( 14 \times 14 \) 的方框内进行目标的检测，这样的检测结果并不会很精确。在下图中蓝色的方框也许是最吻合的，但是实际上它的位置并不精确，另外目标形状也许并不是一个正方形，而是像图中所示的那样是一个长方形。因此需要对其进行改进，即对这 4 个方框内的目标位置进行回归修正。<br><img src="/2018/08/26/YOLO/not_accurate.png" alt="not_accurate"></p>
<h5 id="Grid-cells"><a href="#Grid-cells" class="headerlink" title="Grid cells"></a>Grid cells</h5><p>在实际的算法中，使用的是 \( 19 \times 19 \) grid cells，此处出于示意采用的是 \( 3 \times 3 \) grid cells。<br><img src="/2018/08/26/YOLO/grid_cell.jpg" alt="grid_cell"><br>如何将目标和具体的某一个 grid cell 联系起来呢？<br>YOLO 算法查看目标的 bounding box 的中心点，把目标归给中心点所在的那个 grid cell。<br><img src="/2018/08/26/YOLO/grid_cell_output.jpg" alt="grid_cell_output"><br>这样每一个 grid cell 就有了一个标签：<br>\[<br>y = \left[<br>    \begin{matrix}<br>    p_c \\\\<br>    b_x \\\\<br>    b_y \\\\<br>    b_h \\\\<br>    b_w \\\\<br>    c_1 \\\\<br>    c_2 \\\\<br>    c_3<br>    \end{matrix}<br>\right]<br>\]</p>
<ul>
<li>\( p_c \): 该 grid cell 中是否存在某一个目标的 bounding box 的中心点。</li>
<li>\( b_x \): x coordinate, the center of the object corresponding to the upper left corner of the grid cell, the value range from 0~1,</li>
<li>\( b_y \): y coordinate, the center of the object corresponding to the upper left corner of the grid cell, the value range from 0~1,</li>
<li>\( b_h \): height of the bounding box with repect to the height of grid cell, the value could be greater than 1.</li>
<li>\( b_w \): width of the bounding box with repect to the width of grid cell, the value could be greater than 1,</li>
<li>\( c_1, c_2, c_3 \): 目标属于每一类的概率。</li>
</ul>
<p>通过这样的方式完成一张图片标签的构建。</p>
<p>神经网络的输出是一个 \( 3 \times 3 \times 8\) 的 volume。此时，只要每一个 grid cell 中存在的一个目标个数不超过一个，这个算法就可以工作。此时算法很像 \( 3 \times 3 \) 个 Classification + Localization，直接输出每一个 grid cell 中是否存在目标及目标的类别和位置。关于 Classification + Localization 可以查看我的另一篇博文<a href="目标定位-vs-目标检测/">目标定位 vs 目标检测</a>。</p>
<h5 id="Non-Max-Suppression"><a href="#Non-Max-Suppression" class="headerlink" title="Non Max Suppression"></a>Non Max Suppression</h5><p>使用非最大值抑制 clean up grid cells’ detections。</p>
<h6 id="IoU"><a href="#IoU" class="headerlink" title="IoU"></a>IoU</h6><p>In general, so long as the IoU is greater than or equal to 0.5, then the result will look pretty decent. And by convention, very often 0.5 is used as a threshold to judge as whether the predicted bounding box is correct or not.<br>关于非最大值抑制可以查看我的另一篇博文<a href="http://localhost:4000/2018/08/26/非最大值抑制/" target="_blank" rel="external">非最大值抑制</a>。<br><img src="/2018/08/26/YOLO/before_nms.jpg" alt="before_nms"><br><img src="/2018/08/26/YOLO/after_nms.jpg" alt="affter_nms"></p>
<h5 id="Anchor-Boxes"><a href="#Anchor-Boxes" class="headerlink" title="Anchor Boxes"></a>Anchor Boxes</h5><p>目前为止，如果某一个 grid cell 中含有多个目标的 bounding box 的中心点，那么算法只能检测一个目标而不得不舍弃其他的目标。<br><img src="/2018/08/26/YOLO/car-person.jpg" alt="car-person"><br>虽然使用更加细密的 grid cell 划分，可以降低多个目标中心点出现在同一个 grid cell 中的概率，但是还是难以避免的。因此可以在同一个 grid cell 中配备 n 个锚点 box，此时最多允许 n 个目标的 bounding box 的中心点出现在同一个 grid cell 中。<br><img src="/2018/08/26/YOLO/anchor_box.jpg" alt="anchor_box"><br>现在神经网络的输出是一个 \( 3 \times 3 \times 16\) 的 volume。<br><img src="/2018/08/26/YOLO/anchor_box_y.jpg" alt="anchor_box_y"><br>在之前算法中，图片中的每一个目标被归给含有该目标中心点的那个 grid cell。<br>在使用锚点 box 的算法中，图片中的每一个目标被归给含有该目标中心点的那个grid cell 中的、与该目标有最大交并比的那个 anchor box。</p>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/26/非最大值抑制/">
                非最大值抑制
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-26</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>非最大值抑制 Non-max Suppression 是目标检测（object detection）中常用的后处理（post processing）技术。<br>（Fast-， Faster-）RCNN，SSD，YOLO 等目标检测框架会对一个目标产生多个 bounding box 的预测结果，而我们最终需要的仅仅是最“合适”的那一个。<br>非最大值抑制就是用来去除（clean up）多余的 bounding box 的预测结果，确保对一个目标只输出一个检测结果。<br>概率最大的 bounding box 被保留，且该 bounding box 周围的与它有较大交并比的 bounding box 会被抑制。<br><img src="/2018/08/26/非最大值抑制/grid.png" alt="grid"><br>Each output prediction is:<br>\[<br>    \left[<br>    \begin{matrix}<br>    p_c \\\\<br>    b_x \\\\<br>    b_y \\\\<br>    b_w \\\\<br>    b_h<br>    \end{matrix}<br>    \right]<br>\]<br>Algorithm:<br>Discard all boxes with \( p_c \leq 0.5\)<br>While there are any remaining boxes:</p>
<ul>
<li>Pick the box with the largest \( p_c \), output that as a prediction.</li>
<li>Discard any remaining box with \(IOU \geq 0.5 \) with the box output in the previous step.<br><img src="/2018/08/26/非最大值抑制/non_max_suppression.png" alt="non_max_suppression"></li>
</ul>
<h3 id="Tensorflow-tf-image-non-max-suppression"><a href="#Tensorflow-tf-image-non-max-suppression" class="headerlink" title="Tensorflow tf.image.non_max_suppression"></a>Tensorflow tf.image.non_max_suppression</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">tf.image.non_max_suppression(</div><div class="line">    boxes,</div><div class="line">    scores,</div><div class="line">    max_output_size,</div><div class="line">    iou_threshold=<span class="number">0.5</span>,</div><div class="line">    score_threshold=float(<span class="string">'-inf'</span>),</div><div class="line">    name=<span class="keyword">None</span></div><div class="line">)</div></pre></td></tr></table></figure>
<p>Greedily selects a subset of bounding boxes in descending order of score.</p>
<p>Prunes away boxes that have high intersection-over-union (IOU) overlap with previously selected boxes. Bounding boxes are supplied as [y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any diagonal pair of box corners and the coordinates can be provided as normalized (i.e., lying in the interval [0, 1]) or absolute. Note that this algorithm is agnostic to where the origin is in the coordinate system. Note that this algorithm is invariant to orthogonal transformations and translations of the coordinate system; thus translating or reflections of the coordinate system result in the same boxes being selected by the algorithm. The output of this operation is <strong>a set of integers indexing into the input collection of bounding boxes representing the selected boxes</strong>. The bounding box coordinates corresponding to the selected indices can then be obtained using the tf.gather operation. For example:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">selected_indices = tf.image.non_max_suppression( boxes, scores, max_output_size, iou_threshold) </div><div class="line">selected_boxes = tf.gather(boxes, selected_indices)</div></pre></td></tr></table></figure></p>
<p>Args:<br>boxes: A 2-D float Tensor of shape [num_boxes, 4].<br>scores: A 1-D float Tensor of shape [num_boxes] representing a single score corresponding to each box (each row of boxes).<br>max_output_size: A scalar integer Tensor representing the maximum number of boxes to be selected by non max suppression.<br>iou_threshold: A float representing the threshold for deciding whether boxes overlap too much with respect to IOU.<br>score_threshold: A float representing the threshold for deciding when to remove boxes based on score.<br>name: A name for the operation (optional).<br>Returns:<br>selected_indices: A 1-D integer Tensor of shape [M] representing the selected indices from the boxes tensor, where M &lt;= max_output_size.</p>
<h3 id="Tensorflow-多类别非最大值抑制"><a href="#Tensorflow-多类别非最大值抑制" class="headerlink" title="Tensorflow 多类别非最大值抑制"></a>Tensorflow 多类别非最大值抑制</h3><p>在 <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/core/post_processing.py" target="_blank" rel="external">models/research/object_detection/core/post_processing.py</a> 中定义：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiclass_non_max_suppression</span><span class="params">(boxes,</span></span></div><div class="line"><span class="function"><span class="params">                                   scores,</span></span></div><div class="line"><span class="function"><span class="params">                                   score_thresh,</span></span></div><div class="line"><span class="function"><span class="params">                                   iou_thresh,</span></span></div><div class="line"><span class="function"><span class="params">                                   max_size_per_class,</span></span></div><div class="line"><span class="function"><span class="params">                                   max_total_size=<span class="number">0</span>,</span></span></div><div class="line"><span class="function"><span class="params">                                   clip_window=None,</span></span></div><div class="line"><span class="function"><span class="params">                                   change_coordinate_frame=False,</span></span></div><div class="line"><span class="function"><span class="params">                                   masks=None,</span></span></div><div class="line"><span class="function"><span class="params">                                   boundaries=None,</span></span></div><div class="line"><span class="function"><span class="params">                                   additional_fields=None,</span></span></div><div class="line"><span class="function"><span class="params">                                   scope=None)</span>:</span></div><div class="line">  <span class="string">"""Multi-class version of non maximum suppression.</span></div><div class="line"><span class="string">  This op greedily selects a subset of detection bounding boxes, pruning</span></div><div class="line"><span class="string">  away boxes that have high IOU (intersection over union) overlap (&gt; thresh)</span></div><div class="line"><span class="string">  with already selected boxes.  </span></div><div class="line"><span class="string">  It operates independently for each class for</span></div><div class="line"><span class="string">  which scores are provided (via the scores field of the input box_list),</span></div><div class="line"><span class="string">  pruning boxes with score less than a provided threshold prior to</span></div><div class="line"><span class="string">  applying NMS.</span></div><div class="line"><span class="string">  单独对每一类进行操作，在进行非最大值抑制之前，首先去掉 score 低于 score_thresh 的 boxes。</span></div><div class="line"><span class="string">  Please note that this operation is performed on *all* classes, therefore any</span></div><div class="line"><span class="string">  background classes should be removed prior to calling this function.</span></div><div class="line"><span class="string">  Selected boxes are guaranteed to be sorted in decreasing order by score (but</span></div><div class="line"><span class="string">  the sort is not guaranteed to be stable).</span></div><div class="line"><span class="string">  Args:</span></div><div class="line"><span class="string">    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either</span></div><div class="line"><span class="string">      number of classes or 1 depending on whether a separate box is predicted</span></div><div class="line"><span class="string">      per class.</span></div><div class="line"><span class="string">      根据是否是在第 k 个 detection 处对每一类单独预测一个 box，输入参数 boxes 的 q 可能为 number of</span></div><div class="line"><span class="string">      class 或者 1。</span></div><div class="line"><span class="string">    scores: A [k, num_classes] float32 tensor containing the scores for each of</span></div><div class="line"><span class="string">      the k detections.</span></div><div class="line"><span class="string">    score_thresh: scalar threshold for score (low scoring boxes are removed).</span></div><div class="line"><span class="string">    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap</span></div><div class="line"><span class="string">      with previously selected boxes are removed).</span></div><div class="line"><span class="string">    max_size_per_class: maximum number of retained boxes per class.</span></div><div class="line"><span class="string">    max_total_size: maximum number of boxes retained over all classes. By</span></div><div class="line"><span class="string">      default returns all boxes retained after capping boxes per class.</span></div><div class="line"><span class="string">    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]</span></div><div class="line"><span class="string">      representing the window to clip and normalize boxes to before performing</span></div><div class="line"><span class="string">      non-max suppression.</span></div><div class="line"><span class="string">      此处 before 是错误的，因为在下面代码的实际实现时是 after。</span></div><div class="line"><span class="string">      利用 clip_window 这个窗口对每一个 boxes 进行裁剪和 normalize。</span></div><div class="line"><span class="string">    change_coordinate_frame: Whether to normalize coordinates after clipping</span></div><div class="line"><span class="string">      relative to clip_window (this can only be set to True if a clip_window</span></div><div class="line"><span class="string">      is provided)</span></div><div class="line"><span class="string">    masks: (optional) a [k, q, mask_height, mask_width] float32 tensor</span></div><div class="line"><span class="string">      containing box masks. `q` can be either number of classes or 1 depending</span></div><div class="line"><span class="string">      on whether a separate mask is predicted per class.</span></div><div class="line"><span class="string">    boundaries: (optional) a [k, q, boundary_height, boundary_width] float32</span></div><div class="line"><span class="string">      tensor containing box boundaries. `q` can be either number of classes or 1</span></div><div class="line"><span class="string">      depending on whether a separate boundary is predicted per class.</span></div><div class="line"><span class="string">    additional_fields: (optional) If not None, a dictionary that maps keys to</span></div><div class="line"><span class="string">      tensors whose first dimensions are all of size `k`. After non-maximum</span></div><div class="line"><span class="string">      suppression, all tensors corresponding to the selected boxes will be</span></div><div class="line"><span class="string">      added to resulting BoxList.</span></div><div class="line"><span class="string">    scope: name scope.</span></div><div class="line"><span class="string">  Returns:</span></div><div class="line"><span class="string">    a BoxList holding M boxes.</span></div><div class="line"><span class="string">  Raises:</span></div><div class="line"><span class="string">    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not have</span></div><div class="line"><span class="string">      a valid scores field.</span></div><div class="line"><span class="string">  """</span></div><div class="line">  <span class="keyword">if</span> <span class="keyword">not</span> <span class="number">0</span> &lt;= iou_thresh &lt;= <span class="number">1.0</span>:</div><div class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'iou_thresh must be between 0 and 1'</span>)</div><div class="line">  <span class="keyword">if</span> scores.shape.ndims != <span class="number">2</span>:</div><div class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'scores field must be of rank 2'</span>)</div><div class="line">  <span class="keyword">if</span> scores.shape[<span class="number">1</span>].value <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'scores must have statically defined second '</span></div><div class="line">                     <span class="string">'dimension'</span>)</div><div class="line">  <span class="keyword">if</span> boxes.shape.ndims != <span class="number">3</span>:</div><div class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'boxes must be of rank 3.'</span>)</div><div class="line">  <span class="keyword">if</span> <span class="keyword">not</span> (boxes.shape[<span class="number">1</span>].value == scores.shape[<span class="number">1</span>].value <span class="keyword">or</span></div><div class="line">          boxes.shape[<span class="number">1</span>].value == <span class="number">1</span>):</div><div class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'second dimension of boxes must be either 1 or equal '</span></div><div class="line">                     <span class="string">'to the second dimension of scores'</span>)</div><div class="line">  <span class="keyword">if</span> boxes.shape[<span class="number">2</span>].value != <span class="number">4</span>:</div><div class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'last dimension of boxes must be of size 4.'</span>)</div><div class="line">  <span class="keyword">if</span> change_coordinate_frame <span class="keyword">and</span> clip_window <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'if change_coordinate_frame is True, then a clip_window'</span></div><div class="line">                     <span class="string">'must be specified.'</span>)</div><div class="line"></div><div class="line">  <span class="keyword">with</span> tf.name_scope(scope, <span class="string">'MultiClassNonMaxSuppression'</span>):</div><div class="line">    num_scores = tf.shape(scores)[<span class="number">0</span>]</div><div class="line">    num_classes = scores.get_shape()[<span class="number">1</span>]</div><div class="line"></div><div class="line">    selected_boxes_list = []</div><div class="line">    per_class_boxes_list = tf.unstack(boxes, axis=<span class="number">1</span>)</div><div class="line">    <span class="keyword">if</span> masks <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">      per_class_masks_list = tf.unstack(masks, axis=<span class="number">1</span>)</div><div class="line">    <span class="keyword">if</span> boundaries <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">      per_class_boundaries_list = tf.unstack(boundaries, axis=<span class="number">1</span>)</div><div class="line">    boxes_ids = (range(num_classes) <span class="keyword">if</span> len(per_class_boxes_list) &gt; <span class="number">1</span></div><div class="line">                 <span class="keyword">else</span> [<span class="number">0</span>] * num_classes.value)</div><div class="line">    <span class="comment"># 对每一类单独处理</span></div><div class="line">    <span class="keyword">for</span> class_idx, boxes_idx <span class="keyword">in</span> zip(range(num_classes), boxes_ids):</div><div class="line">      per_class_boxes = per_class_boxes_list[boxes_idx]</div><div class="line">      boxlist_and_class_scores = box_list.BoxList(per_class_boxes)</div><div class="line">      class_scores = tf.reshape(</div><div class="line">          tf.slice(scores, [<span class="number">0</span>, class_idx], tf.stack([num_scores, <span class="number">1</span>])), [<span class="number">-1</span>])</div><div class="line"></div><div class="line">      boxlist_and_class_scores.add_field(fields.BoxListFields.scores,</div><div class="line">                                         class_scores)</div><div class="line">      <span class="keyword">if</span> masks <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        per_class_masks = per_class_masks_list[boxes_idx]</div><div class="line">        boxlist_and_class_scores.add_field(fields.BoxListFields.masks,</div><div class="line">                                           per_class_masks)</div><div class="line">      <span class="keyword">if</span> boundaries <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        per_class_boundaries = per_class_boundaries_list[boxes_idx]</div><div class="line">        boxlist_and_class_scores.add_field(fields.BoxListFields.boundaries,</div><div class="line">                                           per_class_boundaries)</div><div class="line">      <span class="keyword">if</span> additional_fields <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        <span class="keyword">for</span> key, tensor <span class="keyword">in</span> additional_fields.items():</div><div class="line">          boxlist_and_class_scores.add_field(key, tensor)</div><div class="line"></div><div class="line">      max_selection_size = tf.minimum(max_size_per_class,</div><div class="line">                                      boxlist_and_class_scores.num_boxes())</div><div class="line">      selected_indices = tf.image.non_max_suppression(</div><div class="line">          boxlist_and_class_scores.get(),</div><div class="line">          boxlist_and_class_scores.get_field(fields.BoxListFields.scores),</div><div class="line">          max_selection_size,</div><div class="line">          iou_threshold=iou_thresh,</div><div class="line">          score_threshold=score_thresh)</div><div class="line">      nms_result = box_list_ops.gather(boxlist_and_class_scores,</div><div class="line">                                       selected_indices)</div><div class="line">      nms_result.add_field(</div><div class="line">          fields.BoxListFields.classes, (tf.zeros_like(</div><div class="line">              nms_result.get_field(fields.BoxListFields.scores)) + class_idx))</div><div class="line">      selected_boxes_list.append(nms_result)</div><div class="line">    <span class="comment"># selected_boxes 是一个 BoxList 对象，内部以字典的形式存储了一个位置信息张量、score张量、class张量，三个张量中对应的 </span></div><div class="line">    <span class="comment"># index 构成了一个 box 的信息。 </span></div><div class="line">    selected_boxes = box_list_ops.concatenate(selected_boxes_list)</div><div class="line">    <span class="comment"># 打破类别的藩篱，对整个 BoxList 对象按照 score 进行排序</span></div><div class="line">    sorted_boxes = box_list_ops.sort_by_field(selected_boxes,</div><div class="line">                                              fields.BoxListFields.scores)</div><div class="line">    <span class="keyword">if</span> clip_window <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">      sorted_boxes = box_list_ops.clip_to_window(sorted_boxes, clip_window)</div><div class="line">      <span class="keyword">if</span> change_coordinate_frame:</div><div class="line">        sorted_boxes = box_list_ops.change_coordinate_frame(</div><div class="line">            sorted_boxes, clip_window)</div><div class="line">    <span class="keyword">if</span> max_total_size:</div><div class="line">      max_total_size = tf.minimum(max_total_size,</div><div class="line">                                  sorted_boxes.num_boxes())</div><div class="line">      <span class="comment"># 打破类别的藩篱，仅选择 BoxList 对象中 score 最大的 max_total_size 个 box，并返回一个新的 BoxList 对象。</span></div><div class="line">      sorted_boxes = box_list_ops.gather(sorted_boxes,</div><div class="line">                                         tf.range(max_total_size))</div><div class="line">    <span class="keyword">return</span> sorted_boxes</div></pre></td></tr></table></figure></p>
<p>关于 <code>BoxList</code> 的定义可以查看 <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/core/box_list.py" target="_blank" rel="external">models/research/object_detection/core/box_list.py</a>。</p>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/26/目标定位-vs-目标检测/">
                目标定位 vs 目标检测
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-26</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>计算机视觉领域的不同任务：<br><img src="/2018/08/26/目标定位-vs-目标检测/cls.png" alt="classification"><br><img src="/2018/08/26/目标定位-vs-目标检测/other.png" alt="other task"></p>
<h3 id="主要任务类别"><a href="#主要任务类别" class="headerlink" title="主要任务类别"></a>主要任务类别</h3><ul>
<li>Classification<br>图像中有一个主体目标，且该张图片被标记为该主体目标的类别。<ul>
<li>one main object per image</li>
<li>one class label per image</li>
</ul>
</li>
</ul>
<p>one-hot vector<br>\[<br>y = \left[<br>        \begin{matrix}<br>            c_1 \\\\<br>            c_2 \\\\<br>            c_3<br>        \end{matrix}<br>\right]<br>\]</p>
<ul>
<li>Classification + Localization<br>图像中有一个主体目标，且该张图片被标记为该主体的类别和位置。<ul>
<li>one main object per image</li>
<li>one class label per image</li>
</ul>
</li>
</ul>
<p>\[<br>y = \left[<br>    \begin{matrix}<br>        p_c \\\\<br>        b_x \\\\<br>        b_y \\\\<br>        b_w \\\\<br>        b_h \\\\<br>        c_1 \\\\<br>        c_2 \\\\<br>        c_3<br>    \end{matrix}<br>\right]<br>\]</p>
<p>其中 \( p_c \) 标识图像中是否出现目标，\( (b_x, b_y, b_w, b_h) \) 标识若图像中目标存在则图像中目标的位置，\(  (c_1, c_2, c_3) \) 标识若图像中目标存在则图像中目标的类别（此处以三类目标为例）。</p>
<ul>
<li>Object Detection<br>图像中有属于多个类别的多个目标<ul>
<li>multi objects per image</li>
<li>multi classes per image</li>
</ul>
</li>
</ul>
<h3 id="推广任务类别"><a href="#推广任务类别" class="headerlink" title="推广任务类别"></a>推广任务类别</h3><ul>
<li>Multi label classification<br>图像中有一个主体目标，且该张图片被标记为该主体目标的类别，但该主体目标可能同时属于多个类别。<ul>
<li>one main object per image</li>
<li>multi class labels per image</li>
</ul>
</li>
</ul>
<p>\[<br>y = \left[<br>    \begin{matrix}<br>        c_1 \\\\<br>        c_2 \\\\<br>        c_3<br>    \end{matrix}<br>\right]<br>\]<br>\( y \) 根据图像中主体目标所属类别的个数不一定是 one-hot 的。</p>
<ul>
<li>Multi objects Classification + Localization<ul>
<li>n objects per image</li>
<li>m classes per image</li>
<li>\( n_{c_1} + n_{c_2} + n_{c_3} + … + n_{c_m} = n \)</li>
<li>\( n, m, n_{c_i} \) 对于一个具体任务是一组确定的值。</li>
</ul>
</li>
</ul>
<p>\[<br>y\_category = \left[<br>    \begin{matrix}<br>    p_c \\\\<br>    c_1 \\\\<br>    c_2 \\\\<br>    c_{3, 1} \\\\<br>    c_{3, 2}<br>    \end{matrix}<br>\right]<br>y\_location = \left[<br>    \begin{matrix}<br>    \\\\<br>    b_{x, 1} \\\\<br>    b_{y, 1} \\\\<br>    b_{w, 1} \\\\<br>    b_{h, 1} \\\\<br>    b_{x, 2} \\\\<br>    b_{y, 2} \\\\<br>    b_{w, 2} \\\\<br>    b_{h, 2} \\\\<br>    b_{x, (3, 1)} \\\\<br>    b_{y, (3, 1)} \\\\<br>    b_{w, (3, 1)} \\\\<br>    b_{h, (3, 1)} \\\\<br>    b_{x, (3, 2)} \\\\<br>    b_{y, (3, 2)} \\\\<br>    b_{w, (3, 2)} \\\\<br>    b_{h, (3, 2)}<br>    \end{matrix}<br>\right]<br>\]</p>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/13/消失的梯度/">
                消失的梯度
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-13</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>这篇博文的主要灵感是来自 sleebapaul 的 <a href="https://github.com/sleebapaul/vanishing_gradients" target="_blank" rel="external">vanishing gradients</a>，但是他的那篇博文存在大量的公式推导错误，因此主要借鉴了他的一些图片。</p>
<p>This is a discussion on an old problem that hindered the Machine Learning research for decades, now partially solved using various methods discovered in last 10 years. </p>
<center><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/vanishing_grad/neural_network_shallow.png" alt="neural_network_shallow"></center>

<h3 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h3><p>\[<br>\begin{split}<br>    Z_1 &amp; = W_1 \times X \\\\<br>    A_1 &amp; = g(Z_1) \\\\<br>    Z_2 &amp; = W_2 \times A_1 \\\\<br>    A_2 &amp; = g(Z_2) \\\\<br>    Z_3 &amp; = W_3 \times A_2 \\\\<br>    A_3 &amp; = g(Z_3) \\\\<br>    J &amp; = \sum A_3 - y<br>\end{split}<br>\]<br>\( X \) \( Z_1 \) \( A_1 \) \( Z_2 \) \( A_2 \) \( Z_3 \) \( A_3\) \( y \) 都是列向量，这样的假设不仅适用于全连接神经网络，也适用于卷积神经网络，因为卷积运算也可以展开为这样的形式，具体的可以看我的另外一篇博文<a href="https://robertlexis.github.io/2018/08/08/转置卷积-Transposed-Convolution/" target="_blank" rel="external">转置卷积 Transposed Convolution</a>。</p>
<h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p>\( g \) 是激活函数，是 element-wise 地对输入进行激活的，因此其导数 \( g^\prime \) 也是 element-wise 地发挥作用的。<br>即 \( g(z) \)、\( g^\prime(z) \)、\( z \) 的 shape 是相同的。\( g^\prime(z) \) 在公式中与其他项是 element-wise 相乘（用 \( \cdot \) 表示）而不是矩阵相乘（用 \( \times \) 表示）。<br>\[<br>\begin{split}<br>    \frac{\partial J}{\partial J} &amp; = 1 \\\ <br>    \frac{\partial J}{\partial A_3} &amp; = \mathbf{1} \\\ <br>    \frac{\partial J}{\partial Z_3} &amp; = \frac{\partial J}{\partial A_3} \frac{\partial A_3}{\partial Z_3} \\\\<br>    &amp; = \mathbf{1} \cdot g^\prime(Z_3) \\\\<br>    \frac{\partial J}{\partial A_2} &amp; = \frac{\partial J}{\partial Z_3} \frac{\partial Z_3}{\partial A_2} \\\\<br>    &amp; = {W_3}^T \times (\mathbf{1} \cdot g^\prime(Z_3)) \\\\<br>    \frac{\partial J}{\partial Z_2} &amp; = \frac{\partial J}{\partial A_2} \frac{\partial A_2}{\partial Z_2} \\\\<br>    &amp; = ({W_3}^T \times (\mathbf{1} \cdot g^\prime(Z_3))) \cdot g^\prime(Z_2) \\\\<br>    \frac{\partial J}{\partial A_1} &amp; = \frac{\partial J}{\partial Z_2} \frac{\partial Z_2}{\partial A_1} \\\\<br>    &amp; = {W_2}^T \times (({W_3}^T \times (\mathbf{1} \cdot g^\prime(Z_3))) \cdot g^\prime(Z_2)) \\\\<br>    \frac{\partial J}{\partial Z_1} &amp; = \frac{\partial J}{\partial A_1} \frac{\partial A_1}{\partial Z_1} \\\\<br>    &amp; = ({W_2}^T \times (({W_3}^T \times (\mathbf{1} \cdot g^\prime(Z_3))) \cdot g^\prime(Z_2))) \cdot g^\prime(Z_1) \\\\<br>    \frac{\partial J}{\partial X} &amp; = \frac{\partial J}{\partial Z_1} \frac{\partial Z_1}{\partial X} \\\\<br>    &amp; = {W_1}^T \times (({W_2}^T \times (({W_3}^T \times (\mathbf{1} \cdot g^\prime(Z_3))) \cdot g^\prime(Z_2))) \cdot g^\prime(Z_1)) \\\\<br>\end{split}<br>\]</p>
<p><hr><br>\[<br>\begin{split}<br>    \frac{\partial J}{\partial W_3} &amp; = \frac{\partial J}{\partial Z_3} \frac{\partial Z_3}{\partial W_3} \\\\<br>    &amp; = \frac{\partial J}{\partial Z_3} \times {A_2}^T \\\\<br>    &amp; = (\mathbf{1} \cdot g^\prime(Z_3)) \times {A_2}^T \\\\<br>    &amp; = (\mathbf{1} \cdot g^\prime(Z_3)) \times g(W_2 \times g(W_1 \times X))^T \\\\<br>    \frac{\partial J}{\partial W_2} &amp; = \frac{\partial J}{\partial Z_2} \frac{\partial Z_2}{\partial W_2} \\\\<br>    &amp; = \frac{\partial J}{\partial Z_2} \times {A_1}^T \\\\<br>    &amp; = (({W_3}^T \times (\mathbf{1} \cdot g^\prime(Z_3))) \cdot g^\prime(Z_2)) \times {A_1}^T \\\\<br>    &amp; = (({W_3}^T \times (\mathbf{1} \cdot g^\prime(Z_3))) \cdot g^\prime(Z_2)) \times {g(W_1 \times X)}^T \\\\<br>    \frac{\partial J}{\partial W_1} &amp; = \frac{\partial J}{\partial Z_1} \frac{\partial Z_1}{\partial W_1} \\\\<br>    &amp; = \frac{\partial J}{\partial Z_1} \times {X}^T \\\\<br>    &amp; = (({W_2}^T \times (({W_3}^T \times (\mathbf{1} \cdot g^\prime(Z_3))) \cdot g^\prime(Z_2))) \cdot g^\prime(Z_1)) \times {X}^T<br>\end{split}<br>\]<br>We call this Chain rule in calculus.<br>Now, what is essentially “back propagated”? It’s the gradients which represents the rate at which the error changes with respect to the change of parameters in each layer! 即每一层参数的变化引起误差变化的大小，每一层参数的变化对误差变化的贡献。</p>
<h3 id="梯度弥散"><a href="#梯度弥散" class="headerlink" title="梯度弥散"></a>梯度弥散</h3><center><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/vanishing_grad/sigmoid.png" alt="sigmoid"></center>

<p>\[<br>\begin{split}<br>    {0.99}^3 &amp; = 0.970299 \\\\<br>    {0.99}^7 &amp; = 0.9320653479 \\\\<br>    {0.99}^{100} &amp; = 0.36603234127 \\\\<br>    {0.99}^{300} &amp; = 0.04904089407 \\\\<br>\end{split}<br>\]<br>As we propagate away from final layer, the perturbation on network output will not reach the layers, even if reaches, the gradient will be too feeble to make an update. This issue get worsened when number of layers increases. Very deep networks often have a gradient signal that goes to zero quickly because of this reason, thus making gradient descent unbearably slow. </p>
<p>More specifically, during gradient descent, as we backprop from the final layer back to the first layer, we are multiplying by the weight matrix on each step, and thus the gradient can decrease exponentially quickly to zero. Gradient based methods learn a parameter’s value by understanding how a small change in the parameter’s value will affect the network’s output. If a change in the parameter’s value causes very small change in the network’s output-the network just can’t learn the parameter effectively.</p>
<center><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/vanishing_grad/vanishing_grad.png" alt="vanishing_grad"></center>

<p><small>The speed of learning decreases very rapidly for the early layers as the network trains.</small></p>
<h3 id="改进措施"><a href="#改进措施" class="headerlink" title="改进措施"></a>改进措施</h3><h5 id="Initializing-the-weights-with-standard-techniques-like-Xavier-Intialization"><a href="#Initializing-the-weights-with-standard-techniques-like-Xavier-Intialization" class="headerlink" title="Initializing the weights with standard techniques like Xavier Intialization"></a>Initializing the weights with standard techniques like Xavier Intialization</h5><p>Initializing weights properly can reduce to some extend since the fact both too high or too low weights can result in exploding/vanishing gradients.</p>
<h5 id="The-curse-of-Sigmoids-and-Tanhs"><a href="#The-curse-of-Sigmoids-and-Tanhs" class="headerlink" title="The curse of Sigmoids and Tanhs"></a>The curse of Sigmoids and Tanhs</h5><p><center><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/vanishing_grad/sigmoid_derivative.png" alt="sigmoid_derivative"></center><br>Let’s make some observations from these graphs.</p>
<ol>
<li>Sigmoid is confined to the interval [0, 1], the output will be always between these interval for any input. If we consider to initialize the weights as big as say  [−400, 400], after the activation, that will a binay matrix. High values tend to 1 and low values to 0. This will make derivatives zero and thus vanishing gradients.</li>
<li>The maximum value of derivative of sigmoid function is 0.25. So by default, the input weights get \( {\frac{1}{4}}{th}\) of the original value on calculating the gradients.<br>Same are applicable to tanh which is an extended sigmoid.<br><strong>So the take away is don’t use them.</strong></li>
</ol>
<h5 id="Dying-ReLUs"><a href="#Dying-ReLUs" class="headerlink" title="Dying ReLUs"></a>Dying ReLUs</h5><p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/vanishing_grad/relu.png" alt="relu"></p>
<ol>
<li>ReLUs don’t suffer from limited interval problem like sigmoid. The minimum value is 0 but there is no limit for maximum value.</li>
<li>If the input value is less than zero, then output and derivative are zero.<br>This will eliminate all the negative inputs which is okay. But derivatives getting zero is a problem. This means, in the entire training, that neuron which can’t fire above zero will remain unlearned or dead.</li>
</ol>
<p>So, ReLU is also not the perfect solution, but provides a great relief.</p>
<h5 id="ResNets"><a href="#ResNets" class="headerlink" title="ResNets"></a>ResNets</h5><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/11/MobileNet-V1-and-V2-带来的卷积结构革命/">
                MobileNet V1 and V2 带来的卷积结构革命
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-11</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>主要总结了轻量级深度卷积神经网络 MobileNet V1 &amp; V2 的关键贡献 separable convolution 和 inverted resisual &amp; linear bottlenecks。</p>
<h3 id="MobileNet-V1"><a href="#MobileNet-V1" class="headerlink" title="MobileNet V1"></a>MobileNet V1</h3><p><a href="https://arxiv.org/abs/1704.04861" target="_blank" rel="external">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a><br>提出了<strong>可分离卷积结构（separable convolution）</strong>来代替传统的卷积结构，可以在很小的精度损失下有效地减少网络参数，适合于在移动端和嵌入式环境下构建轻量级深度卷积神经网络。</p>
<blockquote>
<p>A standard convolution both filters and combines inputs into a new set of outputs in one step. The depthwise separable convolution splits this into two layers, a separate layer for filtering and a separate layer for combining.</p>
<p>Depthwise separable convolution are made up of two layers: depthwise convolutions and pointwise convolutions. We use depthwise convolutions to apply a single filter per each input channel (input depth). Pointwise convolution, a simple 1×1 convolution, is then used to create a linear combination of the output of the depthwise layer. MobileNets use both batchnorm and ReLU nonlinearities for both layers.</p>
<p>MobileNet uses 3 × 3 depthwise separable convolutions which uses between 8 to 9 times less computation than standard convolutions at only a small reduction in accuracy.</p>
</blockquote>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/mobilenet/separable_convolution.png" alt="separable_convolution"><br><strong>可分离卷积结构可以替代标准卷积结构在各种各样的卷积神经网络中作为基础卷积结构，实现卷积神经网络的轻量化。</strong></p>
<h5 id="MobileNet-可分离卷积的官方实现（去掉关于-namescope-的代码）"><a href="#MobileNet-可分离卷积的官方实现（去掉关于-namescope-的代码）" class="headerlink" title="MobileNet 可分离卷积的官方实现（去掉关于 namescope 的代码）"></a>MobileNet 可分离卷积的官方实现（去掉关于 namescope 的代码）</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_separable_conv2d</span><span class="params">(input_tensor,</span></span></div><div class="line"><span class="function"><span class="params">                           num_outputs,</span></span></div><div class="line"><span class="function"><span class="params">                           normalizer_fn=None,</span></span></div><div class="line"><span class="function"><span class="params">                           stride=<span class="number">1</span>,</span></span></div><div class="line"><span class="function"><span class="params">                           rate=<span class="number">1</span>)</span>:</span></div><div class="line">    <span class="string">"""Separable mobilenet V1 style convolution.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Depthwise convolution, with default non-linearity (relu),</span></div><div class="line"><span class="string">    followed by 1x1 depthwise convolution.  This is similar to</span></div><div class="line"><span class="string">    slim.separable_conv2d, but differs in that it applies batch</span></div><div class="line"><span class="string">    normalization and non-linearity to depthwise. This  matches</span></div><div class="line"><span class="string">    the basic building of Mobilenet Paper</span></div><div class="line"><span class="string">    (https://arxiv.org/abs/1704.04861)</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Args:</span></div><div class="line"><span class="string">      input_tensor: input</span></div><div class="line"><span class="string">      num_outputs: number of outputs</span></div><div class="line"><span class="string">      normalizer_fn: which normalizer function to use for depthwise/pointwise</span></div><div class="line"><span class="string">      stride: stride</span></div><div class="line"><span class="string">      rate: output rate (also known as dilation rate)</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Returns:</span></div><div class="line"><span class="string">        output tesnor</span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    kernel_size = [<span class="number">3</span>, <span class="number">3</span>]</div><div class="line">    padding = <span class="string">'SAME'</span></div><div class="line">    <span class="comment"># 设置 num_outputs = None，即仅做 depthwise convoltion，而不做 slim.separable_conv2d 中的 pointwise convolution，然后依次使用了 normalizer_fn 和 slim.separable_conv2d 的默认非线性激活函数（relu），符合论文给出的卷积结构。</span></div><div class="line">    net = slim.separable_conv2d(</div><div class="line">        input_tensor,</div><div class="line">        num_outputs=<span class="keyword">None</span>,</div><div class="line">        kernel_size,</div><div class="line">        depth_multiplier=<span class="number">1</span>,</div><div class="line">        stride=stride,</div><div class="line">        rate=rate,</div><div class="line">        normalizer_fn=normalizer_fn,</div><div class="line">        padding=padding)</div><div class="line"></div><div class="line">    <span class="comment"># 进行 pointwise convolution，然后依次使用了 normalizer_fn 和 slim.separable_conv2d 的默认非线性激活函数（relu），符合论文给出的卷积结构。</span></div><div class="line">    net = slim.conv2d(</div><div class="line">        net,</div><div class="line">        num_outputs, [<span class="number">1</span>, <span class="number">1</span>],</div><div class="line">        stride=<span class="number">1</span>,</div><div class="line">        normalizer_fn=normalizer_fn)</div><div class="line">  <span class="keyword">return</span> net</div></pre></td></tr></table></figure>
<p>slim.separable_conv2d 和 slim.conv2d 的<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py" target="_blank" rel="external">官方文档</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">slim.separable_conv2d(</div><div class="line">    inputs,</div><div class="line">    num_outputs,</div><div class="line">    kernel_size,</div><div class="line">    depth_multiplier=<span class="number">1</span>,</div><div class="line">    stride=<span class="number">1</span>,</div><div class="line">    padding=<span class="string">'SAME'</span>,</div><div class="line">    data_format=DATA_FORMAT_NHWC,</div><div class="line">    rate=<span class="number">1</span>,</div><div class="line">    activation_fn=nn.relu,</div><div class="line">    normalizer_fn=<span class="keyword">None</span>,</div><div class="line">    normalizer_params=<span class="keyword">None</span>,</div><div class="line">    ...)</div><div class="line"><span class="number">1.</span> This op first performs a depthwise convolution that acts separately on</div><div class="line">channels, creating a variable called `depthwise_weights`. </div><div class="line"><span class="number">2.</span> If `num_outputs` <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>, it adds a pointwise convolution that mixes channels, creating a</div><div class="line">variable called `pointwise_weights`. </div><div class="line"><span class="number">3.</span> Then, <span class="keyword">if</span> `normalizer_fn` <span class="keyword">is</span> <span class="keyword">None</span>, it adds bias to the result, creating a variable called <span class="string">'biases'</span>, otherwise, the `normalizer_fn` <span class="keyword">is</span> applied. </div><div class="line"><span class="number">4.</span> It <span class="keyword">finally</span> applies an activation function to produce the end result.</div><div class="line"></div><div class="line">slim.conv2d</div><div class="line"><span class="number">1.</span> creates a variable called `weights`, representing the convolutional kernel, that <span class="keyword">is</span> convolved (actually cross-correlated) <span class="keyword">with</span> the `inputs`.</div><div class="line"><span class="number">2.</span> If a `normalizer_fn` <span class="keyword">is</span> provided (such <span class="keyword">as</span> `batch_norm`), it <span class="keyword">is</span> then applied. Otherwise, <span class="keyword">if</span></div><div class="line">`normalizer_fn` <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">and</span> a `biases_initializer` <span class="keyword">is</span> provided then a `biases`</div><div class="line">variable would be created <span class="keyword">and</span> added the activations. </div><div class="line"><span class="number">3.</span> Finally, <span class="keyword">if</span> `activation_fn` <span class="keyword">is</span> <span class="keyword">not</span> `<span class="keyword">None</span>`, it <span class="keyword">is</span> applied to the activations <span class="keyword">as</span> well.</div></pre></td></tr></table></figure></p>
<h3 id="MobileNet-V2"><a href="#MobileNet-V2" class="headerlink" title="MobileNet V2"></a>MobileNet V2</h3><p><a href="https://arxiv.org/abs/1801.04381" target="_blank" rel="external">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></p>
<blockquote>
<p>Main contribution:<br>A novel layer module: the inverted residual with linear bottleneck. This module takes as an input a low-dimensional compressed representation which is first expanded to high dimension and filtered with a lightweight depthwise convolution. Features are subsequently projected back to a low-dimensional representation with a <strong>linear convolution</strong>.<br>总结起来就是一句话，利用 MobileNet V1 提出的可分离卷积结构的变种（去掉可分离卷积结构中 pointwise 之后的 relu）作为基础卷积结构，对 residual block 的变种进行了“加速降参”。</p>
</blockquote>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/mobilenet/inverted_residual.png" alt="inverted_residual"><br><small>Diagonally hatched layers do not use non-linearities. The thickness of each block to indicate its relative number of channels. Note how classical residuals connects the layers with high number of channels, whereas the inverted residuals connect the bottlenecks. </small></p>
<ol>
<li>为什么输入和输出的通道数目都被限制在较小的值？<br> The manifolds of interest in neural networks could be embedded in low-dimensional subspaces.</li>
<li>为什么扩张通道数？<br> 由下图可以看出不应该在低维空间内应用 relu，因为会造成信息的丢失，而又需要 relu 提供非线性，就只能在扩张通道数（升维）之后再使用 relu。<blockquote>
<p>The bottlenecks actually contain all the necessary information, while an expansion layer acts merely as an implementation detail that accompanies a non-linear transformation of the tensor. </p>
</blockquote>
</li>
</ol>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/mobilenet/why_remove_relu.png" alt="why_remove_relu"></p>
<ol>
<li>为什么去掉可分离卷积结构中 pointwise 之后的 relu？<br>不应该在低维空间内应用 relu，因为会造成信息的丢失</li>
</ol>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/mobilenet/inverted_residual_1.png" alt="inverted_residual_1"></p>
<p><strong>Inverted Residuals 指中间通道多两头通道少，Linear Bottlenecks 指两头都是线性激活之后得到的 feature map。</strong></p>
<h5 id="Inverted-Residuals-and-Linear-Bottlenecks-的官方实现（去掉关于-namescope-的代码）"><a href="#Inverted-Residuals-and-Linear-Bottlenecks-的官方实现（去掉关于-namescope-的代码）" class="headerlink" title="Inverted Residuals and Linear Bottlenecks 的官方实现（去掉关于 namescope 的代码）"></a>Inverted Residuals and Linear Bottlenecks 的官方实现（去掉关于 namescope 的代码）</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_make_divisible</span><span class="params">(v, divisor)</span>:</span></div><div class="line">    min_value = divisor</div><div class="line">    new_v = max(min_value, int(v + divisor / <span class="number">2</span>) // divisor * divisor)</div><div class="line">    <span class="comment"># Make sure that round down does not go down by more than 10%.</span></div><div class="line">    <span class="keyword">if</span> new_v &lt; <span class="number">0.9</span> * v:</div><div class="line">        new_v += divisor</div><div class="line">    <span class="keyword">return</span> new_v</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">expand_input_by_factor</span><span class="params">(n, divisible_by=<span class="number">8</span>)</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="keyword">lambda</span> num_inputs, **_: _make_divisible(num_inputs * n, divisible_by)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">expanded_conv</span><span class="params">(input_tensor,</span></span></div><div class="line"><span class="function"><span class="params">                  num_outputs,</span></span></div><div class="line"><span class="function"><span class="params">                  expansion_size=expand_input_by_factor<span class="params">(<span class="number">6</span>)</span>,</span></span></div><div class="line"><span class="function"><span class="params">                  stride=<span class="number">1</span>,</span></span></div><div class="line"><span class="function"><span class="params">                  rate=<span class="number">1</span>,</span></span></div><div class="line"><span class="function"><span class="params">                  kernel_size=<span class="params">(<span class="number">3</span>, <span class="number">3</span>)</span>,</span></span></div><div class="line"><span class="function"><span class="params">                  normalizer_fn=None,</span></span></div><div class="line"><span class="function"><span class="params">                  depthwise_channel_multiplier=<span class="number">1</span>,</span></span></div><div class="line"><span class="function"><span class="params">                  padding=<span class="string">'SAME'</span>)</span>:</span></div><div class="line">    <span class="string">"""Depthwise Convolution Block with expansion.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Builds a composite convolution that has the following structure</span></div><div class="line"><span class="string">    expansion (1x1) -&gt; depthwise (kernel_size) -&gt; projection (1x1)</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Args:</span></div><div class="line"><span class="string">        input_tensor: input</span></div><div class="line"><span class="string">        num_outputs: number of outputs in the final layer.</span></div><div class="line"><span class="string">        expansion_size: the size of expansion, could be a constant or a callable.</span></div><div class="line"><span class="string">            If latter it will be provided 'num_inputs' as an input. For forward</span></div><div class="line"><span class="string">            compatibility it should accept arbitrary keyword arguments.</span></div><div class="line"><span class="string">            Default will expand the input by factor of 6.</span></div><div class="line"><span class="string">        stride: depthwise stride</span></div><div class="line"><span class="string">        rate: depthwise rate</span></div><div class="line"><span class="string">        kernel_size: depthwise kernel</span></div><div class="line"><span class="string">        normalizer_fn: batchnorm or otherwise</span></div><div class="line"><span class="string">        depthwise_channel_multiplier: depthwise channel multiplier:</span></div><div class="line"><span class="string">        padding: Padding type to use</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Returns:</span></div><div class="line"><span class="string">        Tensor of depth num_outputs</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    prev_depth = input_tensor.get_shape().as_list()[<span class="number">3</span>]</div><div class="line"></div><div class="line">    <span class="comment"># 设置 num_outputs = None，即仅做 depthwise convoltion，而不做 slim.separable_conv2d 中的 pointwise convolution，然后依次使用了 normalizer_fn 和 slim.separable_conv2d 的默认非线性激活函数（relu），符合论文给出的卷积结构。</span></div><div class="line">    depthwise_func = functools.partial(</div><div class="line">        slim.separable_conv2d,</div><div class="line">        num_outputs=<span class="keyword">None</span>,</div><div class="line">        kernel_size=kernel_size,</div><div class="line">        depth_multiplier=depthwise_channel_multiplier,</div><div class="line">        stride=stride,</div><div class="line">        rate=rate,</div><div class="line">        normalizer_fn=normalizer_fn,</div><div class="line">        padding=padding)</div><div class="line"></div><div class="line">    net = input_tensor</div><div class="line"></div><div class="line">    <span class="comment"># expand</span></div><div class="line">    <span class="keyword">if</span> callable(expansion_size):</div><div class="line">      inner_size = expansion_size(num_inputs=prev_depth)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">      inner_size = expansion_size</div><div class="line">    <span class="keyword">if</span> inner_size &gt; net.shape[<span class="number">3</span>]:</div><div class="line">        net = slim.conv2d(net, inner_size, [<span class="number">1</span>, <span class="number">1</span>], stride=<span class="number">1</span>, normalizer_fn=normalizer_fn, padding=padding)</div><div class="line"></div><div class="line">    <span class="comment"># separable convolution</span></div><div class="line">    net = depthwise_func(net)</div><div class="line">    net = slim.conv2d(net, num_outputs, [<span class="number">1</span>, <span class="number">1</span>], stride=<span class="number">1</span>, normalizer_fn=normalizer_fn, activation_fn=<span class="keyword">None</span>, padding=padding)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> residual <span class="keyword">and</span> stride == <span class="number">1</span> <span class="keyword">and</span> net.get_shape().as_list()[<span class="number">3</span>] == prev_depth: </div><div class="line">      net += input_tensor</div><div class="line">    <span class="keyword">return</span> net</div></pre></td></tr></table></figure>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/09/卷积转置卷积关系在-TensorFLow-中的验证/">
                卷积转置卷积关系在 TensorFLow 中的验证
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-09</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>本文分别在 Numpy 和 TensorFlow 下实现了卷积和转置卷积的计算，并对卷积和转置卷积的参数关系进行了探讨。<br>本文代码的 Jupyter Notebook 可以在我的 <a href="https://github.com/RobertLexis/convolution_vs_transpose_convolution" target="_blank" rel="external">github 仓库</a>中找到。</p>
<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>正向传播：<br>\[<br>\mathbf{y} = \mathbf{C}\mathbf{x}<br>\]</p>
<h5 id="核及输入"><a href="#核及输入" class="headerlink" title="核及输入"></a>核及输入</h5><p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/transposeConvolution/convolution.gif" alt="convolution"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kernel = np.arange(1, 10).reshape((3, 3))</div></pre></td></tr></table></figure></p>
<p>\[<br>kernel =<br>\left[<br>    \begin{matrix}<br>    1 &amp; 2 &amp; 3 \\\\<br>    4 &amp; 5 &amp; 6 \\\\<br>    7 &amp; 8 &amp; 9<br>    \end{matrix}<br>\right]<br>\]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">C = np.array([[1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9, 0, 0, 0, 0, 0],</div><div class="line">              [0, 1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9, 0, 0, 0, 0],</div><div class="line">              [0, 0, 0, 0, 1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9, 0],</div><div class="line">              [0,  0, 0, 0, 0, 1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9]])</div></pre></td></tr></table></figure></p>
<p>\[<br>\mathbf{C} =<br>\left[<br>    \begin{matrix}<br>    1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\<br>    0 &amp; 1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\<br>    0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9 &amp; 0 \\\\<br>    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9<br>    \end{matrix}<br>\right]<br>\]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">input_ = np.arange(1, 17).reshape((4, 4))</div></pre></td></tr></table></figure></p>
<p>\[<br>input\_ =<br>\left[<br>    \begin{matrix}<br>    1 &amp; 2 &amp; 3 &amp; 4 \\\\<br>    5 &amp; 6 &amp; 7 &amp; 8 \\\\<br>    9 &amp; 10 &amp; 11 &amp; 12 \\\\<br>    13 &amp; 14 &amp; 15 &amp; 16<br>    \end{matrix}<br>\right]<br>\]</p>
<h5 id="卷积-in-Numpy"><a href="#卷积-in-Numpy" class="headerlink" title="卷积 in Numpy"></a>卷积 in Numpy</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">x = input_.reshape((-1, 1))</div></pre></td></tr></table></figure>
<p>\[<br>\mathbf{x} =<br>\left[<br>    \begin{matrix}<br>    1 \\\ <br>    2 \\\ <br>    3 \\\ <br>    4 \\\\<br>    5 \\\ <br>    6 \\\ <br>    7 \\\ <br>    8 \\\\<br>    9 \\\ <br>    10 \\\ <br>    11 \\\ <br>    12 \\\\<br>    13 \\\ <br>    14 \\\ <br>    15 \\\ <br>    16<br>    \end{matrix}<br>\right]<br>\]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">y = C.dot(x)</div></pre></td></tr></table></figure></p>
<p>\[<br>\mathbf{y} =<br>\left[<br>    \begin{matrix}<br>    348 \\\\<br>    393 \\\\<br>    528 \\\\<br>    573<br>    \end{matrix}<br>\right]<br>\]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">y = y.reshape((2, 2))</div></pre></td></tr></table></figure></p>
<p>\[<br>\mathbf{y} =<br>\left[<br>    \begin{matrix}<br>    348 &amp; 393 \\\\<br>    528 &amp; 573<br>    \end{matrix}<br>\right]<br>\]</p>
<h5 id="卷积-in-TensorFlow"><a href="#卷积-in-TensorFlow" class="headerlink" title="卷积 in TensorFlow"></a>卷积 in TensorFlow</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">x = tf.expand_dims(tf.expand_dims(tf.constant(input_, dtype=tf.float32), axis=-1), axis=0)</div><div class="line">x.get_shape().as_list()</div><div class="line">[1, 4, 4, 1]</div><div class="line"></div><div class="line">kernel_conv = tf.expand_dims(tf.expand_dims(tf.constant(kernel, dtype=tf.float32), axis=-1), axis=-1)</div><div class="line">kernel_conv.get_shape().as_list()</div><div class="line">[3, 3, 1, 1]</div><div class="line"></div><div class="line">y = tf.nn.conv2d(x, kernel_conv, strides=(1, 1, 1, 1), padding=&apos;VALID&apos;)</div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">    print(y.eval()[0, :, :, 0])</div><div class="line">[[348. 393.]</div><div class="line"> [528. 573.]]</div></pre></td></tr></table></figure>
<h4 id="转置卷积"><a href="#转置卷积" class="headerlink" title="转置卷积"></a>转置卷积</h4><p>正向传播：<br>\[<br>\mathbf{y} = \mathbf{C}^T\mathbf{x}<br>\]</p>
<h5 id="核及输入-1"><a href="#核及输入-1" class="headerlink" title="核及输入"></a>核及输入</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kernel = np.arange(1, 10).reshape((3, 3))</div></pre></td></tr></table></figure>
<p>\[<br>kernel =<br>\left[<br>    \begin{matrix}<br>    1 &amp; 2 &amp; 3 \\\\<br>    4 &amp; 5 &amp; 6 \\\\<br>    7 &amp; 8 &amp; 9<br>    \end{matrix}<br>\right]<br>\]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">C = np.array([[1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9, 0, 0, 0, 0, 0],</div><div class="line">              [0, 1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9, 0, 0, 0, 0],</div><div class="line">              [0, 0, 0, 0, 1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9, 0],</div><div class="line">              [0,  0, 0, 0, 0, 1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9]])</div></pre></td></tr></table></figure></p>
<p>\[<br>\mathbf{C} =<br>\left[<br>    \begin{matrix}<br>    1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\<br>    0 &amp; 1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\<br>    0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9 &amp; 0 \\\\<br>    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 0 &amp; 4 &amp; 5 &amp; 6 &amp; 0 &amp; 7 &amp; 8 &amp; 9<br>    \end{matrix}<br>\right]<br>\]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">C_T = C.T</div></pre></td></tr></table></figure></p>
<p>\[<br>\mathbf{C}^T =<br>\left[<br>    \begin{matrix}<br>       1 &amp; 0 &amp; 0 &amp; 0 \\\\<br>       2 &amp; 1 &amp; 0 &amp; 0 \\\\<br>       3 &amp; 2 &amp; 0 &amp; 0 \\\\<br>       0 &amp; 3 &amp; 0 &amp; 0 \\\\<br>       4 &amp; 0 &amp; 1 &amp; 0 \\\\<br>       5 &amp; 4 &amp; 2 &amp; 1 \\\\<br>       6 &amp; 5 &amp; 3 &amp; 2 \\\\<br>       0 &amp; 6 &amp; 0 &amp; 3 \\\\<br>       7 &amp; 0 &amp; 4 &amp; 0 \\\\<br>       8 &amp; 7 &amp; 5 &amp; 4 \\\\<br>       9 &amp; 8 &amp; 6 &amp; 5 \\\\<br>       0 &amp; 9 &amp; 0 &amp; 6 \\\\<br>       0 &amp; 0 &amp; 7 &amp; 0 \\\\<br>       0 &amp; 0 &amp; 8 &amp; 7 \\\\<br>       0 &amp; 0 &amp; 9 &amp; 8 \\\\<br>       0 &amp; 0 &amp; 0 &amp; 9<br>    \end{matrix}<br>\right]<br>\]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">input_ = np.arange(1, 5).reshape((2, 2))</div></pre></td></tr></table></figure>
<p>\[<br>input\_ =<br>\left[<br>    \begin{matrix}<br>    1 &amp; 2  \\\\<br>    3 &amp; 4<br>    \end{matrix}<br>\right]<br>\]</p>
<h5 id="转置卷积-in-Numpy"><a href="#转置卷积-in-Numpy" class="headerlink" title="转置卷积 in Numpy"></a>转置卷积 in Numpy</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">x = input_.reshape((-1, 1))</div></pre></td></tr></table></figure>
<p>\[<br>\mathbf{x} =<br>\left[<br>    \begin{matrix}<br>    1\\\\<br>    2\\\\<br>    3\\\\<br>    4<br>    \end{matrix}<br>\right]<br>\]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">y = C_T.dot(x)</div><div class="line">y = y.reshape(4, 4)</div></pre></td></tr></table></figure>
<p>\[<br>\mathbf{y} =<br>\left[<br>    \begin{matrix}<br>     1 &amp;  4 &amp;  7 &amp;  6 \\\\<br>     7 &amp; 23 &amp; 33 &amp; 24 \\\\<br>     19 &amp; 53 &amp; 63 &amp; 42 \\\\<br>     21 &amp; 52 &amp; 59 &amp; 36<br>    \end{matrix}<br>\right]<br>\]</p>
<h5 id="转置卷积-in-TensorFlow"><a href="#转置卷积-in-TensorFlow" class="headerlink" title="转置卷积 in TensorFlow"></a>转置卷积 in TensorFlow</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">x =  tf.expand_dims(tf.expand_dims(tf.constant(input_, dtype=tf.float32), axis=-1), axis=0)</div><div class="line">x.get_shape().as_list()</div><div class="line">[1, 2, 2, 1]</div><div class="line"></div><div class="line">kernel_transpose_conv = tf.expand_dims(tf.expand_dims(tf.constant(kernel, dtype=tf.float32), axis=-1), axis=-1)</div><div class="line">kernel_transpose_conv.get_shape().as_list()</div><div class="line">[3, 3, 1, 1]</div><div class="line"></div><div class="line">y = tf.nn.conv2d_transpose(x, kernel_transpose_conv, output_shape=(1, 4, 4, 1), strides=(1, 1, 1, 1), padding=&apos;VALID&apos;)</div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">    print(y.eval()[0, :, :, 0])</div><div class="line">[[ 1.  4.  7.  6.]</div><div class="line"> [ 7. 23. 33. 24.]</div><div class="line"> [19. 53. 63. 42.]</div><div class="line"> [21. 52. 59. 36.]]</div></pre></td></tr></table></figure>
<p>这里选择参数值 <code>strides=(1, 1, 1, 1), padding=&#39;VALID&#39;</code> 是因为转置卷积过程<code>[2, 2] -&gt; [4, 4]</code>对应的卷积过程<code>[4, 4] -&gt; [2, 2]</code>（见第一部分）的 <code>strides=(1, 1, 1, 1), padding=&#39;VALID&#39;</code>，即转置卷积过程的参数是由自身对应的卷积过程的参数确定的，要想在 shape 上做到“逆”，两者的参数必须一致。<code>[2, 2] &lt;-&gt; [4, 4]</code>来回转换的参数需一致，包括 kernel 的shape。</p>
<p>假设 kernel shape <code>[3, 3]</code>，<code>conv2d_transpose</code> 的输入 shape <code>[2, 2]</code>，<code>strides=(1, 1, 1, 1)</code>，而 <code>padding=&#39;SAME&#39;</code>，是不可能得到 <code>output_shape=(1, 4, 4, 1)</code> 的，这是因为 <code>conv2d</code> 在<code>strides=(1, 1, 1, 1), padding=&#39;SAME&#39;</code>，kernel shape <code>[3, 3]</code>，输入是 <code>(1, 4, 4, 1)</code>时，得到的卷积结果 shape 是 <code>[4, 4]</code> ，而不是 <code>conv2d_transpose</code> 输入的 <code>[2, 2]</code>，即卷积操作的输出 shape 和转置卷积的输入 shape 不匹配，会导致 <code>conv2d_transpose</code> 报错。</p>
<h3 id="shape-计算"><a href="#shape-计算" class="headerlink" title="shape 计算"></a>shape 计算</h3><h5 id="卷积-1"><a href="#卷积-1" class="headerlink" title="卷积"></a>卷积</h5><p>padding == “SAME” （有 padding）<br>\[<br>    output\_shape[i] = ceil(input\_shape[i] / strides[i])<br>\]<br>padding == “VALID” （无 padding）<br>\[<br>    output\_shape[i] = ceil((input\_shape[i] - filter\_shape[i] + 1) * dilation\_rate[i] / strides[i])<br>\]</p>
<h5 id="转置卷积-1"><a href="#转置卷积-1" class="headerlink" title="转置卷积"></a>转置卷积</h5><p>\[<br>new\_rows = (rows - 1) \times strides[0] + kernel\_size[0] - 2 \times padding[0] + output\_padding[0]<br>\\\\<br>new\_cols = (cols - 1) \times strides[1] + kernel\_size[1] - 2 \times padding[1] + output\_padding[1]<br>\]</p>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/08/转置卷积-Transposed-Convolution/">
                转置卷积 Transposed Convolution
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-08</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>转置卷积在 Fully Convolutional Network (FCN) 结构的卷积神经网络中完成“上采样”。<br><strong>转置卷积</strong>与<strong>卷积</strong>在神经网络结构的正向和反向传播中正好做着相反的运算。</p>
<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>4x4 的输入（蓝色），3x3 的卷积核, 2x2 的输出为（绿色）。</p>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/transposeConvolution/convolution.gif" alt="convolution"></p>
<p>卷积操作过程可以如下计算： </p>
<p>输入矩阵展开为 \( 4 \times 4 = 16 \) 维（列）向量，记作 \( \mathbf{x} \)。 </p>
<p>输出矩阵展开为 \( 2 \times 2 = 4 \) 维（列）向量，记作 \( \mathbf{y} \)。 </p>
<p>卷积核扩展为如下的形式 \( \mathbf{C} \)，注意这个矩阵并不是<a href="https://en.wikipedia.org/wiki/Toeplitz_matrix" target="_blank" rel="external">托普利兹矩阵（Toeplitz matrix）</a>：</p>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/transposeConvolution/kernel.png" alt="kernel"> </p>
<h5 id="正向传播"><a href="#正向传播" class="headerlink" title="正向传播"></a>正向传播</h5><p>卷积神经网络的正向传播就转换为：<br>\[ \mathbf{y} = \mathbf{C} \mathbf{x} \]<br>左乘 \( \mathbf{C} \)。</p>
<h5 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h5><p>\[<br>\begin{split}<br>\frac{\partial loss}{\partial x_i} &amp; = \sum_{j}\frac{\partial loss}{\partial y_j}\frac{\partial y_j}{\partial x_i} \\\\<br>&amp; = \sum_{j}\frac{\partial loss}{\partial y_j}C_{j, i} \\\\<br>&amp; = C_{*, i}^{T}\frac{\partial loss}{\partial y}<br>\end{split}<br>\]<br>即<br>\[<br>\frac{\partial loss}{\partial x} = C^T\frac{\partial loss}{\partial y}<br>\]</p>
<p>左乘 \( C^T \)。</p>
<h3 id="转置卷积"><a href="#转置卷积" class="headerlink" title="转置卷积"></a>转置卷积</h3><blockquote>
<p>Transposed convolutions – also called fractionally strided convolutions or deconvolutions – work by swapping the forward and backward passes of a convolution.<a href="https://arxiv.org/pdf/1603.07285.pdf" target="_blank" rel="external"><font size="2">1</font></a></p>
<p>The term “deconvolution” is sometimes used in the literature, but we advocate against it on the grounds that a deconvolution is mathematically defined as the inverse of a convolution, which is different from a transposed convolution.<a href="https://arxiv.org/pdf/1603.07285.pdf" target="_blank" rel="external"><font size="2">1</font></a></p>
</blockquote>
<p>转置卷积核扩展为如下的形式 \( \mathbf{C} \)，注意这个矩阵并不是<a href="https://en.wikipedia.org/wiki/Toeplitz_matrix" target="_blank" rel="external">托普利兹矩阵（Toeplitz matrix）</a>：<br><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/transposeConvolution/kernel.png" alt="kernel"> </p>
<h5 id="正向传播-1"><a href="#正向传播-1" class="headerlink" title="正向传播"></a>正向传播</h5><p>\[ \mathbf{y} = \mathbf{C}^T \mathbf{x} \]<br>左乘 \( \mathbf{C}^T \)。</p>
<h5 id="反向传播-1"><a href="#反向传播-1" class="headerlink" title="反向传播"></a>反向传播</h5><p>\[<br>\begin{split}<br>\frac{\partial loss}{\partial x} &amp; = (C^T)^T\frac{\partial loss}{\partial y} \\\\<br>&amp; = C\frac{\partial loss}{\partial y}<br>\end{split}<br>\]<br>左乘 \( C \)。</p>
<p>综上，转置卷积不是逆卷积，在信号处理中逆卷积是输入经过卷积的信号，还原出经过卷积之前的原始信号的操作。而神经网络中卷积和逆卷积仅仅分别是对输入左乘\( \mathbf{C} \) 和 \( \mathbf{C}^T\) 。</p>
<h3 id="两者的联系"><a href="#两者的联系" class="headerlink" title="两者的联系"></a>两者的联系</h3><p>就像论文 <a href="https://arxiv.org/pdf/1603.07285.pdf" target="_blank" rel="external">A guide to convolution arithmetic for deep learning</a> 中讲到的，一个核定义了一个卷积操作，但是它是一个直接卷积（ direct convolution ）还是一个转置卷积（ transposed convolution ）取决于正向传播和反向传播是如何计算的。</p>
<blockquote>
<p>One way to put it is to note that the kernel defines a convolution, but whether it’s a direct convolution or a transposed convolution is determined by how the forward and backward passes are computed. </p>
<p>For instance, although the kernel \( \mathbf{w} \) defines a convolution whose forward and backward passes are computed by multiplying with \( \mathbf{C} \) and \( \mathbf{C}^T \) respectively, it also defines a transposed convolution whose forward and backward passes are computed by multiplying with \( \mathbf{C}^T \) and  \( (\mathbf{C}^T)^T = \mathbf{C} \) respectively.</p>
</blockquote>
<p>另外需要注意的一点是，总是可以通过一个直接卷积（ direct convolution ）来模拟一个转置卷积（ transposed convolution ），但是这种方式的一个缺点是通常会在输入中引入大量的零行和零列，导致计算效率的降低。</p>
<blockquote>
<p>Finally note that it is always possible to emulate a transposed convolution with a direct convolution. The disadvantage is that it usually involves adding many columns and rows of zeros to the input, resulting in a much less efficient implementation.</p>
</blockquote>
<h5 id="直接卷积模拟转置卷积"><a href="#直接卷积模拟转置卷积" class="headerlink" title="直接卷积模拟转置卷积"></a>直接卷积模拟转置卷积</h5><p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/transposeConvolution/transpose_convolution.gif" alt="transpose convolution"> </p>
<ol>
<li>对输入 \( \mathbf{x} \) (1)进行补零得到 \( \tilde{\mathbf{x}} \)；</li>
<li>对核 \( \mathbf{w} \) (2) 进行左右翻转上下翻转得到新的核 \( \tilde{\mathbf{w}} \) (3)；</li>
<li>利用核 \( \tilde{\mathbf{w}} \) 对  \( \tilde{\mathbf{x}} \) 进行卷积，如上面的动图所示。</li>
</ol>
<p>\[<br> \left\{<br> \begin{matrix}<br>   x_0 &amp; x_1 \\\\<br>   x_2 &amp; x_3<br>  \end{matrix}<br>  \right\}\tag{1}<br>\]<br>\[<br> \left\{<br> \begin{matrix}<br>   w_{00} &amp; w_{01} &amp; w_{02} \\\\<br>   w_{10} &amp; w_{11} &amp; w_{12} \\\\<br>   w_{20} &amp; w_{21} &amp; w_{22}<br>  \end{matrix}<br>  \right\}\tag{2}<br>\]<br>\[<br> \left\{<br> \begin{matrix}<br>   w_{22} &amp; w_{21} &amp; w_{20} \\\\<br>   w_{12} &amp; w_{11} &amp; w_{10} \\\\<br>   w_{02} &amp; w_{01} &amp; w_{00}<br>  \end{matrix}<br>  \right\}\tag{3}<br>\]</p>
<p>由图可以看出：</p>
<ol>
<li>\( y_0 = w_{00} \cdot x_0 \)</li>
<li>\( y_1 = w_{01} \cdot x_0 + w_{00} \cdot x_1 \)</li>
<li>\( y_2 = w_{02} \cdot x_0 + w_{01} \cdot x_1 \)</li>
<li>\( y_3 = w_{02} \cdot x_1 \)</li>
<li>以此类推</li>
</ol>
<p>在结果上等效于转置卷积的定义式：</p>
<p>\[<br> \left[<br> \begin{matrix}<br>   w_{00} &amp; 0      &amp; 0      &amp; 0      \\\\<br>   w_{01} &amp; w_{00} &amp; 0      &amp; 0      \\\\<br>   w_{02} &amp; w_{01} &amp; 0      &amp; 0      \\\\<br>   0      &amp; w_{02} &amp; 0      &amp; 0      \\\\<br>   w_{10} &amp; 0      &amp; w_{00} &amp; 0      \\\\<br>   w_{11} &amp; w_{10} &amp; w_{01} &amp; w_{00} \\\\<br>   w_{12} &amp; w_{11} &amp; w_{02} &amp; w_{01} \\\\<br>   0      &amp; w_{12} &amp; 0      &amp; w_{02} \\\\<br>   w_{20} &amp; 0      &amp; w_{10} &amp; 0      \\\\<br>   w_{21} &amp; w_{20} &amp; w_{11} &amp; w_{10} \\\\<br>   w_{22} &amp; w_{21} &amp; w_{12} &amp; w_{11} \\\\<br>   0      &amp; w_{22} &amp; 0      &amp; w_{12} \\\\<br>   0      &amp; 0      &amp; w_{20} &amp; 0      \\\\<br>   0      &amp; 0      &amp; w_{21} &amp; w_{20} \\\\<br>   0      &amp; 0      &amp; w_{22} &amp; w_{21} \\\\<br>   0      &amp; 0      &amp; 0      &amp; w_{22}<br>  \end{matrix}<br>  \right]<br>  \cdot<br>  \left[<br>  \begin{matrix}<br>   x_0 \\\\<br>   x_1 \\\\<br>   x_2 \\\\<br>   x_3<br>  \end{matrix}<br>  \right]<br>\]</p>
<p><font size="2">[1] A guide to convolution arithmetic for deep learning</font></p>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/08/Nvidia-TensorRT-推理加速引擎支持的Layers/">
                Nvidia TensorRT 推理加速引擎支持的Layers
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-08</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h3 id="Supported-Operations-By-Framework"><a href="#Supported-Operations-By-Framework" class="headerlink" title="Supported Operations By Framework"></a>Supported Operations By Framework</h3><p>由<a href="https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#support_op" target="_blank" rel="external">TensorRT 开发者指南</a>可以得知，并不是 Keras 或者 TensorFlow 支持的操作都被 TensorRT 所支持。<br>截止目前[2018/08/08]，TensorRT 支持的 TensorFlow 操作有：</p>
<ul>
<li>Placeholder</li>
<li>Const</li>
<li>Add, Sub, Mul, Div, Minimum and Maximum</li>
<li>BiasAdd</li>
<li>Negative, Abs, Sqrt, Rsqrt, Pow, Exp and Log</li>
<li>FusedBatchNorm</li>
<li>ReLU, TanH, Sigmoid</li>
<li>SoftMax</li>
<li>Mean</li>
<li>ConcatV2</li>
<li>Reshape</li>
<li>Transpose</li>
<li>Conv2D</li>
<li>DepthwiseConv2dNative</li>
<li>ConvTranspose2D</li>
<li>MaxPool</li>
<li>AvgPool</li>
<li>Pad is supported if followed by one of these TensorFlow layers: Conv2D, DepthwiseConv2dNative, MaxPool, and AvgPool</li>
</ul>
<p>在项目实践中，Keras 的 <code>Lambda</code> 和 <code>UpSampling2D</code>（底层是 TensorFlow 的 <code>tf.image.resize_nearest_neighbor -&gt; tensorflow::ops::ResizeNearestNeighbor</code>）并不被 TensorRT 所支持，这在实现 Stacked Hourglass Networks 时造成了困难。特别是 <code>Lambda</code>层 ，在 frozen graph 到 uff 的转化过程中，由于 UFFParser 不能正确地解析 <code>Lambda</code> 层的输入，从而不能正确地对 frozen graph 计算图进行广度优先遍历（使用队列数据结构）转化操作节点，造成解析过程错误中断。至于上采样，目前是使用 <code>Conv2DTranspose</code> 完成的，这样相较于 <code>UpSampling2D</code> 会增加一部分可训练参数，使模型变得“更重”。</p>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/08/OpenCV-Python-C-与Scikit-image在BGR-RGB转灰度图上的不同/">
                OpenCV(Python & C++)与Scikit-image在BGR/RGB转灰度图上的不同
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-08</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>将主机 Python 环境下训练的卷积神经网络模型移植到 Jetson TX2 的 TensorRT 加速环境（C++）下时，遇到了模型精度损失的问题，发现是由于 Python Scikit-image 中函数 <code>color.rgb2gray</code> 与 C++ OpenCV 中函数 <code>cv::cvtColor(cv::InputArray src, cv::OutputArray dst, cv::COLOR_BGR2GRAY)</code> 的彩色图转灰度图的转换函数定义不同，分别如下：</p>
<h3 id="OpenCV"><a href="#OpenCV" class="headerlink" title="OpenCV"></a>OpenCV</h3><p>\[ Y = 0.299 \times R + 0.587 \times G + 0.114 \times B \]</p>
<h3 id="Scikit-image"><a href="#Scikit-image" class="headerlink" title="Scikit-image"></a>Scikit-image</h3><p>\[ Y = 0.2125 \times R + 0.7154 \times G + 0.0721 \times B \]</p>
<h3 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h3><p>由于模型训练时，RGB 转灰度图的预处理是由 Scikit-image  <code>color.rgb2gray</code> 完成的，因此在将模型部署到 Jetson TX2 时使用 C++ OpenCV 时，需要按照 Scikit-image <code>color.rgb2gray</code> 的公式自主实现 RGB 转灰度图，而不是直接使用 OpenCV 的 <code>cv::cvtColor(cv::InputArray src, cv::OutputArray dst, cv::COLOR_BGR2GRAY)</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">cv::Mat skimageBGR2GRAY(const cv::Mat &amp; img) &#123;</div><div class="line">    cv::Mat image;</div><div class="line">    if (img.type() != CV_32FC3) &#123;</div><div class="line">        img.convertTo(image, CV_32FC3);</div><div class="line">    &#125;</div><div class="line">    else &#123;</div><div class="line">        image = img;</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    std::vector&lt;cv::Mat&gt; channels;</div><div class="line">    cv::split(image, channels);</div><div class="line">    cv::Mat B = channels.at(0);</div><div class="line">    cv::Mat G = channels.at(1);</div><div class="line">    cv::Mat R = channels.at(2);</div><div class="line">    cv::Mat grayImage = (0.0721 * B + 0.7154 * G + 0.2125 * R) / 255;</div><div class="line">    </div><div class="line">    return grayImage;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上面的代码首先进行了 <code>cv::Mat</code> 元素数据类型转换，将由 <code>cv::imread(imageFilename, CV_LOAD_IMAGE_COLOR)</code> 读取到的 <code>CV_8UC3</code> 矩阵转换为 <code>CV_32FC3</code>，避免在计算过程中由于数据类型的截断造成精度的损失，由此得到的 <code>grayImage</code> 的元素数据类型为 <code>CV_32FC1</code>，取值范围<code>[0, 1]</code>。</p>
<p>这里需要注意的是，以下函数</p>
<ul>
<li><code>cv2.imread</code></li>
<li><code>cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</code></li>
<li><code>cv::imread(imageFilename, CV_LOAD_IMAGE_COLOR)</code></li>
<li><code>cv::cvtColor(cv::InputArray src, cv::OutputArray dst, cv::COLOR_BGR2GRAY)</code></li>
<li><code>skimage.io.imread</code></li>
<li><code>skimage.color.rgb2gray</code></li>
</ul>
<p>的结果的数据类型，可能发生的数据类型隐式转换和数据类型截断会影响到计算精度。</p>
<p><code>cv2.imread</code>，<code>cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</code>，<code>cv::imread(imageFilename, CV_LOAD_IMAGE_COLOR)</code>，<code>cv::cvtColor(cv::InputArray src, cv::OutputArray dst, cv::COLOR_BGR2GRAY)</code> 结果的数据类型是 <code>uint8</code> ，取值范围是 [0, 255]。<br><code>skimage.io.imread</code> 结果的数据类型是 <code>uint8</code>，取值范围是 [0, 255]；<code>skimage.color.rgb2gray</code> 结果的数据类型是 <code>float64</code>，取值范围是 <code>[0, 1]</code>。</p>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2018/08/03/TensorRT-加速-Keras-模型在-Jetson-上的推理/">
                TensorRT 加速 Keras 模型在 Jetson 上的推理
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-08-03</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>将一个训练好的 Keras 模型通过 TensorRT 加速并 Push 到 Jetson TX2 上的流程框图如下：<br><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/tensorRT/flowchart.png" alt="flowchart"><br>下面对一些关键代码及步骤进行解释：</p>
<h3 id="Keras-model-to-Tensorflow-frozen-graph"><a href="#Keras-model-to-Tensorflow-frozen-graph" class="headerlink" title="Keras model to Tensorflow frozen graph"></a>Keras model to Tensorflow frozen graph</h3><p>这一步可以在任意一台机器上完成，不限于 Jetson TX2 或者其 Host PC 上，只要配置了 tensorflow 和 keras 即可。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> model_from_json</div><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</div><div class="line"><span class="keyword">import</span> os </div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">keras_to_frozen</span><span class="params">(model_file, weights_file)</span>:</span></div><div class="line">    <span class="comment"># load keras model and weights</span></div><div class="line">    <span class="keyword">with</span> open(model_file, <span class="string">'r'</span>) <span class="keyword">as</span> f:</div><div class="line">        json_string = f.read()</div><div class="line">    K.set_learning_phase(<span class="number">0</span>)</div><div class="line">    </div><div class="line">    model = model_from_json(json_string)</div><div class="line">    model.load_weights(weights_file)</div><div class="line"></div><div class="line">    <span class="comment"># rename output nodes</span></div><div class="line">    output_node_prefix = <span class="string">'output_node_'</span></div><div class="line">    output_node_names = []</div><div class="line">    output_nodes = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(model.outputs)):</div><div class="line">        output_node_name = output_node_prefix + str(i)</div><div class="line">        output_nodes.append(tf.identity(model.outputs[i],  name=output_node_name))</div><div class="line">        output_node_names.append(output_node_name)</div><div class="line">    print(<span class="string">'output node names are: '</span>, output_node_names)</div><div class="line"></div><div class="line">    <span class="comment"># freeze the graph</span></div><div class="line">    sess = K.get_session()</div><div class="line">    constant_graph = tf.graph_util.convert_variables_to_constants(sess=sess, </div><div class="line">                                                              input_graph_def=sess.graph.as_graph_def(), </div><div class="line">                                                              output_node_names=output_node_names)</div><div class="line">    <span class="comment"># write graph as pb</span></div><div class="line">    output_dir = <span class="string">'frozen_graph'</span></div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(output_dir):</div><div class="line">        os.mkdir(output_dir)</div><div class="line">    filename = <span class="string">'model.pb'</span></div><div class="line">    <span class="keyword">return</span> tf.train.write_graph(constant_graph, output_dir, filename, as_text=<span class="keyword">False</span>)</div></pre></td></tr></table></figure></p>
<p>代码的关键要点：</p>
<ol>
<li><code>K.set_learning_phase(0)</code> 将学习阶段设置为 0， 即 test 阶段，像 <code>BatchNormalization</code> 这种 layer 在 test 阶段和 train 阶段的行为是不一样的。</li>
<li><code>tf.graph_util.convert_variables_to_constants</code> 将变量转换为常量，这一步使得我们可以用一个文件完全地（fully）表达一个神经网络，即如果不做这一步的话，<code>tf.train.write_graph</code> 写到文件里的仅仅有网络结构而没有相应的训练得到的权重参数。</li>
</ol>
<h3 id="Tensorflow-frozen-graph-to-UFF"><a href="#Tensorflow-frozen-graph-to-UFF" class="headerlink" title="Tensorflow frozen graph to UFF"></a>Tensorflow frozen graph to UFF</h3><p>就目前[2018/08/03]来说，NVCaffe 框架搭建的神经网络可以直接被导入并转化为推理引擎，来自其他框架的神经网络模型可以转化为 UFF 或者 ONNX 格式，然后通过相应的解析器解析成推理引擎。</p>
<p>将 Tensorflow frozen graph 转化为 UFF 文件，需要安装 uff Python 包。<br>这一步可以在 Jetson TX2 或者其 Host PC 上完成，只要安装了 uff 包即可。</p>
<p>uff 包是 TensorRT 3.0.4 for Ubuntu 16.04 and CUDA 9.0 tar package 的一部分，因此需要下载这个 tar 包，同时这个 tar 包也可以用来安装 TensorRT，由于已经通过 JetPack 在 Jetson TX2 上安装了 TensorRT，这一点可以在上一篇文章<a href="https://robertlexis.github.io/2018/08/01/Nvidia-Jetson-TX2-开箱及刷机/" target="_blank" rel="external">Nvidia Jetson TX2 开箱及刷机</a>或者下图中看到，因此我在这里仅取用安装其中的 uff。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tar -xzf TensorRT-3.0.4.Ubuntu-16.04.3.x86_64.cuda-9.0.cudnn7.0.tar.gz</div><div class="line">sudo pip install TensorRT-3.0.4/uff/uff-0.2.0-py2.py3-none-any.whl</div></pre></td></tr></table></figure></p>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/tensorRT/installed.png" alt="installed"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> uff</div><div class="line"><span class="comment"># generate uff from frozen graph</span></div><div class="line">uff_model = uff.from_tensorflow_frozen_model(</div><div class="line">    frozen_file=frozen_graph_filename,</div><div class="line">    output_nodes=output_node_names,</div><div class="line">    output_filename=uff_model_filename,</div><div class="line">    text=<span class="keyword">False</span>,</div><div class="line">)</div></pre></td></tr></table></figure>
<h3 id="UFF-to-plan-engine"><a href="#UFF-to-plan-engine" class="headerlink" title="UFF to plan (engine)"></a>UFF to plan (engine)</h3><p>这一步在安装了 TensorRT 的机器上完成，在此文章中为 Jetson TX2。<br>这一步可以参考 Nvidia <a href="https://developer.nvidia.com/embedded/twodaystoademo" target="_blank" rel="external">Two Days to a Demo</a> Advanced - TensorFlow to TensorRT Image Classification 的 <a href="https://github.com/NVIDIA-Jetson/tf_to_trt_image_classification" target="_blank" rel="external">github 仓库</a> 中的 <code>src/uff_to_plan.cpp</code>。<br>但是需要注意的是，该文件的 71 行方法调用存在错误：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">parser-&gt;registerInput(inputName.c_str(), DimsCHW(<span class="number">3</span>, inputHeight, inputWidth));</div></pre></td></tr></table></figure></p>
<p>编译时报错：<br><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/tensorRT/error1.png" alt="error_1"><br><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/tensorRT/error2.png" alt="error_2"><br>去 <code>/usr/include/aarch64-linux-gnu/NvUffParser.h</code> 查看函数声明，发现需要一个 <code>UffInputOrder</code> 类型的参数:<br><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/tensorRT/method_prototype.png" alt="error_2"><br>在这个头文件内搜索可以找到 <code>UffInputOrder</code> 这一个枚举类型:<br><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/tensorRT/enum.png" alt="error_2"></p>
<p>修改 <code>src/uff_to_plan.cpp</code> 的行 71 为<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">parser-&gt;registerInput(inputName.c_str(), DimsCHW(<span class="number">3</span>, inputHeight, inputWidth), UffInputOrder::kNHWC);</div></pre></td></tr></table></figure></p>
<p>即可。</p>
<h3 id="predict-cu"><a href="#predict-cu" class="headerlink" title="predict.cu"></a>predict.cu</h3><p>这一步在安装了 TensorRT 的机器上完成，在此文章中为 Jetson TX2，即在 Jetson TX2 完成 <code>.cu</code> 文件的编译。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fstream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sstream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;NvInfer.h&gt;</span></span></div><div class="line"></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> nvinfer1;</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Logger</span> :</span> <span class="keyword">public</span> ILogger</div><div class="line">&#123;</div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">log</span><span class="params">(Severity severity, <span class="keyword">const</span> <span class="keyword">char</span> * msg)</span> override</span></div><div class="line"><span class="function">  </span>&#123;</div><div class="line">    <span class="keyword">if</span> (severity != Severity::kINFO)</div><div class="line">      <span class="built_in">cout</span> &lt;&lt; msg &lt;&lt; <span class="built_in">endl</span>;</div><div class="line">  &#125;</div><div class="line">&#125; gLogger;</div><div class="line"></div><div class="line"><span class="comment">/* load the engine */</span></div><div class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"Loading TensorRT engine from plan file..."</span> &lt;&lt; <span class="built_in">endl</span>;</div><div class="line"></div><div class="line"><span class="function">ifstream <span class="title">planFile</span><span class="params">(planFilename)</span></span>; </div><div class="line"><span class="keyword">if</span> (!planFile.is_open())</div><div class="line">&#123;</div><div class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"Could not open plan file."</span> &lt;&lt; <span class="built_in">endl</span>;</div><div class="line">    <span class="keyword">return</span> <span class="number">1</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="built_in">stringstream</span> planBuffer;</div><div class="line">planBuffer &lt;&lt; planFile.rdbuf();</div><div class="line"><span class="built_in">string</span> plan = planBuffer.str();</div><div class="line"></div><div class="line">IRuntime *runtime = createInferRuntime(gLogger);</div><div class="line">ICudaEngine *engine = runtime-&gt;deserializeCudaEngine((<span class="keyword">void</span>*)plan.data(), plan.size(), <span class="literal">nullptr</span>);</div></pre></td></tr></table></figure>
        </div>
    

</div>
            
        </section>
    </div>
</div>



    <div class="row">
        <div class="col-sm-12">
            <div class="wrap-pagination">
                <a class="disabled" href="/">
                    <i class="fa fa-chevron-left" aria-hidden="true"></i>
                </a>
                <a class="" href="/page/2/">
                    <i class="fa fa-chevron-right" aria-hidden="true"></i>
                </a>
            </div>
        </div>
    </div>




</div>

<!-- Footer -->
<div class="push"></div>

<footer class="footer-content">
    <div class="container">
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-6 col-lg-6 footer-about">
                <h2>About</h2>
                <p>
                    This is Robert Lexis (FengCun Li). To see the world, things dangerous to come to, to see behind walls, to draw closer, to find each other and to feel. That is the purpose of LIFE.
                </p>
            </div>
            
    <div class="col-xs-6 col-sm-6 col-md-3 col-lg-3 recent-posts">
        <h2>Recent Posts</h2>
        <ul>
            
            <li>
                <a class="footer-post" href="/2018/08/26/YOLO/">YOLO</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2018/08/26/非最大值抑制/">非最大值抑制</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2018/08/26/目标定位-vs-目标检测/">目标定位 vs 目标检测</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2018/08/13/消失的梯度/">消失的梯度</a>
            </li>
            
        </ul>
    </div>



            
        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <ul class="list-inline footer-social-icons">
                    
                    <li class="list-inline-item">
                        <a href="https://github.com/RobertLexis">
                            <span class="footer-icon-container">
                                <i class="fa fa-github"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    <li class="list-inline-item">
                        <a href="mailto:robert_lexis@163.com">
                            <span class="footer-icon-container">
                                <i class="fa fa-envelope-o"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                </ul>
            </div>
        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <div class="footer-copyright">
                    @Untitled. All right reserved | Robert Lexis Loves Wenny
                </div>
            </div>
        </div>
    </div>
</footer>

<!-- After footer scripts -->

<!-- jQuery -->
<script src="//code.jquery.com/jquery-2.1.4.min.js"></script>

<!-- Tween Max -->
<script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.5/TweenMax.min.js"></script>

<!-- Gallery -->
<script src="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Custom JavaScript -->
<script src="/js/main.js"></script>

<!-- Disqus Comments -->



</body>

</html>