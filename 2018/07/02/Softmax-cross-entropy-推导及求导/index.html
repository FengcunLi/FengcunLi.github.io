<!DOCTYPE html>
<html lang="zh-CN">

<!-- Head tag -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!--Description-->
    
        <meta name="description" content="主要分析了 binary_crossentropy 和 categorical_crossentropy 的定义， softmax 和 categorical_crossentropy 的求导。
binary_crossentropy适用于每个类别相互独立但互不排斥的情况，常见于单类别任务\( (b">
    

    <!--Author-->
    
        <meta name="author" content="Robert Lexis">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="Softmax cross entropy 推导及求导"/>
    

    <!--Open Graph Description-->
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content="This is WHY."/>

    <!--Type page-->
    
        <meta property="og:type" content="article" />
    

    <!--Page Cover-->
    

        <meta name="twitter:card" content="summary" />
    

    <!-- Title -->
    
    <title>Softmax cross entropy 推导及求导 - This is WHY.</title>

    <!-- Bootstrap Core CSS -->
    <link href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" rel="stylesheet"/>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/style.css">

    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Google Analytics -->
    


    <!-- favicon -->
    
	
</head>


<body>

    <!-- Menu -->
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">This is WHY.</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                
                    <li>
                        <a href="/">
                            
                                Home
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/archives">
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/tags">
                            
                                Tags
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/categories">
                            
                                Categories
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="https://github.com/RobertLexis">
                            
                                <i class="fa fa-github fa-stack-2x"></i>
                            
                        </a>
                    </li>
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>

    <!-- Main Content -->
    <!-- Page Header -->
<!-- Set your background image for this header in your post front-matter: cover -->

<header class="intro-header" style="background-image: url('http://www.codeblocq.com/assets/projects/hexo-theme-clean-blog/img/home-bg.jpg')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <h1>Softmax cross entropy 推导及求导</h1>
                    
                    <span class="meta">
                        <!-- Date and Author -->
                        
                        
                            2018-07-02
                        
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

            <!-- Tags and categories -->
           
                <div class="col-lg-4 col-lg-offset-2 col-md-5 col-md-offset-1 post-tags">
                    
                        


<a href="/tags/DL/">#DL</a>


                    
                </div>
                <div class="col-lg-4 col-md-5 post-categories">
                    
                </div>
            

            <!-- Gallery -->
            

            <!-- Post Main Content -->
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <p>主要分析了 binary_crossentropy 和 categorical_crossentropy 的定义， softmax 和 categorical_crossentropy 的求导。</p>
<h3 id="binary-crossentropy"><a href="#binary-crossentropy" class="headerlink" title="binary_crossentropy"></a>binary_crossentropy</h3><p>适用于每个类别相互独立但互不排斥的情况，常见于单类别任务\( (batch size, 1) \)和多类别中的多标签任务\( (batch size, num classes) \)。</p>
<p>\[<br>\begin{split}<br>    p_{i, j} &amp; = sigmoid(logits_{i, j}) \\\\<br>    &amp; = \frac{1}{1 + e^{-logits_{i, j}}} \\\\<br>    loss_{i, j} &amp; = -[y_{i, j} \times ln p_{i, j} + (1 - y_{i, j}) \times (1 - ln p_{i, j})]<br>\end{split}<br>\]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">def binary_crossentropy(target, output, from_logits=False):</div><div class="line">    &quot;&quot;&quot;Binary crossentropy between an output tensor and a target tensor.</div><div class="line"></div><div class="line">    # Arguments</div><div class="line">        target: A tensor with the same shape as `output`.</div><div class="line">        output: A tensor.</div><div class="line">        from_logits: Whether `output` is expected to be a logits tensor.</div><div class="line">            By default, we consider that `output`</div><div class="line">            encodes a probability distribution.</div><div class="line"></div><div class="line">    # Returns</div><div class="line">        A tensor.</div><div class="line">    &quot;&quot;&quot;</div><div class="line">    # Note: tf.nn.sigmoid_cross_entropy_with_logits</div><div class="line">    # expects logits, Keras expects probabilities.</div><div class="line">    if not from_logits:</div><div class="line">        # transform back to logits</div><div class="line">        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)</div><div class="line">        output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)</div><div class="line">        output = tf.log(output / (1 - output))</div><div class="line"></div><div class="line">    return tf.nn.sigmoid_cross_entropy_with_logits(labels=target,</div><div class="line">                                                   logits=output)</div></pre></td></tr></table></figure></p>
<h3 id="categorical-crossentropy"><a href="#categorical-crossentropy" class="headerlink" title="categorical_crossentropy"></a>categorical_crossentropy</h3><p>适用于每个类别相互独立且排斥的情况（onehot），即多类别中的单标签任务\( (batch size, num classes) \)。<br>\[<br>\begin{split}<br>    p_{i, j} &amp; = \frac{e^{logits_{i, j}}}{\sum_{j=0}^{num classes - 1} e^{logits_{i, j}}} \\\\<br>    loss_i &amp; = - \sum_{j=0}^{num  classes - 1} y_{i, j} ln p_{i, j}<br>\end{split}<br>\]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line">def categorical_crossentropy(target, output, from_logits=False, axis=-1):</div><div class="line">    &quot;&quot;&quot;Categorical crossentropy between an output tensor and a target tensor.</div><div class="line"></div><div class="line">    # Arguments</div><div class="line">        target: A tensor of the same shape as `output`.</div><div class="line">        output: A tensor resulting from a softmax</div><div class="line">            (unless `from_logits` is True, in which</div><div class="line">            case `output` is expected to be the logits).</div><div class="line">        from_logits: Boolean, whether `output` is the</div><div class="line">            result of a softmax, or is a tensor of logits.</div><div class="line">        axis: Int specifying the channels axis. `axis=-1`</div><div class="line">            corresponds to data format `channels_last`,</div><div class="line">            and `axis=1` corresponds to data format</div><div class="line">            `channels_first`.</div><div class="line"></div><div class="line">    # Returns</div><div class="line">        Output tensor.</div><div class="line"></div><div class="line">    # Raises</div><div class="line">        ValueError: if `axis` is neither -1 nor one of</div><div class="line">            the axes of `output`.</div><div class="line">    &quot;&quot;&quot;</div><div class="line">    output_dimensions = list(range(len(output.get_shape())))</div><div class="line">    if axis != -1 and axis not in output_dimensions:</div><div class="line">        raise ValueError(</div><div class="line">            &apos;&#123;&#125;&#123;&#125;&#123;&#125;&apos;.format(</div><div class="line">                &apos;Unexpected channels axis &#123;&#125;. &apos;.format(axis),</div><div class="line">                &apos;Expected to be -1 or one of the axes of `output`, &apos;,</div><div class="line">                &apos;which has &#123;&#125; dimensions.&apos;.format(len(output.get_shape()))))</div><div class="line">    # Note: tf.nn.softmax_cross_entropy_with_logits</div><div class="line">    # expects logits, Keras expects probabilities.</div><div class="line">    if not from_logits:</div><div class="line">        # scale preds so that the class probas of each sample sum to 1</div><div class="line">        output /= tf.reduce_sum(output, axis, True)</div><div class="line">        # manual computation of crossentropy</div><div class="line">        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)</div><div class="line">        output = tf.clip_by_value(output, _epsilon, 1. - _epsilon)</div><div class="line">        return - tf.reduce_sum(target * tf.log(output), axis)</div><div class="line">    else:</div><div class="line">        return tf.nn.softmax_cross_entropy_with_logits(labels=target,</div><div class="line">                                                       logits=output)</div></pre></td></tr></table></figure></p>
<h3 id="weighted-cross-entropy"><a href="#weighted-cross-entropy" class="headerlink" title="weighted_cross_entropy"></a>weighted_cross_entropy</h3><p>\[<br>\begin{split}<br>    p_{i, j} &amp; = sigmoid(logits_{i, j}) \\\\<br>    &amp; = \frac{1}{1 + e^{-logits_{i, j}}} \\\\<br>    loss_{i, j} &amp; = -[ pos  weight \times y_{i, j} \times ln p_{i, j} + (1 - y_{i, j}) \times (1 - ln p_{i, j})]<br>\end{split}<br>\]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tf.nn.weighted_cross_entropy_with_logits(labels,logits, pos_weight, name=None)</div></pre></td></tr></table></figure></p>
<h3 id="softmax-求导"><a href="#softmax-求导" class="headerlink" title="softmax 求导"></a>softmax 求导</h3><p>\[<br>\begin{split}<br>    y_i &amp; = \frac{e^{x_i}}{\sum_{j=0}^{m-1} e^{x_j}} \\\\<br>    \frac{\partial y_i}{\partial x_k} &amp; = \frac{\partial \frac{e^{x_i}}{\sum_{j=0}^{m-1} e^{x_j}}}{\partial x_k} \\\\<br>    &amp; = \frac{\frac{\partial e^{x_i}}{\partial x_k} \times \sum - e^{x_i} \times \frac{\partial \sum}{\partial x_k}}{ {\sum}^2 } \\\\<br>    &amp; = \frac{\frac{\partial e^{x_i}}{\partial x_k} \times \sum - e^{x_i} \times e^{x_k}}{ {\sum}^2 } \\\\<br>    &amp; = \begin{cases}<br>        \frac{e^{x_k} \times \sum - e^{x_i} \times e^{x_k}}{ {\sum}^2 }, \\text{ if } i = k \\\\<br>        \frac{ - e^{x_i} \times e^{x_k}}{ {\sum}^2 }, \\text{ if } i \neq k<br>    \end{cases}\\\\<br>    &amp; = \begin{cases}<br>        y_k (1 - y_i), \\\text{ if } i = k \\\\</p>
<pre><code>    - y_i y_k, \\\text{ if } i \neq k
\end{cases}
</code></pre><p>\end{split}<br>\]</p>
<p>\[<br>    \mathbf{y} = softmax(\mathbf{x})<br>\]</p>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/image/jpg/softmax/softmax.png" alt="softmax"></p>
<p>雅可比矩阵<br>\[<br>Jacobian_{\mathbf{y}}(\mathbf{x}) =<br>\left[<br> \begin{matrix}<br>   \frac{\partial y_0}{\partial x_0} &amp; \frac{\partial y_0}{\partial x_1} &amp; \dots &amp; \frac{\partial y_0}{\partial x_{m-1}} \\\\<br>   \vdots &amp;  \vdots &amp; \ddots &amp; \vdots \\\\<br>   \frac{\partial y_{m-1}}{\partial x_0} &amp; \frac{\partial y_{m-1}}{\partial x_1} &amp; \dots &amp; \frac{\partial y_{m-1}}{\partial x_{m-1}}<br>  \end{matrix}<br>  \right]<br>\]</p>
<h3 id="categorical-crossentropy-求导"><a href="#categorical-crossentropy-求导" class="headerlink" title="categorical_crossentropy 求导"></a>categorical_crossentropy 求导</h3><p>\[<br>\begin{split}<br>    \frac{\partial loss}{\partial logits_k} &amp; = \frac{\partial {- \sum_{j=0}^{num  classes - 1} y_{j} ln p_{j}}}{\partial logits_k} \\\\<br>    &amp; = - \sum_{j=0}^{num classes - 1} y_{j}  \frac{\partial ln p_{j}}{\partial logits_k} \\\\<br>    &amp; = - \sum_{j=0}^{num classes - 1} y_{j}  \frac{1}{p_{j}} \frac{\partial p_{j}}{\partial logits_k} \\\\<br>    &amp; = - \sum_{j=0}^{num classes - 1} y_{j}  \frac{1}{p_{j}} \begin{cases}<br>                                                            p_k (1 - p_j), \\text{ if } j = k \\\\</p>
<pre><code>                                                        - p_j p_k, \\text{ if } j \neq k
                                                        \end{cases} \\\\
&amp; = - y_{k}(1 - p_k) - \sum_{j=0, j \neq k}^{num classes - 1} y_{j} (-p_k) \\\\
&amp; = - y_{k} + y_{k} p_k + \sum_{j=0, j \neq k}^{num classes - 1} y_{j} p_k \\\\
&amp; = - y_{k} + p_k \sum_{j=0}^{num classes - 1} y_{j} \\\\
&amp; = p_k - y_{k}
</code></pre><p>\end{split}<br>\]<br>可以看出 categorical_crossentropy 的导数很简洁，即预测概率与真实概率的差。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">tf.nn.softmax_cross_entropy_with_logits(</div><div class="line">    _sentinel=None,</div><div class="line">    labels=None,</div><div class="line">    logits=None,</div><div class="line">    dim=-1,</div><div class="line">    name=None</div><div class="line">)</div></pre></td></tr></table></figure></p>
<blockquote>
<p>WARNING: This op expects unscaled logits, since it performs a softmax on logits internally for efficiency. Do not call this op with the output of softmax, as it will produce incorrect results.</p>
<p>Backpropagation will happen only into logits. To calculate a cross entropy loss that allows backpropagation into both logits and labels, see tf.nn.softmax_cross_entropy_with_logits_v2.</p>
</blockquote>
<p>相较于相继调用 <code>softmax</code> 和 <code>cross_entropy</code> （正向传播，反向传播），<code>softmax_cross_entropy_with_logits</code> 的反向传播速度更快，原因就是可以直接使用上面的的推导结果\( \frac{\partial loss}{\partial logits_k} =  p_k - y_{k} \) 简单快速地求得 <code>logits</code> 上的梯度，并在此基础上继续反向传播，而不必对 <code>cross_entropy</code> 和 <code>softmax</code> 依次反向传播之后才得到 <code>logits</code> 上的梯度\( \sum_{j=0}^{m-1} \frac{\partial loss}{\partial p_j} \frac{\partial p_j}{\partial x_k} \)[upstream gradients local gradients]。将这两个操作合为一个操作，正向传播速度一样，反向传播实现了加速。</p>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>

                
            </div>

            <!-- Comments -->
            
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    


                </div>
            
        </div>
    </div>
</article>

    <!-- Footer -->
    <hr />

<!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    

                    

                    
                        <li>
                            <a href="https://github.com/RobertLexis" target="_blank">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    

                    

                    

                    
                </ul>
                <p class="copyright text-muted">&copy; 2018 Robert Lexis<br></p>
                <p class="copyright text-muted">Original Theme <a target="_blank" href="http://startbootstrap.com/template-overviews/clean-blog/">Clean Blog</a> from <a href="http://startbootstrap.com/" target="_blank">Start Bootstrap</a></p>
                <p class="copyright text-muted">Adapted for <a target="_blank" href="https://hexo.io/">Hexo</a> by <a href="http://www.codeblocq.com/" target="_blank">Jonathan Klughertz</a></p>
            </div>
        </div>
    </div>
</footer>


    <!-- After footer scripts -->
    
<!-- jQuery -->
<script src="//code.jquery.com/jquery-2.1.4.min.js"></script>

<!-- Bootstrap -->
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>

<!-- Gallery -->
<script src="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Disqus Comments -->



</body>

</html>