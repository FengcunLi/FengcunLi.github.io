<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!--Description-->
    
        <meta name="description" content="本文主要讲解 Annotations 中的 label 和 bboxes 是如何在 SSD 中使用的。网络的输入 glabels 和 gbboxes 是无法直接和网络的输出进行比较并计算 losses 的。因此需要首先通过 bboxes_encode 进行编码，得到对应于不同特征层（block）的 feat_labels，feat_localizations，feat_scores(杰卡德系数)，再通过feat_labels，feat_localizations 与网络不同特征层（block）的输出进行比较并计算 losses。">
    

    <!--Author-->
    
        <meta name="author" content="Robert Lexis">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="ssd 源码分析"/>
    

    <!--Open Graph Description-->
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content="This is Robert Lexis."/>

    <!--Type page-->
    
        <meta property="og:type" content="article" />
    

    <!--Page Cover-->
    

    <meta name="twitter:card" content="summary" />
    

    <!-- Title -->
    
    <title>ssd 源码分析 - This is Robert Lexis.</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.2/css/bootstrap.min.css" integrity="sha384-y3tfxAZXuh4HwSYylfB+J125MxIs6mR5FOHamPBG064zB+AFeWH94NdvaCBm8qnd" crossorigin="anonymous">

    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/style.css">

    <!-- Google Analytics -->
    


</head>


<body>

<div class="bg-gradient"></div>
<div class="bg-pattern"></div>

<!-- Menu -->
<!--Menu Links and Overlay-->
<div class="menu-bg">
    <div class="menu-container">
        <ul>
            
            <li class="menu-item">
                <a href="/">
                    Home
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/archives">
                    Archives
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/about">
                    About
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/tags">
                    Tags
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/categories">
                    Categories
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/contact">
                    Contact
                </a>
            </li>
            
        </ul>
    </div>
</div>

<!--Hamburger Icon-->
<nav>
    <a href="#menu"></a>
</nav>

<div class="container">

    <!-- Main Content -->
    <div class="row">
    <div class="col-sm-12">

        <!--Title and Logo-->
        <header>
    <div class="logo">
        <a href="/"><i class="logo-icon fa fa-cube" aria-hidden="true"></i></a>
        
    </div>
</header>

        <section class="main">
            
<div class="post">

    <div class="post-header">
        <h1 class="title">
            <a href="/2018/05/17/ssd-源码分析/">
                ssd 源码分析
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2018-05-17</span>
            
            
            
        </div>
    </div>

    <div class="content">

        <!-- Gallery -->
        

        <!-- Post Content -->
        <p>本文主要讲解 Annotations 中的 label 和 bboxes 是如何在 SSD 中使用的。<br>网络的输入 <code>glabels</code> 和 <code>gbboxes</code> 是无法直接和网络的输出进行比较并计算 losses 的。因此需要首先通过 <code>bboxes_encode</code> 进行编码，得到对应于不同特征层（block）的 <code>feat_labels</code>，<code>feat_localizations</code>，<code>feat_scores</code>(杰卡德系数)，再通过<br><code>feat_labels</code>，<code>feat_localizations</code> 与网络不同特征层（block）的输出进行比较并计算 losses。<br><a id="more"></a></p>
<h3 id="anchors-的生成"><a href="#anchors-的生成" class="headerlink" title="anchors 的生成"></a>anchors 的生成</h3><h5 id="维度："><a href="#维度：" class="headerlink" title="维度："></a>维度：</h5><p>anchors type: list A of list B<br>len(A): num_of_blocks, for 300 it’s 6, for 512 it’s 7.<br>B: [y, x, h, w]<br>shape of y, x: for block 4 of 300 is 38 <em> 38 </em> 1(1 is an expanded dim)<br>shape of h, w: for block 4 of 300 is (len(sizes) + len(ratios) = 4, )</p>
<h5 id="生成过程-of-300"><a href="#生成过程-of-300" class="headerlink" title="生成过程 of 300"></a>生成过程 of 300</h5><ol>
<li>feat_shapes: [(38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)]<br>分别对应 blocks: [‘block4’, ‘block7’, ‘block8’, ‘block9’, ‘block10’, ‘block11’]</li>
<li>anchor_sizes: [(21., 45.), (45., 99.), (99., 153.), (153., 207.), (207., 261.), (261., 315.)]</li>
<li>anchor_ratios: [[2, .5], [2, .5, 3, 1./3], [2, .5, 3, 1./3], [2, .5, 3, 1./3], [2, .5], [2, .5]]</li>
<li>anchor_steps: [8, 16, 32, 64, 100, 300]</li>
<li>anchor_offset: 0.5<br>For the first feature map (block 4), the y, x:<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">y, x = np.mgrid[0:feat_shape[0], 0:feat_shape[1]]</div><div class="line">y = (y.astype(dtype) + offset) * step / img_shape[0]</div><div class="line">x = (x.astype(dtype) + offset) * step / img_shape[1]</div><div class="line"></div><div class="line"># Expand dims to support easy broadcasting.</div><div class="line">y = np.expand_dims(y, axis=-1)</div><div class="line">x = np.expand_dims(x, axis=-1)</div></pre></td></tr></table></figure>
</li>
</ol>
<p>(38 - 1 + 0.5) * 8 = 300<br>So the range of y, x is [4/300, 1.0].<br>y, x 在后续的处理中是当作中心使用的。<br>对于各个 block 的 y，x ，它们都是映射到（大概）原图上的 (0, 1) 之间的值，标记着一些散布在原图上的锚点。</p>
<p>For the first feature map (block 4), the h, w:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">num_anchors = len(sizes) + len(ratios)</div><div class="line">h = np.zeros((num_anchors, ), dtype=dtype)</div><div class="line">w = np.zeros((num_anchors, ), dtype=dtype)</div><div class="line"># Add first anchor boxes with ratio=1.</div><div class="line">h[0] = sizes[0] / img_shape[0]</div><div class="line">w[0] = sizes[0] / img_shape[1]</div><div class="line">di = 1</div><div class="line">if len(sizes) &gt; 1:</div><div class="line">    h[1] = math.sqrt(sizes[0] * sizes[1]) / img_shape[0]</div><div class="line">    w[1] = math.sqrt(sizes[0] * sizes[1]) / img_shape[1]</div><div class="line">    di += 1</div><div class="line">for i, r in enumerate(ratios):</div><div class="line">    h[i+di] = sizes[0] / img_shape[0] / math.sqrt(r)</div><div class="line">    w[i+di] = sizes[0] / img_shape[1] * math.sqrt(r)</div></pre></td></tr></table></figure></p>
<p><img src="http://oytnj8g2y.bkt.clouddn.com/hw.jpg" alt=""></p>
<p>feat_shapes 并非任意指定的值，而真的就是来自卷积神经网络的某一层特征图的尺寸值，即该层特征图的输出尺寸决定了 feat_shapes，feat_shapes 用来指导 anchors 的生成，anchors 的生成决定了神经网络输入的编码，最终<strong>特征图的输出</strong>和<strong>输入编码</strong>之间计算 Loss，指导神经网络的学习过程。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">def ssd_multibox_layer(inputs,</div><div class="line">                       num_classes,</div><div class="line">                       sizes,</div><div class="line">                       ratios=[1],</div><div class="line">                       normalization=-1,</div><div class="line">                       bn_normalization=False):</div><div class="line">    &quot;&quot;&quot;Construct a multibox layer, return a class and localization predictions.</div><div class="line">    &quot;&quot;&quot;</div><div class="line">    net = inputs</div><div class="line">    if normalization &gt; 0:</div><div class="line">        net = custom_layers.l2_normalization(net, scaling=True)</div><div class="line">    # Number of anchors.</div><div class="line">    num_anchors = len(sizes) + len(ratios)</div><div class="line"></div><div class="line">    # Location.</div><div class="line">    num_loc_pred = num_anchors * 4</div><div class="line">    loc_pred = slim.conv2d(net, num_loc_pred, [3, 3], activation_fn=None,</div><div class="line">                           scope=&apos;conv_loc&apos;)</div><div class="line">    loc_pred = custom_layers.channel_to_last(loc_pred)</div><div class="line">    loc_pred = tf.reshape(loc_pred,</div><div class="line">                          tensor_shape(loc_pred, 4)[:-1]+[num_anchors, 4])</div><div class="line">    # Class prediction.</div><div class="line">    num_cls_pred = num_anchors * num_classes</div><div class="line">    cls_pred = slim.conv2d(net, num_cls_pred, [3, 3], activation_fn=None,</div><div class="line">                           scope=&apos;conv_cls&apos;)</div><div class="line">    cls_pred = custom_layers.channel_to_last(cls_pred)</div><div class="line">    cls_pred = tf.reshape(cls_pred,</div><div class="line">                          tensor_shape(cls_pred, 4)[:-1]+[num_anchors, num_classes])</div><div class="line">    return cls_pred, loc_pred</div></pre></td></tr></table></figure></p>
<h3 id="输入编码"><a href="#输入编码" class="headerlink" title="输入编码"></a>输入编码</h3><p><code>bboxes_encode -&gt; tf_ssd_bboxes_encode -&gt; tf_ssd_bboxes_encode_layer</code><br>input: labels, bboxes of a single image, not a batch of images, because the call of bboxes_encode is invoked before the construction of batch.<br>labels: such as [1, 1, 3]<br>bboxes: such as [[…, …, …, …], […, …, …, …], […, …, …, …]]</p>
<h6 id="编码过程"><a href="#编码过程" class="headerlink" title="编码过程"></a>编码过程</h6><p>一张图，一份 labels ，一份 bboxes，一个 anchor_layer ====&gt;&gt;&gt;&gt; for 循环遍历 labels 和 bboxes，不断计算杰卡德系数，更新属于该 anchor_layer 的对应于该图的 feat_labels 和 feat_scores(也就是杰卡德系数)。<br><img src="http://oytnj8g2y.bkt.clouddn.com/jaccard.jpg" alt=""><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div></pre></td><td class="code"><pre><div class="line">def tf_ssd_bboxes_encode_layer(labels,</div><div class="line">                               bboxes,</div><div class="line">                               anchors_layer,</div><div class="line">                               num_classes,</div><div class="line">                               no_annotation_label,</div><div class="line">                               ignore_threshold=0.5,</div><div class="line">                               prior_scaling=[0.1, 0.1, 0.2, 0.2],</div><div class="line">                               dtype=tf.float32):</div><div class="line">    # 这里的 anchors_layer 就是上面讲到的 anchors 生成中的一个</div><div class="line">    # 下面的代码利用到了 numpy 的 auto broadcasting，</div><div class="line">    # 使得 ymin，xmin，ymax，xmax，vol_anchors 的维度都成为类似 block4 的 (38, 38, 4)。</div><div class="line">    yref, xref, href, wref = anchors_layer</div><div class="line">    ymin = yref - href / 2.</div><div class="line">    xmin = xref - wref / 2.</div><div class="line">    ymax = yref + href / 2.</div><div class="line">    xmax = xref + wref / 2.</div><div class="line">    vol_anchors = (xmax - xmin) * (ymax - ymin)</div><div class="line"></div><div class="line">    # feat_labels，feat_scores，feat_ymin，feat_xmin，feat_ymax，feat_xmax 的维度</div><div class="line">    # 都成为类似 block4 的 (38, 38, 4)。</div><div class="line">    shape = (yref.shape[0], yref.shape[1], href.size)</div><div class="line">    feat_labels = tf.zeros(shape, dtype=tf.int64)</div><div class="line">    feat_scores = tf.zeros(shape, dtype=dtype)</div><div class="line">    feat_ymin = tf.zeros(shape, dtype=dtype)</div><div class="line">    feat_xmin = tf.zeros(shape, dtype=dtype)</div><div class="line">    feat_ymax = tf.ones(shape, dtype=dtype)</div><div class="line">    feat_xmax = tf.ones(shape, dtype=dtype)</div><div class="line"></div><div class="line">    # 计算一个 bbox 与该 anchor_layer 上所有 anchor 的杰卡德系数</div><div class="line">    # 返回的 jaccard 维度也类似于 (38, 38, 4)</div><div class="line">    def jaccard_with_anchors(bbox):</div><div class="line">        &quot;&quot;&quot;Compute jaccard score between a box and the anchors.</div><div class="line">        &quot;&quot;&quot;</div><div class="line">        int_ymin = tf.maximum(ymin, bbox[0])</div><div class="line">        int_xmin = tf.maximum(xmin, bbox[1])</div><div class="line">        int_ymax = tf.minimum(ymax, bbox[2])</div><div class="line">        int_xmax = tf.minimum(xmax, bbox[3])</div><div class="line">        h = tf.maximum(int_ymax - int_ymin, 0.)</div><div class="line">        w = tf.maximum(int_xmax - int_xmin, 0.)</div><div class="line">        # Volumes.</div><div class="line">        inter_vol = h * w</div><div class="line">        union_vol = vol_anchors - inter_vol \</div><div class="line">            + (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])</div><div class="line">        jaccard = tf.div(inter_vol, union_vol)</div><div class="line">        return jaccard</div><div class="line"></div><div class="line">    def condition(i, feat_labels, feat_scores,</div><div class="line">                    feat_ymin, feat_xmin, feat_ymax, feat_xmax):</div><div class="line">        &quot;&quot;&quot;Condition: check label index.</div><div class="line">        &quot;&quot;&quot;</div><div class="line">        r = tf.less(i, tf.shape(labels))</div><div class="line">        return r[0]</div><div class="line"></div><div class="line">    def body(i, feat_labels, feat_scores,</div><div class="line">                feat_ymin, feat_xmin, feat_ymax, feat_xmax):</div><div class="line">        &quot;&quot;&quot;Body: update feature labels, scores and bboxes.</div><div class="line">        Follow the original SSD paper for that purpose:</div><div class="line">            - assign values when jaccard &gt; 0.5;</div><div class="line">            - only update if beat the score of other bboxes.</div><div class="line">        &quot;&quot;&quot;</div><div class="line"></div><div class="line">        label = labels[i]</div><div class="line">        bbox = bboxes[i]</div><div class="line">        jaccard = jaccard_with_anchors(bbox)</div><div class="line"></div><div class="line">        # mask 代表仅更新 jaccard 系数大于当前的 feat_scores 的，且 label 有效的部分，其余部分不更新。</div><div class="line">        # label 与 num_classes 的大小关系一定要对，这在 mask = tf.logical_and(mask, label &lt; num_classes) </div><div class="line">        # 中提出了要求，</div><div class="line">        # 一旦 label &lt; num_classes 为假，那么 mask 就会被全部清零，失去更新 feat_labels 和 feat_scores 的机会，</div><div class="line">        # 从而无法作为输入参与到训练中来。</div><div class="line">        # 这会影响到 mAP么？ TO DO!!!!</div><div class="line"></div><div class="line">        mask = tf.greater(jaccard, feat_scores)</div><div class="line">        mask = tf.logical_and(mask, feat_scores &gt; -0.5)</div><div class="line">        mask = tf.logical_and(mask, label &lt; num_classes)</div><div class="line">        imask = tf.cast(mask, tf.int64)</div><div class="line">        fmask = tf.cast(mask, dtype)</div><div class="line"></div><div class="line">        # Update values using mask.</div><div class="line">        feat_labels = imask * label + (1 - imask) * feat_labels</div><div class="line">        feat_scores = tf.where(mask, jaccard, feat_scores)</div><div class="line">        feat_ymin = fmask * bbox[0] + (1 - fmask) * feat_ymin</div><div class="line">        feat_xmin = fmask * bbox[1] + (1 - fmask) * feat_xmin</div><div class="line">        feat_ymax = fmask * bbox[2] + (1 - fmask) * feat_ymax</div><div class="line">        feat_xmax = fmask * bbox[3] + (1 - fmask) * feat_xmax</div><div class="line">        return [i+1, feat_labels, feat_scores,</div><div class="line">                feat_ymin, feat_xmin, feat_ymax, feat_xmax]</div><div class="line">    # Main loop definition.</div><div class="line">    i = 0</div><div class="line">    [i, feat_labels, feat_scores,</div><div class="line">        feat_ymin, feat_xmin,</div><div class="line">        feat_ymax, feat_xmax] = tf.while_loop(condition, body,</div><div class="line">                                            [i, feat_labels, feat_scores,</div><div class="line">                                            feat_ymin, feat_xmin,</div><div class="line">                                            feat_ymax, feat_xmax])</div><div class="line">    </div><div class="line">    # Transform to center / size.</div><div class="line">    feat_cy = (feat_ymax + feat_ymin) / 2.</div><div class="line">    feat_cx = (feat_xmax + feat_xmin) / 2.</div><div class="line">    feat_h = feat_ymax - feat_ymin</div><div class="line">    feat_w = feat_xmax - feat_xmin</div><div class="line"></div><div class="line">    # Encode features.</div><div class="line">    feat_cy = (feat_cy - yref) / href / prior_scaling[0]</div><div class="line">    feat_cx = (feat_cx - xref) / wref / prior_scaling[1]</div><div class="line">    feat_h = tf.log(feat_h / href) / prior_scaling[2]</div><div class="line">    feat_w = tf.log(feat_w / wref) / prior_scaling[3]</div><div class="line"></div><div class="line">    # Use SSD ordering: x / y / w / h instead of ours.</div><div class="line">    feat_localizations = tf.stack([feat_cx, feat_cy, feat_w, feat_h], axis=-1)</div><div class="line">    return feat_labels, feat_localizations, feat_scores</div></pre></td></tr></table></figure></p>
<p>shape of feat_labels, feat_scores is: such as 38 38 4<br>feat_localizations: such as 38 38 4 4<br>feat_localizations 中的每一个值都不是绝对数值，而是相对数值并经过了缩放编码，缩放可控制坐标、长宽两者之间对于 loss 的相对影响力，以及它们和 feat_labels 之间对于 loss的相对影响力。<br>这样就将 glabels 和 gbboxes 通过杰卡德系数这一标准映射到了 anchors 上，glabels 没什么可说的，就是给了 anchor 一个标签，关于 gbboxes 则是给了 anchor 一个绝对的上下左右的界限，并在后续将这个界限转成了相对的缩放后的中心位置和长宽。<br>即将 glabels 和 gbboxes 编到了 anchors 上，形成了图 feat_labels, feat_localizations, feat_scores。</p>
<h3 id="losses-的计算"><a href="#losses-的计算" class="headerlink" title="losses 的计算"></a>losses 的计算</h3><p>logits shape：类似于 (N, 38, 38, 4, num_classes)<br>计算的思想就是首先根据 groundtruth 构建正负样本，gscores 中杰卡德系数大于门限值的对应的就是正样本，小于门限值的对应的就是负样本。由于负样本会远远多于正样本，因此只选择预测最差的一部分进行 hard mining。分别计算在正负样本上的loss并综合起来。一张图片会产生很多个（可能多于目标个数）的正样本以及很多的负样本。<br>上一步的输入编码之后得到的一系列 feat_labels, feat_localizations, feat_scores，分别组装成 list 输入到下面的函数用于与网络的各个特征 block 的输出计算 loss。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div></pre></td><td class="code"><pre><div class="line"># 参数 logits, localisations, gclasses, glocalisations, gscores 都是对应的是一个批次 batch。</div><div class="line">def ssd_losses(logits, localisations,</div><div class="line">               gclasses, glocalisations, gscores,</div><div class="line">               match_threshold=0.5,</div><div class="line">               negative_ratio=3.,</div><div class="line">               alpha=1.,</div><div class="line">               label_smoothing=0.,</div><div class="line">               scope=None):</div><div class="line">    with tf.name_scope(scope, &apos;ssd_losses&apos;):</div><div class="line">        l_cross_pos = []</div><div class="line">        l_cross_neg = []</div><div class="line">        l_loc = []</div><div class="line">        # 一个 block 一个 block 的来处理</div><div class="line">        for i in range(len(logits)):</div><div class="line">            dtype = logits[i].dtype</div><div class="line">            with tf.name_scope(&apos;block_%i&apos; % i):</div><div class="line">                # positive mask 正样本的 mask</div><div class="line">                pmask = gscores[i] &gt; match_threshold</div><div class="line">                # final positive mask</div><div class="line">                fpmask = tf.cast(pmask, dtype)</div><div class="line">                n_positives = tf.reduce_sum(fpmask)</div><div class="line"></div><div class="line">                # Negative mask. 负样本的 mask，并利用 nvalues 进行筛选。</div><div class="line">                # no_classes 与所有目标重合度不足的为0，表示是背景，1 表示是目标。one vs others。</div><div class="line">                no_classes = tf.cast(pmask, tf.int32)</div><div class="line">                predictions = slim.softmax(logits[i])</div><div class="line">                nmask = tf.logical_and(tf.logical_not(pmask),</div><div class="line">                                       gscores[i] &gt; -0.5)</div><div class="line">                fnmask = tf.cast(nmask, dtype)</div><div class="line">                # nvalues 若anchor是目标则为1， 若anchor是背景则为预测为背景的概率，</div><div class="line">                # nvalues 的值用来筛选 hard negative，如果anchor 即 groundtruth 为背景，</div><div class="line">                # 而predictions[:, :, :, :, 0]很小，则其为 hard negative。</div><div class="line">                # 由 predictions[:, :, :, :, 0] 可知将背景作为一个0类“目标”的必要性。</div><div class="line">                nvalues = tf.where(nmask,</div><div class="line">                                   predictions[:, :, :, :, 0],</div><div class="line">                                   1. - fnmask)</div><div class="line">                nvalues_flat = tf.reshape(nvalues, [-1])</div><div class="line">                # Number of negative entries to select.</div><div class="line">                n_neg = tf.cast(negative_ratio * n_positives, tf.int32)</div><div class="line">                n_neg = tf.maximum(n_neg, tf.size(nvalues_flat) // 8)</div><div class="line">                n_neg = tf.maximum(n_neg, tf.shape(nvalues)[0] * 4)</div><div class="line">                max_neg_entries = 1 + tf.cast(tf.reduce_sum(fnmask), tf.int32)</div><div class="line">                n_neg = tf.minimum(n_neg, max_neg_entries)</div><div class="line"></div><div class="line">                val, idxes = tf.nn.top_k(-nvalues_flat, k=n_neg)</div><div class="line">                minval = val[-1]</div><div class="line">                # Final negative mask.</div><div class="line">                nmask = tf.logical_and(nmask, -nvalues &gt; minval)</div><div class="line">                fnmask = tf.cast(nmask, dtype)</div><div class="line"></div><div class="line">                # Add cross-entropy loss.</div><div class="line">                with tf.name_scope(&apos;cross_entropy_pos&apos;):</div><div class="line">                    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits[i],</div><div class="line">                                                                          labels=gclasses[i])</div><div class="line">                    # 只计算 positive 的loss</div><div class="line">                    loss = tf.losses.compute_weighted_loss(loss, fpmask)</div><div class="line">                    l_cross_pos.append(loss)</div><div class="line"></div><div class="line">                with tf.name_scope(&apos;cross_entropy_neg&apos;):</div><div class="line">                    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits[i],</div><div class="line">                                                                          labels=no_classes)</div><div class="line">                    # 只计算 hard negative 的 loss</div><div class="line">                    loss = tf.losses.compute_weighted_loss(loss, fnmask)</div><div class="line">                    l_cross_neg.append(loss)</div><div class="line"></div><div class="line">                # Add localization loss: smooth L1, L2, ...</div><div class="line">                with tf.name_scope(&apos;localization&apos;):</div><div class="line">                    # Weights Tensor: positive mask + random negative.</div><div class="line">                    weights = tf.expand_dims(alpha * fpmask, axis=-1)</div><div class="line">                    loss = custom_layers.abs_smooth(localisations[i] - glocalisations[i])</div><div class="line">                    loss = tf.losses.compute_weighted_loss(loss, weights)</div><div class="line">                    l_loc.append(loss)</div><div class="line"></div><div class="line">        # Additional total losses...</div><div class="line">        with tf.name_scope(&apos;total&apos;):</div><div class="line">            total_cross_pos = tf.add_n(l_cross_pos, &apos;cross_entropy_pos&apos;)</div><div class="line">            total_cross_neg = tf.add_n(l_cross_neg, &apos;cross_entropy_neg&apos;)</div><div class="line">            total_cross = tf.add(total_cross_pos, total_cross_neg, &apos;cross_entropy&apos;)</div><div class="line">            total_loc = tf.add_n(l_loc, &apos;localization&apos;)</div><div class="line"></div><div class="line">            # Add to EXTRA LOSSES TF.collection</div><div class="line">            tf.add_to_collection(&apos;EXTRA_LOSSES&apos;, total_cross_pos)</div><div class="line">            tf.add_to_collection(&apos;EXTRA_LOSSES&apos;, total_cross_neg)</div><div class="line">            tf.add_to_collection(&apos;EXTRA_LOSSES&apos;, total_cross)</div><div class="line">            tf.add_to_collection(&apos;EXTRA_LOSSES&apos;, total_loc)</div></pre></td></tr></table></figure></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>整个过程就是生成 anchors，将 labels 和 bboxes 编码到 anchors 上，并和网络的输出比较分别计算出正负样本以及位置的loss。<br>重要的点是：</p>
<ol>
<li>num_classes 与每一个 label 的值关系要对，对于 num_classes =4 ,其 labels 就应该为[0, 1, 2, 3]，而不能是大于等于 num_classes 的其他值。</li>
<li>背景的 label 必须设为 0。</li>
<li><p>sparse_softmax_cross_entropy_with_logits 的实现就是 label = 0 对应着 logits 的第一“列”，label = 1 就对应着 logits 的第二“列”，以此类推，因此如果在设置类名和label之间的映射时出现错误则会使得 loss 的计算不能正确反映真实的loss。比如 num_classes = 3，此时logits为三列，而如果 labels = [0, 1, 3]，如此这般时 loss 的计算就会受到影响。</p>
<ul>
<li>labels: Tensor of shape [d_0, d_1, …, d_{r-1}] (where r is rank of labels and result) and dtype int32 or int64. Each entry in labels must be an index in [0, num_classes). Other values will raise an exception when this op is run on CPU, and return NaN for corresponding loss and gradient rows on GPU.</li>
<li>logits: Unscaled log probabilities of shape [d_0, d_1, …, d_{r-1}, num_classes] and dtype float32 or float64.</li>
</ul>
</li>
</ol>

    </div>

    

    
        <div class="post-tags">
            <i class="fa fa-tags" aria-hidden="true"></i>
            <a href="/tags/DL/">#DL</a>
        </div>
    

    <!-- Comments -->
    

</div>
        </section>

    </div>
</div>


</div>

<!-- Footer -->
<div class="push"></div>

<footer class="footer-content">
    <div class="container">
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-6 col-lg-6 footer-about">
                <h2>About</h2>
                <p>
                    This is Robert Lexis (FengCun Li). To see the world, things dangerous to come to, to see behind walls, to draw closer, to find each other and to feel. That is the purpose of LIFE.
                </p>
            </div>
            
    <div class="col-xs-6 col-sm-6 col-md-3 col-lg-3 recent-posts">
        <h2>Recent Posts</h2>
        <ul>
            
            <li>
                <a class="footer-post" href="/2019/03/14/Perfect-forward/">Perfect forward</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2019/03/14/Move-semantic-perfect-forward/">Move semantic &amp; perfect f</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2019/03/14/RAII-smart-pointer/">RAII &amp; smart pointer</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2019/03/13/Leetcode/">Leetcode</a>
            </li>
            
        </ul>
    </div>



            
        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <ul class="list-inline footer-social-icons">
                    
                    <li class="list-inline-item">
                        <a href="https://github.com/RobertLexis">
                            <span class="footer-icon-container">
                                <i class="fa fa-github"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    <li class="list-inline-item">
                        <a href="mailto:robert_lexis@163.com">
                            <span class="footer-icon-container">
                                <i class="fa fa-envelope-o"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                </ul>
            </div>
        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <div class="footer-copyright">
                    @Untitled. All right reserved | Robert Lexis Loves Wenny
                </div>
            </div>
        </div>
    </div>
</footer>

<!-- After footer scripts -->

<!-- jQuery -->
<script src="//code.jquery.com/jquery-2.1.4.min.js"></script>

<!-- Tween Max -->
<script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.5/TweenMax.min.js"></script>

<!-- Gallery -->
<script src="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.js" type="text/javascript" charset="utf-8"></script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script>

<!-- Custom JavaScript -->
<script src="/js/main.js"></script>

<!-- Disqus Comments -->



</body>

</html>